{"id":"1569559259","paper":{"title":{"text":"Matroidal Undirected Network"},"authors":[{"name":"Chung Chan"}],"abstr":{"text":"Abstract\u2014The undirected graphical model is generalized to a linear matroid. The optimal direction for multicasting can be found in polynomial time with respect to the size of the network. A more general problem is also considered where certain function of a distributed source is to be computed at multiple nodes. The converse results are derived, not from the usual cut-set bound but through the related problem of secret key agreement and secure source coding by public discussion. A unifying model of partly directed network can also be formulated, covering both the directed and undirected networks as special cases."},"body":{"text":"The problem of undirected network coding was ﬁrst studied in [ 2 ]. The network consists of point-to-point communication links, where information can ﬂow in two different directions, up to a total rate below the capacity of the link. Independent messages are generated at a source node and then multicast to a set of sink nodes. This is done by choosing the directions of the links and performing coding at the source and inter- mediate nodes. Although the number of possible directions is exponential in the number of undirected links, efﬁcient polynomial-time algorithm exists for computing the optimal direction [ 3 ]. Given the optimal direction, the network coding scheme can also be obtained in polynomial time [ 4 ]. There is also a symmetry in the undirectedness of the network that allows the same code to be used for different choices of the source from the same multicast group [ 5 ].\nThe purpose of this work is to identify the more general structure that makes this undirected network coding problem polynomial-time solvable. It is motivated by the previous work in [ 6 , 7 ], which pointed out a common notion of mutual dependence underlying the undirected network coding problem and the seemingly different problem of secret key agree- ment [ 8 ]. More precisely, the capacities of the two problems are the same and can be computed in polynomial time by exploiting the underlying structure called matroid [ 9 ]. This structure also leads to an information-theoretically appealing characterization of the capacity, which can be viewed as a natural generalization of Shannon\u2019s mutual information to the multivariate case and the combinatorial notion of partition connectivity [ 9 ] originated from the tree packing problem. A similar divergence upper bound on the capacity was ﬁrst pointed out in [ 8 ], and the connection with steiner-tree packing was also observed independently by [ 2 ] and [ 10 ] for the network coding and secrecy problems respectively. However,\nthe bound is not tight in general as shown by the minimal counter-example in [ 11 ] and the connection with steiner-tree packing is not exact. The identity in [ 7 ] provides a way to resolve this disparity and better understand the connection between the different problems.\nThe main result of this work is a generalization of the graph- ical undirected network model referred to as the matroidal undirected network. It can be viewed as the counterpart of the deterministic network model in [ 12 ] since the network may contain undirected broadcast links, interference links, and more general ﬁnite linear channels. It is also inspired by the more abstract view of a network as a matroid or linking system in [ 13 , 14 ], for which the max-ﬂow min-cut theorem takes on a more general form. In addition to studying the problem of multicasting independent messages, we will also consider multicasting a distributed source or function of the source just like [ 15 , 16 ] for the directed network. By relating the problem to the secure source coding problem in [ 17 , 18 ], polynomial-time solution or partial solution can be obtained by exploiting the underlying matroidal structure. The concept can also be extended to a network with its direction partially ﬁxed, with some directed and undirected links. This creates a continuum between the directed and undirected network models. In the sequel, we will describe the model more precisely and introduce the problem of multicasting information over the network. Interested readers can also refer to the paper in [ 1 ], which contains the extended results.\nThe main idea is to deﬁne an undirected network not by the interconnections of a graph but by the more general statistical dependence of a distributed source. To illustrate this, consider the graphical network in Fig. 1(a) , which consists of three users and two undirected links. One of the links is between user 1 and 2 and the other is between user 1 and 3. There are altogether 2 2 = 4 different ways to direct the network as shown in Fig. 1(c) . Consider the ﬁrst direction in Fig. 1(c) . If we set the input symbols (X 1a , X 1b ) to the independent uniformly random (Z 1a , Z 1b ), then the statistics of the inputs and outputs are captured by the distributed source in Fig. 1(b) . If we instead choose the second direction in Fig. 1(b) and set the input symbols (X 2 , X 1b ) to the independent uniformly ran- dom (Z 2 , Z 1b ), we have the same source in Fig. 1(c) . n.b. the statistics of the channel inputs and outputs are always captured by the same distributed source regardless of the direction. The\nsource obtained this way by sending independent and uni- formly random inputs over the network is called the emulated source. Indeed, the emulated source completely characterizes the undirected network in the sense every possible direction corresponds to a different maximal subset of uniformly random source components, referred to as a base of the emulated source. e.g. (Z 1a , Z 1b ) is a base that corresponds to the ﬁrst directed network in Fig. 1(c) with (X 1a , X 1b ) as the inputs. (Z 2 , Z 1b ), (Z 1a , Z 3 ) and (Z 2 , Z 3 ) are the remaining bases, each corresponding to one of the remaining directions. In general, any graphical undirected network can be characterized by an emulated source that is obtained by ﬁxing an arbitrary direction and sending independent uniformly random input symbols. The set of possible bases of the emulated source corresponds to the set of possible ways to direct the network. We call this kind of undirected network matroidal because the emulated source form a matroid [ 9 ] with the rank function being the entropy function [ 19 ] of the source. This is along the same idea as in [ 13 ] where a channel viewed more generally as a linking system can be regarded as a matroid with a ﬁxed base being the set of input variables.\nMatroidal undirected network is a more general concept than the graphical network. e.g. it covers the network in Fig. 2(a) with an undirected interference edge. There are three possible directions as shown in Fig. 2(c) . In the ﬁrst conﬁgura- tion, user 1 and 2 choose the input bits X 1 and X 2 respectively, while user 3 observes the xor bit Y 3 = X 1 ⊕ X 2 . With X 1 and X 2 chosen uniformly randomly and independently, the channel turns into the emulated source in Fig. 2(b) . There are three possible choices of the bases, namely (Z 1 , Z 2 ), (Z 1 , Z 3 ) and (Z 2 , Z 3 ). Each of them corresponds to a different direction in Fig. 2(c) . The network is characterized by the emulated source, and so it is matroidal. Similarly, an undirected broadcast link among the three users can be represented by the emulated source with Z 1 = Z 2 = Z 3 being a uniformly random bit. Any Z i for i = 1, 2, 3 is a base and can therefore be chosen\nas the input of the link. We will consider more generally the undirected version of the following ﬁnite linear network.\nDenote the ﬁnite ﬁeld of order q by F q and have all loga- rithms taken with base q for convenience. Let V := [m] := {1, . . . , m} be the ﬁnite set of users in the network. User i ∈ V\nchooses the channel input ˙x i as a column vector of elements in F q . After the entire input vector ˙x V := [ ˙x ⊺ 1 ... ˙x ⊺ m ] ⊺ is speciﬁed, user i ∈ V observes the output vector\nwhere H i is a transfer matrix with entries in F q . We will impose the additional requirement that ˙x i is a subvector of ˙z i , i.e. ˙x i ⊆ ˙z i . This does not lose generality as user i observes his channel input x i trivially.\nIf the inputs of a ﬁnite linear network are generated uniformly randomly and independently, then the channel outputs form a ﬁnite linear source.\nA source Z V := (Z i : i ∈ V ) is called ﬁnite linear if the component source Z i for user i ∈ V can be written as a vector z i over F q satisfying\n(3a) (3b)\nwhere ℓ(x V ) denotes the length of x V , and H( ·) is the en- tropy [ 19 ] with all logarithms taken base q. x V is called a base of Z V and H V := [ H ⊺ 1 ... H ⊺ m ] ⊺ is called a representation. The set of all possible bases of Z V is denoted as B(Z V ).\nA base x V satisfying ( 3 ) is a perfect compression of the source because x V ⊆ z V and H(x V ) = H(z V ) means that there is a bijection between x V and z V , while H(x V ) = ℓ(x V ) means that x V cannot be compressed further. A ﬁnite linear source deﬁnes an undirected network because every base corresponds to a different representation which can be viewed as a directed ﬁnite linear network. e.g. if ¯ x V is another base satisfying ( 3 ), then it is a subvector of z V by ( 3a ) and so can be written as ¯ x V = M z V for some boolean matrix M . Since z V = H V x V by ( 2 ), we have ¯ x V = M H V x V . M H V must be invertible since the bases are uniformly distributed with the same length by ( 3b ). Thus, x V = (M H V ) −1 ¯ x V and so z i = H i (M H V ) −1 ¯ x V for all i ∈ V . H V (M H V ) −1 is therefore the representation of Z V corresponding to ¯ x V . The set of all bases then corresponds to a collection of ﬁnite linear networks, which deﬁnes the undirected ﬁnite linear network.\nWe will consider the problem of multicasting correlated sources or some function of the sources like [ 15 , 16 ] but over a matroidal undirected ﬁnite linear network characterized by a ﬁnite linear source Z V as described in § II-A . Let U V := (U i : i ∈ V ) be the distributed source where U i is the component observed privately by user i ∈ V . A subset A ⊆ V of |A| ≥ 1 sink nodes or active users want to recover some function G of U V by the following block coding scheme.\nA positive integer n ∈ P is chosen as the block length. U V and Z V are extended n times into the i.i.d. sequences U n V := (U V t : t ∈ [n]) and similarly Z n V , with Z V t represented by the vector z V t over F q . Each user i ∈ V observes U n i and then transmits over the undirected network as follows.\nEncoding: At time t from 1 to n, user i ∈ V speciﬁes the direction x it ⊆ z it and the corresponding channel input ˙x it with ℓ( ˙x it ) = ℓ(x it ) as a function of his private source U n i\nand previous channel outputs denoted by ˙z i[t −1] . An encoding error occurs if the direction is invalid, i.e. x V ̸∈ B(Z V ). Otherwise, the channel return to user i ∈ V his output ˙z it := H it ˙x V t as in ( 1 ), where H V t is the representation of Z V t corresponding to the base x V t , i.e. z it := H it x V t as in ( 2 ). Decoding: After time n, each active user j ∈ A attempts to recover G n as a function ˆ G j of his private source U n j and his entire channel output sequence ˙z i[n] . A decoding error occurs if G n ̸= ˆG j for any j ∈ A.\nG n is said to be transmissible to A if ε n decays to zero, i.e. lim sup n →∞ ε n = 0. The objective is to ﬁnd an easily computable condition for transmissibility.\nA particular case of interest is to attain omniscience of the distributed source, i.e. G = U V . Another case of interest is when the users want to send independent messages instead of\ncorrelated memoryless sources. Let W i be the message from user i ∈ V and ˆ W j be the estimate of the entire message W V by user j ∈ A. The encoding and decoding proceed in the same way as before with U n i , G n and ˆ G j replaced by W i , W V and ˆ W j respectively. ε n is also deﬁned as in ( 4 ) with the corresponding modiﬁcations. Each W i takes values from a message set W i that is growing exponentially in n at rate\nn . \t (5) The rate tuple R V := (R i : i ∈ V ) is said to be achievable if lim sup n →∞ ε n = 0 assuming the messages are uniformly distributed. The maximum throughput or simply the capacity of the network is deﬁned as the maximum achievable sum rate\nwhere the supremums on the left and right are taken over all achievable rate vectors and block codes respectively.\nWe ﬁrst derive a necessary condition for transmissibility. Such converse results for network coding are often derived using the cut-set bound. It is rather tricky to apply the same technique here because the directions of the network can vary in time and adapt to the channel outputs. We will obtain the desired condition in a different way through the closely related problem of secure source coding by public discussion [ 17 ].\nThe secure source coding problem involves a wiretapper in addition to the set V of users, a subset A of which is also identiﬁed as the active users. The users observe n iid samples of some private distributed source say ˜ U V . They want to discuss in public until some given function G of the source, called the secret source, can be computed by the active users but not the wiretapper. Unlike the original network coding problem where the communication is over a given undirected network, there is no restriction on the public discussion. The users can broadcast messages to all other users noiselessly with unlimited rates for multiple rounds. The only catch is that the public messages and the discussion scheme are known to the wiretapper. The secret source G is said to be securely computable if the discussion can be chosen such that the error probability in recovering secret source sequence G n by the active users and the amount of information about G n leaked to the wiretapper decay to zero in n.\nThis problem was ﬁrst proposed in [ 17 ] as an extension to the secret key agreement problem in [ 8 ]. It was further extended in [ 18 , 20 ] in the study of imperfect secrecy, the achievable exponents and the admissible choices of key func- tions. The problem of secure source coding can be mapped to that of undirected network coding as follows such that G is securely computable by public discussion if G is transmissible over the undirected network.\nFor the secure source coding problem, we set (U V , Z V ) as the multiple source, where U V is independent of Z V , and (U i , Z i ) is the component source observed privately by user i ∈ V . The secret source G is a function of U V but not Z V . The additional source Z V allows the users to simulate the undirected network by public discussion as follows. At time t from 1 to n, user i ∈ V broadcasts the public message\nwhere H V t is the representation of Z V t corresponding to the base x V t . After time n, user j ∈ A compute the estimate ˆG j of G n from U n j and ˙z i[n] .\nUsing the above mapping, the overall error probability is ϵ n in ( 4 ), which decays to zero by the assumption that G is transmissible. It remains to argue that the public discussion reveals no information about G n . From ( 7 ), f V [n] is uniformly distributed because x V [n] is not only uniformly distributed by ( 3b ) but also independent of ˙x V [n] since ˙x V [n] is a function of U n V and the channel output ˙z V [n] , which is ultimately a function of U n V independent of Z n V . Since f V [n] is uniformly distributed regardless of the realization of U n V , we have U n V independent of f V [n] . Hence, G is securely computable and so the necessary condition in [ 17 ] and [ 18 , Theorem 7] for G to be securely computable is also the necessary condition for G to be transmissible.\nTheorem 1 A function G of U V is transmissible to A ⊆ V : |A| ≥ 1 over a matroidal undirected network Z V only if\nz(B) ≥ H(U B |U B c ) + H(Z B |Z B c ) ∀B ⊆ V : B ̸⊇ A z(B) ≥ H(U B |U B c G) + H(Z B |Z B c ) ∀B ⊆ V : B ⊇ A\n(9a) (9b)\nz i and B c denotes V \\ B. The optimal z V can be computed in polynomial time with respect to the size |V | = m of the network, assuming that H(U B ) and H(Z B ) can be evaluated in polynomial time for B ⊆ V . \t 2\nP ROOF For the secure source coding problem in [ 18 ], the R.H.S. of ( 8 ) is a linear program (LP) that characterizes the maximum amount of information about G that can be kept secret from the wiretapper under the requirement that G is recoverable by all active users after public discussion.\nIntuitively, it should be equal to H(G) for G to be securely computable since no information about G should be leaked to the wiretapper. With the previous argument that G being transmissible implies it is securely computable, this is the desired necessary condition.\nThe polynomial time complexity in computing the optimal z V is not straightforward because the number of constraints in ( 9 ) is exponential in m. The idea is to exploit the underlying matroidal structure by solving the LP using the ellipsoid method [ 9 ]. The complexity of the ellipsoid method is equiva- lent to that of the separation oracle that determines whether a solution is feasible. From ( 9 ), z V is feasible iff for all j ∈ A 0 ≤ min\nThese are submodular function minimizations over lattice families, and so can be solved in polynomial time [ 9 ]. More precisely, the ﬁrst constraint set {B ⊆ V : j /∈ B} is a lattice family because, for every B 1 and B 2 in the family, B 1 ∩ B 2 and B 1 ∪B 2 are also in the family. The ﬁrst objective function f (B) := z(B) − H(U B |U B c ) − H(Z B |Z B c ) is submodular\nby the fact that entropy function is submodular [ 19 ]. The same argument applies to the last minimization. Since there are only |A| + 1 ≤ m + 1 submodular function minimizations, the overall complexity is polynomial in m as desired. \t ■\nThe necessary condition may not be sufﬁcient as illustrated in [ 1 ]. The problem of function computation is difﬁcult in general even for directed networks [ 16 ]. In the omniscience case G = U V , however, closely matching necessary and sufﬁcient conditions have been derived for directed networks using the cut-set bound and random coding scheme [ 15 ]. It turns out that the necessary condition above can also be expressed in a similar form of the cut-set bound for which a random coding scheme can also give a closely matching sufﬁcient condition for undirected networks.\nTheorem 2 U V is transmissible to A over a matroidal undi- rected network Z V only if\n(11a) (11b)\nx(B) ≤ H(Z B ) ∀B ⊊ V x(V ) = H(Z V ).\n(13a) (13b)\nFurthermore, x V = z V is an optimal solution to ( 13 ) if z V is an optimal solution satisfying ( 10 ). \t 2\n( 12 ) is in the form of the cut-set bound. To see this, consider some subset B ⊆ V : B ̸⊇ A. Since the source U V needs to be recovered by some users in B c , namely the active users in A \\ B ̸= ∅, there must be an information ﬂow of rate at least H(U B |U B c ) collectively from B to B c . Suppose, for simplic- ity, that x V t ∈ B(Z V ) is chosen as the direction for time t prior to observing any channel outputs. Then, using some standard information-theoretic argument, it can be argued that the network supports a ﬂow rate of at most 1 n\nI(x Bt ∧ Z B c |x B c t ) = H(Z B c ) − x(B c ) where I( ·) denotes Shannon\u2019s mutual information [ 19 ], x i := 1 n\nℓ(x it ), and the last equality is by ( 3 ). Furthermore, it can be shown [ 9 ] that the set of all possible x V forms the base B of a polymatroid. ( 12 ) simply asserts that there is a way to direct the network according to some x V ∈ B such that any subset B c of users containing an active user in A can obtain information at the required rate H(U B |U B c ) ≤ H(Z B c ) − x(B c ). The formal proof of Theorem 2 is given in [ 1 ] using the identity in [ 7 ]. The following closely matching sufﬁcient condition is derived using the random coding scheme by adapting the error analysis in [ 12 ] to the current undirected network model.\nAs detailed in [ 1 ], the optimal direction of the network can be obtained from the optimal x V to ( 14 ), which again can be computed in polynomial time. In the case of multicasting independent messages, the sufﬁcient and necessary conditions match precisely and give the achievable rate region below.\nTheorem 4 The set of achievable R V for the undirected network Z V is the set of non-negative tuples deﬁned by\nThe capacity has the alternative form of partition connectiv- ity in [ 7 ]. It can again be computed using the ellipsoid method in polynomial time and so as the projection ( 18 ) of G onto A.\nThe previous results can be extended to undirected network models where the matroidal structure can be identiﬁed. In particular, a more general matroidal partly directed ﬁnite linear network can be deﬁned as in [ 1 ] by specifying the base partially so that the remaining choices of direction still forms the base of a matroid. The directed and undirected networks are covered as extreme special cases. The mapping from the secret key agreement problem to the network coding problem holds also for other scenarios such as agreeing on multiple keys among different groups of users and multicasting independent messages among different multicast groups."},"refs":[{"authors":[{"name":"C. Cha"}],"title":{"text":""}},{"authors":[{"name":"Z. Li"},{"name":"B. Li"}],"title":{"text":"Network coding in undirected networks"}},{"authors":[{"name":"Z. Li"},{"name":"B. Li"},{"name":"L. C. Lau"}],"title":{"text":"On achieving maximum multicast through- put in undirected networks"}},{"authors":[{"name":"S. Jaggi"},{"name":"P. Sanders"},{"name":"P. A. Chou"},{"name":"M. Effros"},{"name":"S. Egner"},{"name":"K. Jain"},{"name":"L. Tolhiuzen"}],"title":{"text":"Polynomial time algorithms for multicast network code construction"}},{"authors":[{"name":"J. Goseling"},{"name":"C. Fragouli"},{"name":"S. N. Diggavi"}],"title":{"text":"Network coding for undi- rected information exchange"}},{"authors":[{"name":"C. Chan"}],"title":{"text":"Generating secret in a network"}},{"authors":[],"title":{"text":"The hidden ﬂow of information"}},{"authors":[{"name":"I. Csisz´ar"},{"name":"P. Narayan"}],"title":{"text":"Secrecy capacities for multiple terminals"}},{"authors":[{"name":"A. Schrijve"}],"title":{"text":"Combinatorial Optimization: Polyhedra and Efﬁciency"}},{"authors":[{"name":"C. Y. S. Nitinawarat"},{"name":"A. Reznik"}],"title":{"text":"Secret key generation for a pairwise independent network model"}},{"authors":[{"name":"C. Chan"},{"name":"L. Zheng"}],"title":{"text":"Mutual dependence for secret key agreement"}},{"authors":[{"name":"A. S. Avestimehr"},{"name":"S. N. Diggavi"},{"name":"D. N. C. Tse"}],"title":{"text":"Wireless network in- formation ﬂow: A deterministic approach"}},{"authors":[{"name":"A. Schrijver"}],"title":{"text":"Matroids and linking systems"}},{"authors":[{"name":"M. Goemans"},{"name":"S. Iwata"},{"name":"R. Zenklusen"}],"title":{"text":"An algorithmic framework for wireless information ﬂow"}},{"authors":[{"name":"T. S. Han"}],"title":{"text":"Multicasting multiple correlated sources to multiple sinks over a noisy channel network"}},{"authors":[{"name":"R. Appuswamy"},{"name":"M. Franceschetti"},{"name":"N. Karamchandani"},{"name":"K. Zeger"}],"title":{"text":"Network coding for computing: Cut-set bounds"}},{"authors":[{"name":"H. Tyagi"},{"name":"P. Narayan"},{"name":"P. Gupta"}],"title":{"text":"When is a function securely com- putable?"}},{"authors":[{"name":"C. Chan"}],"title":{"text":"Multiterminal secure source coding for a common secret source"}},{"authors":[{"name":"R. W. Yeun"}],"title":{"text":"Information Theory and Network Coding"}},{"authors":[{"name":"C. Chan"}],"title":{"text":"Agreement of a restricted secret key"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012test/1569559259.pdf"},"links":[{"id":"1569559541","weight":35},{"id":"1569559221","weight":25},{"id":"1569558785","weight":27},{"id":"1569559565","weight":29},{"id":"1569558681","weight":23},{"id":"1569559195","weight":26},{"id":"1569558859","weight":19},{"id":"1569566489","weight":24},{"id":"1569558901","weight":11},{"id":"1569559111","weight":35},{"id":"1569558985","weight":27},{"id":"1569558509","weight":22},{"id":"1569565705","weight":45},{"id":"1569551347","weight":15},{"id":"1569559199","weight":21},{"id":"1569559035","weight":9},{"id":"1569558779","weight":37},{"id":"1569559523","weight":14},{"id":"1569559597","weight":27},{"id":"1569559251","weight":47},{"id":"1569550425","weight":37},{"id":"1569564509","weight":3},{"id":"1569558697","weight":20},{"id":"1569559233","weight":19}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S9.T1.4","endtime":"11:10","authors":"Chung Chan","date":"1341399000000","papertitle":"Matroidal undirected network","starttime":"10:50","session":"S9.T1: Network Coding:  Security and Reliability","room":"Kresge Rehearsal B (030)","paperid":"1569559259"},"cluster":{"jsonClass":"Map$EmptyMap$"}}
