{"id":"1569566611","paper":{"title":{"text":"Sparse Signal Separation in Redundant Dictionaries"},"authors":[{"name":"Céline Aubel ∗"},{"name":"Christoph Studer \u2020"},{"name":"Graeme Pope ∗"},{"name":"Helmut Bölcskei ∗"}],"abstr":{"text":"Abstract\u2014We formulate a uniﬁed framework for the separa- tion of signals that are sparse in \u201cmorphologically\u201d different redundant dictionaries. This formulation incorporates the so- called \u201canalysis\u201d and \u201csynthesis\u201d approaches as special cases and contains novel hybrid setups. We ﬁnd corresponding coherence- based recovery guarantees for an 1 -norm based separation algorithm. Our results recover those reported in Studer and Baraniuk, ACHA, submitted, for the synthesis setting, provide new recovery guarantees for the analysis setting, and form a basis for comparing performance in the analysis and synthesis settings. As an aside our ﬁndings complement the D-RIP recovery results reported in Candès et al., ACHA, 2011, for the \u201canalysis\u201d signal recovery problem"},"body":{"text":"We consider the problem of splitting the signal x = x 1 +x 2 into its constituents x 1 ∈ C d and x 2 ∈ C d \u2014assumed to be sparse in \u201cmorphologically\u201d different (redundant) dic- tionaries [1]\u2014based on m linear, nonadaptive, and noisy measurements y = Ax + e. Here, A ∈ C m×d , m ≤ d, is the measurement matrix, assumed to be known, and e ∈ C m is a noise vector, assumed to be unknown and to satisfy e 2 ≤ ε, with ε known.\nRedundant dictionaries [2], [3] often lead to sparser repre- sentations than nonredundant ones, such as, e.g., orthonormal bases, and have therefore become pervasive in the sparse signal recovery literature [3]. In the context of signal separation, redundant dictionaries lead to an interesting dichotomy [1], [4], [5]:\n\u2022 In the so-called \u201csynthesis\u201d setting, it is assumed that, for = 1, 2, x = D s , where D ∈ C d×n (d < n) is a redundant dictionary (of full rank) and the coefﬁcient vector s ∈ C n is sparse (or approximately sparse in the sense of [6]). Given the vector y ∈ C m , the problem of ﬁnding the constituents x 1 and x 2 is formalized as [7]:\n\u2022 In the so-called \u201canalysis\u201d setting, it is assumed that, for = 1, 2, there exists a matrix Ψ ∈ C n×d such that\nΨ x is sparse (or approximately sparse). The problem of recovering x 1 and x 2 from y is formalized as [5]:\nThroughout the paper, we exclusively consider redundant dic- tionaries as for D , = 1, 2, square, the synthesis setting can be recovered from the analysis setting by taking Ψ = D −1 .\nThe problems (PS) and (PA) arise in numerous applications including denoising [8], super-resolution [8], inpainting [9]\u2013 [11], deblurring [11], and recovery of sparsely corrupted signals [12]. Coherence-based recovery guarantees for (PS) were reported in [7]. The problem (PA) was mentioned in [5]. In the noiseless case, recovery guarantees for (PA), expressed in terms of a concentration inequality, are given in [13] for A = I d and Ψ 1 and Ψ 2 both Parseval frames [2].\nwhich encompasses (PS) and (PA). To recover (PS) from (P), one sets A = AD and Ψ = [I d 0 d,n−d ] T , for = 1, 2. (PA) is obtained by choosing A = A, for = 1, 2. Our main contribution is a coherence-based recovery guarantee for the general problem (P). This result recovers [7, Th. 4], which deals with (PS), provides new recovery guarantees for (PA), and constitutes a basis for comparing performance in the analysis and synthesis settings. As an aside, it also complements the D-RIP recovery guarantee in [5, Th. 1.2] for the problem\nby delivering a corresponding coherence-based recovery guar- antee. Moreover, the general formulation (P) encompasses novel hybrid problems of the form\nNotation: Lowercase boldface letters stand for column vectors and uppercase boldface letters denote matrices. The transpose, conjugate transpose, and Moore-Penrose inverse of the matrix M are designated as M T , M H , and M \u2020 , respectively. The jth column of M is written [M] j , and\nthe entry in the ith row and jth column of M is [M] i,j . We let σ min (M) denote the smallest singular value of M, use I n for the n × n identity matrix, and let 0 k×m be the k × m all zeros matrix. For matrices M and N, we let ω min (M) \t min j [M] j 2 , ω max (M) \t max j [M] j 2 , ω min (M, N) min{ω min (M), ω min (N)}, and ω max (M, N)\nmax{ω max (M), ω max (N)}. The kth entry of the vector x is written [x] k , and x 1 \t k |[x] k | stands for its 1 -norm. We take supp k (x) to be the set of indices corresponding to the k largest (in magnitude) coefﬁcients of x. Sets are designated by uppercase calligraphic letters; the cardinality of the set S is |S| and the complement of S (in some given set) is denoted by S c . For a set S of integers and n ∈ Z, we let n + S {n + p : p ∈ S}. The n × n diagonal projection matrix P S for the set S ⊂ {1, . . . , n} is deﬁned as follows:\nand we set M S P S M. We deﬁne σ k (x) to be the 1 -norm approximation error of the best k-sparse approximation of x, i.e., σ k (x) \t x−x S 1 where S = supp k (x) and x S P S x.\nCoherence deﬁnitions in the sparse signal recovery litera- ture [3] usually apply to dictionaries with normalized columns. Here, we will need coherence notions valid for general (un- normalized) dictionaries M and N, assumed, for simplicity of exposition, to consist of nonzero columns only.\nDeﬁnition 1 (Coherence): The coherence of the dictio- nary M is deﬁned as\nDeﬁnition 2 (Mutual coherence): The mutual coherence of the dictionaries M and N is deﬁned as\nThe main contribution of this paper is the following recov- ery guarantee for (P).\nTheorem 1: Let y = A 1 x 1 + A 2 x 2 + e with e 2 ≤ ε and let Ψ 1 ∈ C n 1 ×p 1 and Ψ 2 ∈ C n 2 ×p 2 be full-rank matrices. Let x = [x T 1 x T 2 ] T , ˆ µ 1 = ˆ µ(A 1 Ψ \u2020 1 ), ˆ µ 2 = ˆ µ(A 2 Ψ \u2020 2 ), ˆ µ m = ˆ µ m (A 1 Ψ \u2020 1 , A 2 Ψ \u2020 2 ), and ˆ µ max = max{ˆ µ 1 , ˆ µ 2 , ˆ µ m }. Without loss of generality, we assume that ˆ µ 1 ≤ ˆ µ 2 . Let k 1 and k 2 be nonnegative integers such that\n(3) Then, the solution (x ∗ 1 , x ∗ 2 ) to the convex program (P) satisﬁes\nwhere C 0 , C 1 ≥ 0 are constants that do not depend on x 1 and x 2 and where x ∗ = [x ∗ 1 T x ∗ 2 T ] T .\nNote that the quantities ˆ µ 1 , ˆ µ 2 , and ˆ µ m characterize the in- terplay between the measurement matrix A and the sparsifying transforms Ψ 1 and Ψ 2 .\nAs a corollary to our main result, we get the following statement for the problem (P ∗ ) considered in [5].\nCorollary 2: Let y = Ax + e with e 2 ≤ ε and let Ψ ∈ C n×p be a full-rank matrix. Let k be a nonnegative integer such that\nThe proofs of Theorem 1 and Corollary 2 can be found in the Appendix.\nWe conclude by noting that D-RIP recovery guarantees for (P ∗ ) were provided in [5]. As is common in RIP-based\nrecovery guarantees the restricted isometry constants are, in general, hard to compute. Moreover, the results in [5] hinge on the assumption that Ψ forms a Parseval frame, i.e., Ψ H Ψ = I d ; a corresponding extension to general Ψ was provided in [14]. We ﬁnally note that it does not seem possible to infer the coherence-based threshold (5) from the D-RIP recovery guarantees in [5], [14].\nWe analyze an image-separation problem where we remove a ﬁngerprint from a cartoon image. We corrupt the 512 × 512 greyscale cartoon image depicted in Fig. 1(a) by adding a ﬁngerprint 2 and i.i.d. zero-mean Gaussian noise.\nCartoon images are constant apart from (a small number of) discontinuities and are thus sparse under the ﬁnite difference operator ∆ deﬁned in [15]. Fingerprints are sparse under the application of a wave atom transform, W, such as the redun- dancy 2 transform available in the WaveAtom toolbox 3 [16]. It is therefore sensible to perform separation by solving the problem (PA) with Ψ 1 = ∆, Ψ 2 = W, and A = I d . For our simulation, we use a regularized version of ∆ and we employ the TFOCS solver 4 from [17].\nFig. 1(c) shows the corresponding recovered image. We can see that the restoration procedure gives visually satisfactory results.\nFor simplicity of exposition, we ﬁrst present the proof of Corollary 2 and then describe the proof of Theorem 1.\nWe deﬁne the vector h = x ∗ − x, where x ∗ is the solution to (P ∗ ) and x is the vector to be recovered. We furthermore set S = supp k (Ψx).\n1) Prerequisites: Our proof relies partly on two important results developed earlier in [5], [6] and summarized, for completeness, next.\nProof: Since x ∗ is the minimizer of (P ∗ ), the inequality Ψx 1 ≥ Ψx ∗ 1 holds. Using Ψ = Ψ S + Ψ S c and x ∗ =\n≥ Ψx ∗ 1 = Ψ S x + Ψ S h 1 + Ψ S c x + Ψ S c h 1 ≥ Ψ S x 1 − Ψ S h 1 + Ψ S c h 1 − Ψ S c x 1 .\nLemma 4 (Tube constraint [5], [6]): The vector Ah satis- ﬁes Ah 2 ≤ 2ε.\nProof: Since both x ∗ and x are feasible (we recall that y = Ax + e with e 2 ≤ ε), we have the following\n2) Bounding the recovery error: We want to bound h 2 from above. Since σ min (Ψ) > 0 by assumption (Ψ is assumed to be full-rank), it follows from the Rayleigh-Ritz theorem [18, Th. 4.2.2] that\nSince Q is the set of indices of the k largest (in magnitude) coefﬁcients of Ψh and since Q and S both contain k elements, we have Ψ S h 1 ≤ Ψ Q h 1 and Ψ Q c h 1 ≤ Ψ S c h 1 , which, combined with the cone constraint in Lemma 3, yields\n+ 2 Ψ S c x 1 Ψ Q h 1 k\nk u 2 for k-sparse 5 u and (12b) is a consequence of 2xy ≤ x 2 + y 2 , for x, y ∈ R.\nk \t (13a) ≤\nwhere (13a) is a consequence of (12b) and (13b) results from x 2 + y 2 ≤ x + y, for x, y ≥ 0.\n3) Bounding the term Ψ Q h 2 in (14): In the last step of the proof, we bound the term Ψ Q h 2 in (14). To this end, we ﬁrst bound AΨ \u2020 Ψ Q h 2 2 , with Ψ \u2020 = (Ψ H Ψ) −1 Ψ H , using Geršgorin\u2019s disc theorem [18, Th. 6.2.2]:\nwhere θ min ω 2 min − µ(k − 1) and θ max ω 2 max + µ(k − 1) with\nUsing Lemma 4 and (15) and following the same steps as in [20, Th. 2.1] and [7, Th. 1], we arrive at the following chain of inequalities:\n= (Ah) H AΨ \u2020 Ψ Q h − (AΨ \u2020 Ψ Q c h) H AΨ \u2020 Ψ Q h \t (17a) ≤ |(Ah) H AΨ \u2020 Ψ Q h| + |(Ψ Q c h) H (AΨ \u2020 ) H AΨ \u2020 (Ψ Q h)| ≤ Ah 2 AΨ \u2020 Ψ Q h 2\n(17d) ≤ 2ε θ max Ψ Q h 2 + µk Ψ Q h 2 2\nwhere (17a) follows from Ψ Q h = Ψh − Ψ Q c h and Ψ \u2020 Ψ = I d , (17b) is a consequence of the Cauchy-Schwarz inequality, (17c) is obtained from (15), Lemma 4, and the deﬁnition of µ in (16), (17d) results from (11), and (17e) comes from u 1 ≤ √\nIf h = 0, then Ψ Q h 2 = 0, since Ψ is assumed to be full-rank and Q is the set of indices of the k largest (in magnitude) coefﬁcients of Ψh, and therefore, the inequality between θ min Ψ Q h 2 2 and (17e) simpliﬁes to\n4) Recovery guarantee: Using Deﬁnition 1, we get ˆ µ = ˆ µ(AΨ \u2020 ) = µ/ω 2 min . Combining (14) and (18), we therefore conclude that for\nk < 1 2\nˆ µ \t (19) we have\n(1 + ˆ µ(k − 1)) 1 − ˆ µ(2k − 1)\nWe start by transforming (P) into the equivalent problem (P ∗ ) minimize\nby amalgamating Ψ 1 , Ψ 2 and A 1 , A 2 into the matrices Ψ and A as follows:\nwhere p = 2d in the analysis setting, p = 2n in the synthesis setting, and p = d + n in hybrid settings. The corresponding measurement vector is y = Ax + e, where we set x = [x T 1 x T 2 ] T .\nA recovery condition for (P) could now be obtained by simply inserting A and Ψ in (20), (21) above into (5). In certain cases, we can, however, get a better (i.e., less restrictive) threshold following ideas similar to those reported in [7] and detailed next.\nWe deﬁne the vectors h 1 = x ∗ 1 − x 1 , h 2 = x ∗ 2 − x 2 , the sets Q 1 \t supp k\n(Ψ 2 h 2 ), and h = [h T 1 h T 2 ] T , Q = Q 1 ∪ Q 2 , and set k = k 1 + k 2 .\nWe furthermore let, for = 1, 2, µ = max\nWith the deﬁnitions of Q 1 and Q 2 , we have from (15) AΨ \u2020 Ψ Q h 2 2 = AΨ \u2020 Ψ Q 1 h 2 2 + AΨ \u2020 Ψ Q 2 h 2 2\nwith θ min, \t ω 2 min (A Ψ \u2020 ) − µ (k − 1) and θ max, ω 2 max (A Ψ \u2020 ) + µ (k − 1), for = 1, 2.\nIn addition, the last term in (22) can be bounded as |(AΨ \u2020 Ψ Q 1 h) H AΨ \u2020 Ψ Q 2 h|\n≤ µ m Ψ Q 1 h 1 Ψ Q 2 h 1 \t (25a) ≤ µ m k 1 k 2 Ψ Q 1 h 2 Ψ Q 2 h 2 \t (25b) ≤ µ m\nwhere (25a) follows from the deﬁnition of µ m , (25b) results from u 1 ≤\nk u 2 , for k-sparse u, and (25c) is a conse- quence of the arithmetic-mean geometric-mean inequality.\nwhere θ min ω 2 min −f (k 1 , k 2 ), θ max ω 2 max +f (k 1 , k 2 ), ω min ω min (A 1 Ψ \u2020 1 , A 2 Ψ \u2020 2 ), ω max ω max (A 1 Ψ \u2020 1 , A 2 Ψ \u2020 2 ), and\nNext, we bound g(k 1 , k 2 ) from below by a function of k = k 1 +k 2 . This can be done, e.g., by looking for the minimum [7]\nTo ﬁnd ˆ g(k) in (26) or in (27), we need to distinguish between two cases:\n\u2022 Case 1: µ 1 (k 1 − 1) ≤ µ 2 (k 2 − 1) In this case, we get\nA straightforward calculation reveals that the minimum of g is achieved at\nσ min (Ψ)ˆ g(k) and\nwhere we used Deﬁnitions 1 and 2 to get a threshold depending on the coherence parameters only.\n\u2022 Case 2: µ 2 (k 2 − 1) ≤ µ 1 (k 1 − 1) Similarly to Case 1, we get\nSince ˆ µ 1 ≤ ˆ µ 2 , by assumption, the inequality in (30) is tighter than the one in (29). We complete the proof by combining the thresholds in (19) and (29) to get (3)."},"refs":[{"authors":[{"name":"R. Rubinstein"},{"name":"A. M. Bruckstein"},{"name":"M. Elad"}],"title":{"text":"Dictionaries for sparse representation modeling"}},{"authors":[{"name":"O. Christense"},{"name":"J. J. Benedett"}],"title":{"text":"An Introduction to Frames and Riesz Bases, ser"}},{"authors":[{"name":"M. Ela"}],"title":{"text":"Sparse and Redundant Representations \u2013 From Theory to Applications in Signal and Image Processing "}},{"authors":[{"name":"P. Milanfar"},{"name":"R. Rubinstein"}],"title":{"text":"Analysis versus synthesis in signal priors"}},{"authors":[{"name":"E. J. Candès"},{"name":"Y. C. Eldar"},{"name":"D. Needell"},{"name":"P. Randall"}],"title":{"text":"Compressed sens- ing with coherent and redundant dictionaries"}},{"authors":[{"name":"E. J. Candès"},{"name":"J. Romberg"},{"name":"T. Tao"}],"title":{"text":"Stable signal recovery from incomplete and inaccurate measurements"}},{"authors":[{"name":"C. Studer"},{"name":"R. Baraniuk"}],"title":{"text":"Stable restoration and separation of approximately sparse signals"}},{"authors":[{"name":"S. G. Malla"}],"title":{"text":"A Wavelet Tour of Signal Processing: The Sparse Way"}},{"authors":[{"name":"M. Elad"},{"name":"J.-L. Starck"},{"name":"P. Querre"},{"name":"D. L. Donoho"}],"title":{"text":"Simultaneous cartoon and texture image inpainting using morphological component analysis (MCA)"}},{"authors":[{"name":"J. Fadili"},{"name":"J.-L. Starck"},{"name":"M. Elad"},{"name":"D. L. Donoho"}],"title":{"text":"MCALab: Repro- ducible research in signal and image decomposition and inpainting"}},{"authors":[{"name":"J.-F. Cai"},{"name":"S. Osher"},{"name":"Z. Shen"}],"title":{"text":"Split Bregman methods and frame based image restoration"}},{"authors":[{"name":"C. Studer"},{"name":"P. Kuppinger"},{"name":"G. Pope"},{"name":"H. Bölcskei"}],"title":{"text":"Recovery of sparsely corrupted signals"}},{"authors":[{"name":"G. Kutyniok"}],"title":{"text":"Data separation by sparse representations"}},{"authors":[{"name":"Y. Liu"},{"name":"T. Mi"},{"name":"S. Li"}],"title":{"text":"Compressed sensing with general frames via optimal-dual-based 1 -analysis"}},{"authors":[{"name":"S. Nam"},{"name":"M. Davies"},{"name":"M. Elad"},{"name":"R. Gribonval"}],"title":{"text":"The cosparse analysis model and algorithms"}},{"authors":[{"name":"L. Demanet"},{"name":"L. Ying"}],"title":{"text":"Wave atoms and sparsity of oscillatory patterns"}},{"authors":[{"name":"S. Becker"},{"name":"E. J. Candès"},{"name":"M. Grant"}],"title":{"text":"Templates for convex cone problems with applications to sparse signal recovery"}},{"authors":[{"name":"R. A. Hor"},{"name":"C. R. Johnso"}],"title":{"text":"Matrix Analysis"}},{"authors":[{"name":"T. T. Cai"},{"name":"L. Wang"},{"name":"G. Xu"}],"title":{"text":"New bounds for restricted isometry constants"}},{"authors":[],"title":{"text":"Stable recovery of sparse signals and an oracle inequality"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566611.pdf"},"links":[{"id":"1569566567","weight":2},{"id":"1569564843","weight":4},{"id":"1569566527","weight":3},{"id":"1569566485","weight":3},{"id":"1569565383","weight":3},{"id":"1569565883","weight":4},{"id":"1569564889","weight":6},{"id":"1569565223","weight":5},{"id":"1569566725","weight":8},{"id":"1569565663","weight":2},{"id":"1569565377","weight":5},{"id":"1569566385","weight":9},{"id":"1569564635","weight":5},{"id":"1569565867","weight":10},{"id":"1569566799","weight":13},{"id":"1569565067","weight":3},{"id":"1569559665","weight":9},{"id":"1569561021","weight":3},{"id":"1569565691","weight":2},{"id":"1569566815","weight":5},{"id":"1569566875","weight":3},{"id":"1569564605","weight":2},{"id":"1569566981","weight":4},{"id":"1569566433","weight":3},{"id":"1569566321","weight":21},{"id":"1569566605","weight":3},{"id":"1569565489","weight":3},{"id":"1569566683","weight":4},{"id":"1569566855","weight":3},{"id":"1569560629","weight":4},{"id":"1569566869","weight":16},{"id":"1569565097","weight":5},{"id":"1569566227","weight":2},{"id":"1569566091","weight":7},{"id":"1569559259","weight":4},{"id":"1569566697","weight":7},{"id":"1569566597","weight":5},{"id":"1569565551","weight":6},{"id":"1569565711","weight":4},{"id":"1569566761","weight":5},{"id":"1569566943","weight":5},{"id":"1569565091","weight":6},{"id":"1569566591","weight":5},{"id":"1569556029","weight":3},{"id":"1569566571","weight":7},{"id":"1569552245","weight":7},{"id":"1569565607","weight":2},{"id":"1569565495","weight":4},{"id":"1569559967","weight":5},{"id":"1569567045","weight":8},{"id":"1569565227","weight":13},{"id":"1569564481","weight":16},{"id":"1569560833","weight":6},{"id":"1569566415","weight":7},{"id":"1569564805","weight":6},{"id":"1569567005","weight":24},{"id":"1569566469","weight":2},{"id":"1569566081","weight":5},{"id":"1569565355","weight":5},{"id":"1569564469","weight":4},{"id":"1569565931","weight":5},{"id":"1569566373","weight":2},{"id":"1569566647","weight":5},{"id":"1569551535","weight":11},{"id":"1569566765","weight":4},{"id":"1569564897","weight":10},{"id":"1569565775","weight":4},{"id":"1569565547","weight":3},{"id":"1569566871","weight":7},{"id":"1569566653","weight":13},{"id":"1569565461","weight":13},{"id":"1569564731","weight":7},{"id":"1569565171","weight":3},{"id":"1569566207","weight":9},{"id":"1569564227","weight":5},{"id":"1569558325","weight":6},{"id":"1569565837","weight":3},{"id":"1569566671","weight":4},{"id":"1569566303","weight":3},{"id":"1569566119","weight":3},{"id":"1569564233","weight":4},{"id":"1569566459","weight":3},{"id":"1569567535","weight":3},{"id":"1569563411","weight":6},{"id":"1569560427","weight":3},{"id":"1569564401","weight":5},{"id":"1569564849","weight":3},{"id":"1569559541","weight":5},{"id":"1569565317","weight":2},{"id":"1569566363","weight":6},{"id":"1569566319","weight":3},{"id":"1569565123","weight":6},{"id":"1569566941","weight":4},{"id":"1569566033","weight":9},{"id":"1569566739","weight":4},{"id":"1569555811","weight":4},{"id":"1569558459","weight":3},{"id":"1569565609","weight":3},{"id":"1569565291","weight":5},{"id":"1569564203","weight":6},{"id":"1569566821","weight":7},{"id":"1569556713","weight":9},{"id":"1569566751","weight":4},{"id":"1569566467","weight":6},{"id":"1569565771","weight":4},{"id":"1569566157","weight":4},{"id":"1569560613","weight":2},{"id":"1569566903","weight":5},{"id":"1569566999","weight":3},{"id":"1569565859","weight":5},{"id":"1569565809","weight":4},{"id":"1569566843","weight":6},{"id":"1569566579","weight":4},{"id":"1569558483","weight":7},{"id":"1569566563","weight":8},{"id":"1569566089","weight":2},{"id":"1569559221","weight":3},{"id":"1569556091","weight":2},{"id":"1569565347","weight":10},{"id":"1569566925","weight":8},{"id":"1569564387","weight":3},{"id":"1569565455","weight":3},{"id":"1569566497","weight":7},{"id":"1569566795","weight":2},{"id":"1569566963","weight":5},{"id":"1569561679","weight":5},{"id":"1569566709","weight":3},{"id":"1569564989","weight":3},{"id":"1569566787","weight":2},{"id":"1569560721","weight":5},{"id":"1569566015","weight":3},{"id":"1569566523","weight":3},{"id":"1569565897","weight":6},{"id":"1569551763","weight":4},{"id":"1569565953","weight":4},{"id":"1569566895","weight":2},{"id":"1569566889","weight":2},{"id":"1569565709","weight":4},{"id":"1569566749","weight":2},{"id":"1569566269","weight":6},{"id":"1569564189","weight":8},{"id":"1569564195","weight":2},{"id":"1569561513","weight":8},{"id":"1569566985","weight":5},{"id":"1569564613","weight":2},{"id":"1569567009","weight":6},{"id":"1569566865","weight":2},{"id":"1569565321","weight":3},{"id":"1569558785","weight":3},{"id":"1569564647","weight":3},{"id":"1569566095","weight":3},{"id":"1569566193","weight":3},{"id":"1569564271","weight":8},{"id":"1569564337","weight":6},{"id":"1569565907","weight":4},{"id":"1569566343","weight":3},{"id":"1569564311","weight":2},{"id":"1569565803","weight":4},{"id":"1569565785","weight":5},{"id":"1569566239","weight":2},{"id":"1569566167","weight":35},{"id":"1569566679","weight":10},{"id":"1569565989","weight":3},{"id":"1569566575","weight":5},{"id":"1569563981","weight":6},{"id":"1569561085","weight":5},{"id":"1569566419","weight":4},{"id":"1569566617","weight":2},{"id":"1569559565","weight":9},{"id":"1569566905","weight":7},{"id":"1569566733","weight":2},{"id":"1569566753","weight":3},{"id":"1569563307","weight":7},{"id":"1569566063","weight":7},{"id":"1569558681","weight":4},{"id":"1569566759","weight":6},{"id":"1569565589","weight":2},{"id":"1569559195","weight":5},{"id":"1569566149","weight":12},{"id":"1569559995","weight":2},{"id":"1569566657","weight":13},{"id":"1569558859","weight":6},{"id":"1569565213","weight":3},{"id":"1569565365","weight":2},{"id":"1569566643","weight":2},{"id":"1569566511","weight":9},{"id":"1569566719","weight":5},{"id":"1569566991","weight":28},{"id":"1569565841","weight":2},{"id":"1569566369","weight":5},{"id":"1569566531","weight":5},{"id":"1569567665","weight":4},{"id":"1569561143","weight":9},{"id":"1569566581","weight":7},{"id":"1569565833","weight":3},{"id":"1569566489","weight":4},{"id":"1569564611","weight":3},{"id":"1569565535","weight":4},{"id":"1569562867","weight":7},{"id":"1569566395","weight":4},{"id":"1569565667","weight":2},{"id":"1569561795","weight":2},{"id":"1569566845","weight":5},{"id":"1569566325","weight":5},{"id":"1569566423","weight":2},{"id":"1569564795","weight":4},{"id":"1569567015","weight":6},{"id":"1569559805","weight":4},{"id":"1569566437","weight":6},{"id":"1569566811","weight":2},{"id":"1569566851","weight":2},{"id":"1569558901","weight":3},{"id":"1569565735","weight":2},{"id":"1569553909","weight":2},{"id":"1569559111","weight":4},{"id":"1569566687","weight":3},{"id":"1569564881","weight":3},{"id":"1569566939","weight":3},{"id":"1569553537","weight":7},{"id":"1569565427","weight":7},{"id":"1569566403","weight":3},{"id":"1569565839","weight":4},{"id":"1569565915","weight":6},{"id":"1569552251","weight":7},{"id":"1569566139","weight":2},{"id":"1569553519","weight":5},{"id":"1569567051","weight":2},{"id":"1569566885","weight":3},{"id":"1569564441","weight":2},{"id":"1569566231","weight":2},{"id":"1569564209","weight":2},{"id":"1569554689","weight":2},{"id":"1569566513","weight":2},{"id":"1569566425","weight":4},{"id":"1569554881","weight":3},{"id":"1569554971","weight":9},{"id":"1569565501","weight":7},{"id":"1569566899","weight":4},{"id":"1569566445","weight":5},{"id":"1569566209","weight":11},{"id":"1569562821","weight":2},{"id":"1569566791","weight":4},{"id":"1569565559","weight":19},{"id":"1569566371","weight":9},{"id":"1569565655","weight":6},{"id":"1569566909","weight":2},{"id":"1569566127","weight":8},{"id":"1569565151","weight":2},{"id":"1569558985","weight":7},{"id":"1569563763","weight":10},{"id":"1569565087","weight":2},{"id":"1569566473","weight":6},{"id":"1569564857","weight":5},{"id":"1569564333","weight":2},{"id":"1569566913","weight":25},{"id":"1569566809","weight":4},{"id":"1569566629","weight":5},{"id":"1569566257","weight":3},{"id":"1569565033","weight":4},{"id":"1569566447","weight":5},{"id":"1569566357","weight":3},{"id":"1569565817","weight":5},{"id":"1569565847","weight":13},{"id":"1569564353","weight":2},{"id":"1569563897","weight":3},{"id":"1569557083","weight":2},{"id":"1569565887","weight":5},{"id":"1569565929","weight":5},{"id":"1569566141","weight":8},{"id":"1569553591","weight":2},{"id":"1569565055","weight":2},{"id":"1569564677","weight":2},{"id":"1569563231","weight":5},{"id":"1569565633","weight":5},{"id":"1569565279","weight":5},{"id":"1569555879","weight":5},{"id":"1569566115","weight":4},{"id":"1569565219","weight":4},{"id":"1569558509","weight":6},{"id":"1569554759","weight":5},{"id":"1569564851","weight":3},{"id":"1569565595","weight":8},{"id":"1569565185","weight":5},{"id":"1569556671","weight":2},{"id":"1569566773","weight":5},{"id":"1569564985","weight":4},{"id":"1569565095","weight":2},{"id":"1569566223","weight":4},{"id":"1569558401","weight":6},{"id":"1569566553","weight":3},{"id":"1569564973","weight":5},{"id":"1569565469","weight":3},{"id":"1569564969","weight":7},{"id":"1569566593","weight":2},{"id":"1569565029","weight":5},{"id":"1569565357","weight":3},{"id":"1569561245","weight":3},{"id":"1569566505","weight":3},{"id":"1569565393","weight":3},{"id":"1569565933","weight":8},{"id":"1569562207","weight":4},{"id":"1569565705","weight":2},{"id":"1569566191","weight":6},{"id":"1569567033","weight":9},{"id":"1569565527","weight":7},{"id":"1569566603","weight":6},{"id":"1569565363","weight":2},{"id":"1569566159","weight":4},{"id":"1569566695","weight":2},{"id":"1569566051","weight":7},{"id":"1569561379","weight":3},{"id":"1569561123","weight":6},{"id":"1569566655","weight":3},{"id":"1569566673","weight":4},{"id":"1569567235","weight":3},{"id":"1569565739","weight":2},{"id":"1569565311","weight":5},{"id":"1569566233","weight":7},{"id":"1569566667","weight":4},{"id":"1569566297","weight":2},{"id":"1569566893","weight":13},{"id":"1569566317","weight":3},{"id":"1569564097","weight":4},{"id":"1569560997","weight":6},{"id":"1569563845","weight":3},{"id":"1569566407","weight":2},{"id":"1569560349","weight":2},{"id":"1569566501","weight":5},{"id":"1569565741","weight":11},{"id":"1569566275","weight":4},{"id":"1569566481","weight":3},{"id":"1569565545","weight":9},{"id":"1569566857","weight":16},{"id":"1569565961","weight":2},{"id":"1569566387","weight":3},{"id":"1569566245","weight":7},{"id":"1569560503","weight":4},{"id":"1569565463","weight":5},{"id":"1569564339","weight":2},{"id":"1569566219","weight":12},{"id":"1569565439","weight":5},{"id":"1569566229","weight":5},{"id":"1569566949","weight":4},{"id":"1569566133","weight":3},{"id":"1569562551","weight":3},{"id":"1569563395","weight":2},{"id":"1569566901","weight":2},{"id":"1569551347","weight":5},{"id":"1569565415","weight":3},{"id":"1569555367","weight":2},{"id":"1569561623","weight":7},{"id":"1569566383","weight":4},{"id":"1569564485","weight":9},{"id":"1569565155","weight":2},{"id":"1569566631","weight":10},{"id":"1569565571","weight":5},{"id":"1569565885","weight":12},{"id":"1569566177","weight":7},{"id":"1569565493","weight":3},{"id":"1569557633","weight":10},{"id":"1569564411","weight":4},{"id":"1569566805","weight":4},{"id":"1569559199","weight":4},{"id":"1569566929","weight":4},{"id":"1569566293","weight":7},{"id":"1569565665","weight":4},{"id":"1569566831","weight":5},{"id":"1569565549","weight":4},{"id":"1569565523","weight":7},{"id":"1569565611","weight":9},{"id":"1569557715","weight":8},{"id":"1569564175","weight":5},{"id":"1569566983","weight":10},{"id":"1569566097","weight":7},{"id":"1569566479","weight":3},{"id":"1569556361","weight":2},{"id":"1569566431","weight":2},{"id":"1569565397","weight":5},{"id":"1569566873","weight":15},{"id":"1569565765","weight":4},{"id":"1569565925","weight":6},{"id":"1569565435","weight":7},{"id":"1569557275","weight":5},{"id":"1569565263","weight":4},{"id":"1569566129","weight":3},{"id":"1569565215","weight":4},{"id":"1569565385","weight":5},{"id":"1569565575","weight":8},{"id":"1569565919","weight":6},{"id":"1569565181","weight":4},{"id":"1569566711","weight":8},{"id":"1569565241","weight":2},{"id":"1569566927","weight":3},{"id":"1569565865","weight":2},{"id":"1569566887","weight":3},{"id":"1569565273","weight":6},{"id":"1569566267","weight":6},{"id":"1569564131","weight":5},{"id":"1569552037","weight":11},{"id":"1569564919","weight":6},{"id":"1569565511","weight":3},{"id":"1569566737","weight":9},{"id":"1569566429","weight":6},{"id":"1569561221","weight":2},{"id":"1569566917","weight":5},{"id":"1569566035","weight":3},{"id":"1569566253","weight":3},{"id":"1569565353","weight":12},{"id":"1569564683","weight":9},{"id":"1569564305","weight":6},{"id":"1569564283","weight":5},{"id":"1569564291","weight":2},{"id":"1569566691","weight":3},{"id":"1569565421","weight":7},{"id":"1569566547","weight":3},{"id":"1569566651","weight":6},{"id":"1569565177","weight":4},{"id":"1569566823","weight":4},{"id":"1569566677","weight":5},{"id":"1569565349","weight":2},{"id":"1569552025","weight":12},{"id":"1569566137","weight":5},{"id":"1569565013","weight":2},{"id":"1569565829","weight":3},{"id":"1569566283","weight":4},{"id":"1569566529","weight":5},{"id":"1569565375","weight":5},{"id":"1569566715","weight":34},{"id":"1569565237","weight":5},{"id":"1569566639","weight":3},{"id":"1569566755","weight":7},{"id":"1569566819","weight":3},{"id":"1569565041","weight":4},{"id":"1569564703","weight":7},{"id":"1569566713","weight":3},{"id":"1569565541","weight":3},{"id":"1569566813","weight":7},{"id":"1569565293","weight":4},{"id":"1569566771","weight":3},{"id":"1569564649","weight":2},{"id":"1569564201","weight":4},{"id":"1569562277","weight":5},{"id":"1569566641","weight":5},{"id":"1569565425","weight":23},{"id":"1569564247","weight":2},{"id":"1569564437","weight":8},{"id":"1569566533","weight":2},{"id":"1569563975","weight":5},{"id":"1569551905","weight":4},{"id":"1569564861","weight":8},{"id":"1569565457","weight":6},{"id":"1569564787","weight":4},{"id":"1569566487","weight":5},{"id":"1569565529","weight":11},{"id":"1569556759","weight":5},{"id":"1569566619","weight":8},{"id":"1569565271","weight":2},{"id":"1569561185","weight":5},{"id":"1569566075","weight":2},{"id":"1569566397","weight":3},{"id":"1569558779","weight":7},{"id":"1569565669","weight":2},{"id":"1569565233","weight":3},{"id":"1569563721","weight":8},{"id":"1569566001","weight":4},{"id":"1569565593","weight":10},{"id":"1569560235","weight":3},{"id":"1569566817","weight":2},{"id":"1569564157","weight":5},{"id":"1569565729","weight":3},{"id":"1569566389","weight":4},{"id":"1569566435","weight":3},{"id":"1569567483","weight":3},{"id":"1569566911","weight":2},{"id":"1569564923","weight":5},{"id":"1569565367","weight":3},{"id":"1569566299","weight":8},{"id":"1569564281","weight":2},{"id":"1569564769","weight":7},{"id":"1569565769","weight":2},{"id":"1569566601","weight":2},{"id":"1569565805","weight":4},{"id":"1569561713","weight":5},{"id":"1569566933","weight":3},{"id":"1569563919","weight":8},{"id":"1569566577","weight":4},{"id":"1569557851","weight":5},{"id":"1569567691","weight":22},{"id":"1569565389","weight":5},{"id":"1569559919","weight":10},{"id":"1569565861","weight":6},{"id":"1569566147","weight":17},{"id":"1569565537","weight":6},{"id":"1569559523","weight":2},{"id":"1569566057","weight":4},{"id":"1569562367","weight":4},{"id":"1569560785","weight":5},{"id":"1569565561","weight":4},{"id":"1569565631","weight":3},{"id":"1569560213","weight":3},{"id":"1569555891","weight":2},{"id":"1569566847","weight":7},{"id":"1569565997","weight":3},{"id":"1569563425","weight":6},{"id":"1569565035","weight":12},{"id":"1569559597","weight":5},{"id":"1569564961","weight":3},{"id":"1569559251","weight":5},{"id":"1569567013","weight":3},{"id":"1569566583","weight":5},{"id":"1569561861","weight":5},{"id":"1569565337","weight":8},{"id":"1569564253","weight":2},{"id":"1569565737","weight":4},{"id":"1569564463","weight":2},{"id":"1569565853","weight":5},{"id":"1569550425","weight":5},{"id":"1569566273","weight":8},{"id":"1569564123","weight":8},{"id":"1569566341","weight":3},{"id":"1569565889","weight":6},{"id":"1569566635","weight":6},{"id":"1569563725","weight":7},{"id":"1569551539","weight":8},{"id":"1569564505","weight":4},{"id":"1569565165","weight":2},{"id":"1569565565","weight":6},{"id":"1569565635","weight":5},{"id":"1569561397","weight":2},{"id":"1569565731","weight":5},{"id":"1569556327","weight":2},{"id":"1569566797","weight":13},{"id":"1569566125","weight":12},{"id":"1569566413","weight":4},{"id":"1569565707","weight":6},{"id":"1569565113","weight":5},{"id":"1569566375","weight":6},{"id":"1569564257","weight":7},{"id":"1569565583","weight":2},{"id":"1569566555","weight":7},{"id":"1569564931","weight":2},{"id":"1569565373","weight":2},{"id":"1569566973","weight":5},{"id":"1569561579","weight":4},{"id":"1569566449","weight":3},{"id":"1569566987","weight":2},{"id":"1569565031","weight":4},{"id":"1569564755","weight":2},{"id":"1569551541","weight":7},{"id":"1569565619","weight":2},{"id":"1569566839","weight":6},{"id":"1569551751","weight":3},{"id":"1569558697","weight":2},{"id":"1569565139","weight":5},{"id":"1569565895","weight":3},{"id":"1569566663","weight":3},{"id":"1569564419","weight":3},{"id":"1569565579","weight":4},{"id":"1569566067","weight":6},{"id":"1569566825","weight":13},{"id":"1569566615","weight":2},{"id":"1569566241","weight":2},{"id":"1569564807","weight":3},{"id":"1569566609","weight":2},{"id":"1569563007","weight":5},{"id":"1569566113","weight":14},{"id":"1569566443","weight":9},{"id":"1569566727","weight":8},{"id":"1569565315","weight":6},{"id":"1569565515","weight":2},{"id":"1569566417","weight":2},{"id":"1569560581","weight":5},{"id":"1569559233","weight":2}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S11.T9.4","endtime":"11:10","authors":"Céline Aubel, Christoph Studer, Graeme Pope, Helmut Bölcskei","date":"1341485400000","papertitle":"Sparse Signal Separation in Redundant Dictionaries","starttime":"10:50","session":"S11.T9: L1-Regularized Least Squares and Frames","room":"Stratton West Lounge (201)","paperid":"1569566611"},"cluster":{"jsonClass":"HashMap$HashTrieMap","spectral6":"3","spectral43":"24","spectral28":"12","spectral32":"16","spectral14":"4","spectral20":"0","spectral9":"6","spectral25":"2","spectral42":"34","spectral3":"1","spectral47":"20","spectral17":"4","louvain":"553","spectral36":"4","spectral39":"33","spectral10":"4","spectral15":"12","spectral33":"12","spectral5":"2","spectral21":"13","spectral44":"11","spectral26":"7","spectral40":"20","spectral8":"1","spectral11":"4","spectral4":"3","spectral37":"35","spectral48":"3","spectral22":"12","spectral23":"1","spectral12":"9","spectral50":"9","spectral19":"0","spectral34":"4","spectral45":"42","spectral7":"5","spectral49":"1","spectral38":"34","spectral24":"3","spectral13":"7","spectral31":"22","spectral29":"5","spectral35":"19","spectral30":"27","spectral41":"7","spectral27":"15","spectral18":"4","spectral46":"34","spectral2":"0","spectral16":"2"}}
