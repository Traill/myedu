{"id":"1569551535","paper":{"title":{"text":"On Optimum Strategies for Minimizing the Exponential Moments of a Loss Function"},"authors":[{"name":"Neri Merhav"}],"abstr":{"text":"Abstract\u2014We consider a general problem of minimizing the exponential moment of a given loss function, with an emphasis on the relation to the more common criterion of minimization the ﬁrst moment of the same loss function. Our basic observation is about simple sufﬁcient conditions for a strategy to be optimum in the exponential moment sense. This observation is useful and application examples are given. We also examine the asymptotic regime and investigate universal asymptotically optimum strate- gies in light of the aforementioned sufﬁcient conditions."},"body":{"text":"Many problems in information theory and related ﬁelds are about the quest for a strategy s that minimizes the expectation of a certain loss function, (X, s), where X is a random vari- able. A few examples are the following: (i) Data compression, where X symbolizes the data to be compressed, s is the data compression scheme, and (X, s) is the length function or the distortion or a linear combination of both, (iii) Bayesian estimation where X designates jointly the desired random variable and the measurements, s is the estimation function and (X, s) is the error function, (iv) Prediction, sequential decision (see, e.g., [17]) and stochastic control problems [3].\nWhile the criterion of minimizing E{ (X, s)} has been most common, the exponential moments, E exp{α (X, s)} (α > 0), have received much less attention at least in informa- tion theory and signal processing. In optimization and stochas- tic control, on the other hand, the exponential moment criterion has received much more attention, and it is well\u2013known as the risk\u2013sensitive or risk\u2013averse loss function (see, e.g., [5], [6], and references therein), where one of the main motivations is imposing a penalty that is sensitive to large values of (X, s), hence the qualiﬁer \u201crisk\u2013sensitive\u201d. Another motivation is robustness of the resulting risk\u2013sensitive optimum controllers [2], A few additional motivations for minimizing exponential moments, are the following. First, E exp{α (X, s)}, as a function of α, is the moment\u2013generating function of (X, s), and hence provides full information about the distribution of this random variable. If we ﬁnd a strategy that uniformly minimizes E exp{α (X, s)} for all α ≥ 0 (and there are examples of this), this is stronger than just minimizing the ﬁrst moment. Secondly, exponential moments are intimately related to large\u2013deviations rate functions, and are related to minimizing the probabilities of large deviations events Pr{ (X, s) ≥ L 0 } (for some threshold L 0 ). There are several\nworks along this line, especially in contexts related to buffer overﬂow in data compression [10], [11], [22], exponential moments related to guessing [1], large deviations properties of parameter/signal estimators, [4], [12] and more.\nHow can we harness the existing knowledge on optimum strategies in the ﬁrst moment sense in our quest for minimizing exponential moments? We ﬁrst furnish sufﬁcient conditions that the optimum strategy in the exponential moment sense can be found in terms of the optimum strategy in the ﬁrst moment sense. The main message of this expository paper is that the combination of these sufﬁcient conditions serves as a tool for solving concrete problems, and it gives a a new insight into these problems. In some applications, these sufﬁcient conditions for optimality yield an equation in s, whose solution is the desired optimum strategy. In other applications this may not be the case yet the optimality conditions may still be useful as one may have an intuitive guess concerning the optimum strategy, and then the optimality conditions can be used to prove optimality. A few application examples of this are given in Section 3.\nWe next study the asymptotic regime (Section 4). Consider the case where X is a random vector, X = (X 1 , . . . , X n ), gov- erned by a product\u2013form probability distribution, and (X, s) grows linearly with n for a given empirical distribution of X. In this case, the exponential moments typically behave like exponential functions of n. If we can then select a strategy s that somehow \u201cadapts\u201d to the empirical distribution of (X 1 , . . . , X n ), then such strategies may be universally asymptotically optimum in that they depend on neither the probability distribution, nor on α. This is again demonstrated in several examples.\nLet X be a random variable taking on values in an al- phabet X , and drawn from a probability distribution P . Let the variable s designate a strategy chosen from a space S. Here, the term \u201cstrategy\u201d means a mathematical object that, depending on the application, may be either a scalar, a vector, a function of X or of another random variable that depends on X. Associated with each x ∈ X and s ∈ S, is a loss (x, s). The function (x, s) is called the loss function. The operator E{·} (or E P {·}) will denote the expectation operator w.r.t.\nP , and whenever we refer to the expectation w.r.t. another probability distribution Q, we use the notation E Q {·}.\nFor a given α > 0, consider the problem of minimizing E exp{α (X, s)} across s ∈ S. The following observation relates the optimum s for this problem to the optimum s for the problem of minimizing E Q { (X, s)} w.r.t. another probability distribution Q.\nObservation 1: Assume that there exists a strategy s ∈ S for which Z(s) ∆ = E P exp{α (X, s)} < ∞. A strategy s ∈ S minimizes E P exp{α (X, s)} if there exists a prob- ability distribution Q on X that satisﬁes the following two conditions: 1) s minimizes E Q { (X, s)} over S. 2) Q(x) = P (x)e α (x,s) /Z(s).\nThe proof appears in the full version of this paper [14]. Partially related results have appeared in the literature of optimization and control (cf. [8, Theorem 4.9]). However, in [8], a much more complicated paradigm has been considered, and the results therein do not seem to be completely equivalent to Observation 1. Moreover, since the setting here is much simpler, then so is the proof, which is not only short, but also almost free of regularity conditions.\nE P exp{α (X, s)} ≡ E Q exp α (X, s) + ln P (X) Q(X)\nbecomes an equality for Q(x) = P (x)e α (x,s) /Z(s), since for this choice of Q, α (X, s) + ln P (X) Q(X) , becomes a constant with probability one. Since the left\u2013hand side is indepen- dent of Q, such an equality in Jensen\u2019s inequality means that αE Q (X, s) − D(Q P ) is maximized by Q(x) = P (x)e α(x,s) /Z(s). This leads directly to the well\u2013known identity (see, e.g., [5, Proposition 2.3]):\nwhich is also intimately related to the well\u2013known Laplace principle [7] in large deviations theory.\nIn view of eq. (2), another look at the problem of min- imizing E P exp{α (X, s)} reveals that it is equivalent 1 to the minimax problem min s max Q F (s, Q) where F (s, Q) ∆ = αE Q (X, s) − D(Q P ). Now, suppose that S and (·, ·) are such that: min s∈S max Q F (s, Q) = max Q min s∈S F (s, Q). This means that there is a saddle point (s ∗ , Q ∗ ), where s ∗ is a solution of the minimax problem and Q ∗ is a solution to the maximin problem. As mentioned above, the maxi- mizing Q in the inner maximization on the left\u2013hand side is Q ∗ (x) = P (x)e α (x,s ∗ ) /Z(s ∗ ), which is condition 2 of Observation 1. By the same token, the inner minimization over s on the right\u2013hand side obviously minimizes E Q ∗ (X, s), which is condition 1. This means then that the two conditions of Observation 1 are actually equivalent to the conditions for a saddle point of F (s, Q).\nA related criterion is max s∈S E exp{−α (X, s)} (again, with α > 0), which is called a risk\u2013seeking cost criterion.\nIf (x, s) is non-negative, this has the advantage that the exponential moment is ﬁnite for all α > 0. From the same considerations as before, here we have:\nE exp{−α (X, s)} = exp{− min\nand the optimality conditions relating s and Q are similar to those of Observation 1, except that now we have a double minimization problem. However, it should be noted that here the conditions of Observation 1 are only necessary conditions, as for the above equalities to hold, the pair (s, Q) should globally minimize the function F (s, Q), unlike the earlier case, where only a saddle point was sought. On the other hand, the advantage is that even if one cannot solve explicitly for the optimum s, then the double minimization naturally suggests an iterative algorithm.\nConsider the problem of quantizing X into M reproduction levels, ˆ x 0 , ˆ x 1 , . . . , ˆ x M −1 , and let the distortion metric be d(x, ˆ x) = (x − ˆ x) 2 . The ordinary quantizer design problem is about the choice of a function s : X → {ˆ x 0 , ˆ x 1 , . . . , ˆ x M −1 }, that minimizes E P [X − s(X)] 2 , i.e., (x, s) = [x − s(x)] 2 . As is well known [13], this problem lacks a closed\u2013form solution, and one resorts to iterative algorithms for quantizer design, which alternate between two necessary conditions for optimality: the nearest\u2013neighbor condition, according to which s(x) should be the reproduction level that is closest to x and the centroid condition, i.e., ˆ x i should be the conditional expectation of X given that X falls in the interval of values of x that are to be mapped to the i\u2013th quantization level.\nConsider the maximization of the negative exponential moment E P e −α[X−s(X)] 2 . Here the centroid condition is no longer relevant. However, one can use the fact that this problem is equivalent to the double minimization of G(s, Q) ∆ = αE Q [X − s(X)] 2 + D(Q P ) over s and Q. This suggests an iterative algorithm that consists of two nested loops: The outer loop alternates between minimizing s for a given Q, on the one hand, and minimizing Q for a given s, on the other hand. The inner loop implements the former ingredient of minimizing E Q [X − s(X)] 2 over s for a given Q, which is again implementable by the standard iterative procedure that was described in the previous paragraph.\nAs a simple example for a combination of s and Q that are matched (in the above sense), consider the case where P is the uniform distribution over [−A, +A]. The optimum MMSE quantizer is uniform as well: The interval [−A, A] is partitioned evenly into M sub-intervals, each of size 2A/M and the reproduction level ˆ x i , pertaining to each sub-interval, is its midpoint, What happens when the exponential moment is considered? Let us \u2018guess\u2019 that the same quantizer s remains optimum. Then, Q(x) is proportional to 1{|x| ≤ A} · exp{−α min i (x − ˆ x i ) 2 }, which means that Q has \u201cGaussian peaks\u201d at all reproduction points {ˆ x i }. It is plausible that\nthe same uniform quantizer s continues to be optimum (or at least nearly so) for Q, and hence these s and Q match each other. Moreover, at least for large α, this quantizer nearly attains the rate\u2013distortion function of Q at distortion level D = 1/(2α). To see why this is true, observe that for large α, the factor exp{−α min i (x − ˆ x i ) 2 } = max i exp{−α(x − ˆ x i ) 2 } is well approximated by i exp{−α(x − ˆ x i ) 2 }, which after normalization of Q, becomes a mixture of M evenly weighted Gaussians, where the i\u2013th mixture component is centered at ˆ x i , i = 0, 1, . . . , M −1. This mixture can then be viewed as a con- volution between the uniform discrete distribution on {ˆ x i } and the Gaussian density N (0, 1/(2α)). Thus, for D ≤ 1/(2α), the rate\u2013distortion function of Q agrees with the Shannon lower bound (see [14]), R L (D) = log M + 1 2 log(1/[2αD]), which, for D = 1/(2α), gives a coding rate of log M , just like the aforementioned uniform quantizer.\nFinally, consider the case where X = (X 1 , . . . , X n ) is quantized by a sequential causal quantizer with memory, i.e., X t is quantized into one of M quantization levels, which are allowed to depend on past quantizer outputs\n[X t − s(X t | ˆ X 1 , . . . , ˆ X t−1 )] 2 }. As is shown in [18], whenever P is memoryless, the allowed dependence on the past does not improve the exponential moment performance, i.e., the optimum quantizer of this type makes use of the current symbol X t only. This means that the causal vector quantization problem actually degenerates back to the scalar quantization problem considered in the previous paragraphs. This continues to be true even if variable\u2013rate coding is allowed, except that then time\u2013sharing between at most two quantizers must also be allowed. These results are analogous to those of [20] for the ordinary criterion of expected code length for a given distortion.\nLet X = (X 1 , X 2 , . . . , X n ) T be a Gaussian random vector with mean vector θu, where θ ∈ IR and u = (u 1 , . . . , u n ) T is a given deterministic vector. Let the non\u2013singular n × n covariance matrix of X be given by Λ. It is well known that for this kind of a model, among all unbiased estimators of θ, the one that minimizes the mean square error is the maximum likelihood (ML) estimator, which in this case, is given by s(x) = u T Λ −1 x/u T Λ −1 u. Does this estimator also minimize E exp{α[s(X) − θ] 2 } among all unbiased estimators and for all values of α in the allowed range?\nLet us \u2018guess\u2019 that this estimator indeed minimizes also E exp{α[s(X) − θ] 2 } and then check whether it satisﬁes the conditions of Observation 1. Denoting v = Λ −1 u/(u T Λ −1 u), the corresponding density Q, which will be denoted here by Q θ , is proportional to exp{− 1 2 (x − θu) T Λ −1 (x − θu) + α(v T x − θ) 2 }, or equivalently to exp{− 1 2 (x − θu) T (Λ −1 − 2αvv T )(x − θu)}, where α is chosen small enough such that (Λ −1 − 2αvv T ) is still positive deﬁnite. Now, the ML estimator of θ under Q θ is given by (see [14] for details):\nIn other words, we are back to s(x) which means that our \u2018guess\u2019 was successful. Indeed, the MSE of s(x) under Q θ , which is v T (Λ −1 − 2αvv T ) −1 v, can easily be shown to be identical to the Cram´er\u2013Rao lower bound under Q θ , which is given by 1/[u T (Λ −1 − 2αvv T )u]. We can therefore summarize our conclusion in the following proposition:\nProposition 1: Let X be a Gaussian random vector with a mean vector θu and a non\u2013singular covariance matrix Λ. Let a be the supremum of all values of α such that (Λ −1 − 2αvv T ) is positive deﬁnite, where v = Λ −1 u/(u T Λ −1 u). Then, among all unbiased estimators of θ, the estimator s(x) = v T x uniformly minimizes the exponential moment E exp{α[s(X) − θ] 2 } for all α ∈ (0, a).\nConsider the zero\u2013mean Gaussian memoryless source U 1 , U 2 , . . . with variance σ 2 u and the Gaussian memoryless channel y = x + z, where the noise is N (0, σ 2 z ). In the ordinary joint source\u2013channel coding problem, one seeks an encoder and decoder that minimize D = 1 n n i=1 E{(U i − V i ) 2 }, where V = (V 1 , . . . , V n ) is the reconstruction. It is well known that the minimum achievable distortion is D = σ 2 u /(1 + Γ/σ 2 z ), where Γ is the maximum power allowed and it may be achieved by a transmitter that simply ampliﬁes the source by a gain factor of Γ/σ 2 u and a receiver that implements linear MMSE estimation of U i given Y i , on a symbol\u2013by\u2013symbol basis.\nWhat if we replace the expected distortion by the criterion E exp{α i (U i −V i ) 2 }? Are the simple linear transmitter and receiver of the previous paragraph, still optimum? Our strategy s consists of the choice of an encoding function x = f (u) and a decoding function v = g(y). The class S is then the set of all pairs of functions {f, g}, where f satisﬁes the power constraint E P { f (U ) 2 } ≤ nΓ. Condition 2 of Observation 1 tells us that the modiﬁed probability distribution of u and z should be of the form\nwhere g i is restriction of g to the i\u2013th component of v. Clearly, if we continue to restrict the encoder f to be linear, with a gain of Γ/σ 2 u and the only remaining degree of freedom is the de- coder g, then we are basically dealing with a problem of pure Bayesian estimation, and then the optimum decoder continues to be the same linear decoder as before (see [19]). 2 However, once we extend the scope and allow f be a non\u2013linear encoder, then the optimum f and g would no longer remain linear like in the expected distortion case. It is not difﬁcult to see that the conditions of Observation 1 are no longer met for any linear functions f and g. The key reason is that while Q(u, z) of eq. (5) continues to be Gaussian (though now U i and Z i are correlated) when f and g are linear, the power constraint, E P { X 2 } ≤ nΓ, when expressed as an expectation w.r.t. Q, becomes E Q { f (U ) 2 P (U )/Q(U )} ≤ nΓ, but \u201cpower\u201d\nfunction f (u) 2 P (u)/Q(u), with P and Q being Gaussian densities, is no longer the usual quadratic function of f (u) for which there is a linear encoder and decoder that is optimum. More details on the optimum encoder and decoder can be found in [14].\nThe optimum strategy for minimizing E P exp{α (X, s)} depends, in general, on both P and α. It turns out, however, that this dependence can sometimes be relaxed if one gives up the quest for a strictly optimum strategy, and resorts to asymptotically optimum strategies.\nConsider the case where we have a random vector X = (X 1 , . . . , X n ), governed by P (x) = n i=1 P (x i ), where each x i takes on values in a ﬁnite set X . If (x, s) grows linearly with n for a given empirical distribution of x and a given s ∈ S, then it is expected that the exponential moment E exp{α (x, s)} would behave, at least asymptotically, as an exponential function of n. In particular, for a given s, let us assume that the limit lim n→∞ 1 n ln E P exp{α (X, s)} exists. Let us denote this limit by E(s, α, P ). An asymptotically optimum strategy is a strategy s ∗ for which E(s ∗ , α, P ) ≤ E(s, α, P ) for every s ∈ S. An asymptotically optimum strategy s ∗ is called universal asymptotically optimum w.r.t. a class P of probability distributions, if s ∗ is independent of α and P , yet it is asymptotically optimum for all α in the allowed range, every s ∈ S, and every P ∈ P. Here, we take P to be the class of all memoryless sources with a given ﬁnite alphabet X , We denote by T Q the set of all x ∈ X n whose empirical distribution is Q.\nSuppose there exists a strategy s ∗ and a function λ : P → IR such that following two conditions hold: (a) For every T Q and every x ∈ T Q , (x, s ∗ ) ≤ n[λ(Q) + o(1)], where o(1) designates a (positive) sequence that tends to zero as n → ∞. (b) For every T Q and every s ∈ S,\nIt is then straightforward to show that s ∗ is a universal asymptotically optimum strategy w.r.t. P, with E(s ∗ , α, P ) = max Q [αλ(Q) − D(Q P )], where condition (a) supports the direct part and condition (b) supports the converse part. The interesting point here is not in the last statement, but in the fact that there are many application examples where these two conditions hold at the same time.\nBefore we provide such examples, a few words are in order concerning conditions (a) and (b). Condition (a) means that there is a choice of s ∗ , that does not depend on x or on its type class, yet the performance of s ∗ , for every x ∈ T Q , \u201cadapts\u201d to the empirical distribution Q of x essentially optimally (i.e., cannot be improved signiﬁcantly), at least for a considerable (non\u2013exponential) fraction of the members of T Q . It is instructive to relate conditions (a) and (b) to conditions 1 and 2 of Observation 1. First, observe that in order to guarantee asymptotic optimality of s ∗ , condition 2 of Observation 1 can be somewhat relaxed: For Jensen\u2019s inequality in (??) to remain\nexponentially tight, it is no longer necessary to make the random variable α (X, s) + ln[P (X)/Q(X)] completely de- generate (i.e., a constant for every realization x, as in condition 2 of Observation 1), but it is enough to keep it essentially ﬁxed across a considerably large subset of the dominant type class, T Q ∗ , i.e., the one whose empirical distribution Q ∗ essentially achieves the maximum of [αλ(Q) − D(Q P )]. Taking Q ∗ (x) to be the memoryless source induced by the dominant Q ∗ , this is precisely what happens under conditions (a) and (b), which imply that\nα (x, s ∗ ) + ln P (x) Q ∗ (x)\nfor (at least) a non\u2013exponential fraction of the members of T Q ∗ , namely, a subset of T Q ∗ that is large enough to maintain the exponential order of the contribution of T Q ∗ to E exp{α (x, s ∗ )}. The combination of conditions (a) and (b) also means that s ∗ is essentially optimum for T Q ∗ , which is a reminiscence of condition 1 of Observation 1. Moreover, since s ∗ \u201cadapts\u201d to T Q , this has the ﬂavor of the maximin problem of Section 2, where s is optimized for each Q. Since the minimizing s in the maximin problem is independent of P and α, this also explains the universality property.\nThe ﬁrst example is that of ﬁxed\u2013rate rate\u2013distortion coding. A vector X from a memoryless source P is encoded by s with respect to a given additive distortion measure d : X × ˆ X → IR,\nˆ X being the reconstruction alphabet. Let D Q (R) denote the distortion\u2013rate function of a source Q (with alphabet X ) relative to d and let (x, s) designate the distortion between x and its reproduction. This example meets conditions (a) and (b) with λ(Q) = D Q (R): Condition (a) is based on the type covering lemma according to which T Q can be completely covered by essentially e nR \u2018spheres\u2019 of radius nD Q (R), centered at the reproduction vectors. Thus, s ∗ encodes x in two parts, the ﬁrst is a header that describes the index of T Q of x (whose description length is O(log n)) and the second part encodes the index of the codeword within T Q , using nR nats. Condition (b) is met since there is no way to cover T Q with exponentially less than e nR spheres within distortion less than D Q (R).\nSimilarly, consider variable\u2013rate coding within maximum distortion D. In this case, every x is encoded by (x, s) nats, and this time, conditions (a) and (b) apply with λ(Q) = R Q (D), the rate\u2013distortion function of Q. The considerations are similar to those of the ﬁrst example. It is interesting to particularize this to the case D = 0, where R Q (0) = H(Q), the empirical entropy associated with Q. Here, a more reﬁned result can be obtained, which extends the main result of [21]: Given a length function of a lossless data compression (x, s) (s being the data compression scheme), and given a parametric class of sources of n\u2013vectors, {P n θ }, indexed by a parameter θ ∈ Θ ⊂ IR k , a lower bound on E P n\nwhere > 0 is arbitrarily small (for large n), H(P n θ ) is the entropy of X associated with P n θ , and E P n\n{·} is the expectation under P n θ . On the other hand, the same expression is achievable, by a number of universal coding schemes, provided that the factor (1 − ) in the above expression is replaced by (1 + ).\nConsidering now the exponential moment criterion, as a lower bound, we have (see [14] for a full proof): ln E P n\nexp{α (X, s)} ≥ αH 1/(1+α) (P n θ ) + α(1 − ) k 2 log n, where H u (P n θ ) is R´enyi\u2019s entropy of order u. Consider now the case where {P n θ , θ ∈ Θ} is the class of all memoryless sources over X , where the parameter vector θ designates k = |X |−1 letter probabilities. In this case, since the source is completely deﬁned by the single\u2013letter probabilities, we can omit the superscript n of P n θ and denote the source by P θ . Deﬁne a two\u2013part code s ∗ , which ﬁrst encodes the index of T Q and then the index of x within T Q . Then, (x, s ∗ ) = ln |T Q | + k log n ≈ n ˆ H(x) + k 2 log n, where ˆ H(x) is the empirical entropy pertaining to x, and where the approximate inequality is easily obtained by the Stirling approximation. Then, as can be seen in [14]: ln E P θ exp{α (X, s)} ≤ nαH 1/(1+α) (P θ )+α k 2 log n. Rissanen\u2019s result is now obtained a special case by dividing both sides by α and taking the limit α → 0.\nWe next summarize these ﬁndings in the form of a theorem, which is an exponential\u2013moment counterpart of [21, Theorem 1]. The converse part (part (a)) can actually be extended to even more general classes of sources, which are not even necessarily parametric, using the results of [16], where the expression (k log n)/(2n) is replaced by the capacity of the \u201cchannel\u201d from θ to X, as deﬁned by the class of sources {P θ } when viewed as a set of conditional distributions of X given θ. For simplicity, the direct part (part (b)) of this theorem is formalized for the class of all memoryless sources with a given ﬁnite alphabet, parametrized by the letter probabilities, but it can also be extended to wider classes of sources, like Markov sources of a given order.\nTheorem 1: Converse part: Let P = {P n θ , θ ∈ Θ} be a parametric class of ﬁnite\u2013alphabet memoryless sources, indexed by a parameter θ that takes on values in a compact subset Θ of IR k . Let the central limit theorem hold, under Q n θ , for the ML estimator of each θ in the interior of Θ. If (x, s) is a length function of a code s satisfying the Kraft inequality, then for every α > 0 and > 0, 1 nα ln E P n\nexp{α (X, s)} is lower bounded by H 1/(1+α) (P n θ ) + (1 − )k(log n)/(2n) for all θ ∈ Θ except for a set A (n) ⊂ Θ whose Lebesgue measure vanishes as n → ∞.\nDirect part: For the case where P is the class of all mem- oryless sources with a given alphabet of size k + 1 and θ designates the vector of the k ﬁrst letter probabilities, there\nexists a universal lossless data compression code s ∗ , whose length function (x, s ∗ ) satisﬁes the reversed inequality where the factor (1 − ) is replaced by (1 + ).\nInteresting discussions with Rami Atar are acknowledged with thanks."},"refs":[{"authors":[{"name":"E. Arikan"},{"name":"N. Merhav"}],"title":{"text":"Guessing subject to distortion"}},{"authors":[{"name":"R. Atar"},{"name":"P. Dupuis"},{"name":"A. Shwartz"}],"title":{"text":"An escape\u2013time criterion for queue- ing networks: asymptotic risk\u2013sensitive control via differential games"}},{"authors":[{"name":"D. Bertseka"}],"title":{"text":"Dynamic Programming and Optimal Control, Vol"}},{"authors":[{"name":"J. P. N. Bishwal"}],"title":{"text":"Large deviations and Berry\u2013Esseen inequalities for estimators in nonlinear nonhomogeneous diffusions"}},{"authors":[{"name":"P. Dai Pra"},{"name":"L. Meheghini"},{"name":"W. J. Runggaldier"}],"title":{"text":"Connections between stochastic control and dynamic games"}},{"authors":[{"name":"G. B. Di Masi"},{"name":"L. Stettner"}],"title":{"text":"Risk\u2013sensitive control of discrete\u2013time Markov processes with inﬁnite horizon"}},{"authors":[{"name":"P. Dupui"},{"name":"R. S. Elli"}],"title":{"text":"A Weak Convergence Approach to the Theory of Large Deviations , John Wiley & Sons, 1997"}},{"authors":[{"name":"W. H. Fleming"},{"name":"D. Hern´andez\u2013Hern´andez"}],"title":{"text":"Risk\u2013sensitive control of ﬁnite state machines on an inﬁnite horizon I"}},{"authors":[{"name":"R. M. Gra"}],"title":{"text":"Source Coding Theory, Kluwer Academic Publishers, Nor- well, MA, U"}},{"authors":[{"name":"P. A. Humblet"}],"title":{"text":"Generalization of Huffman coding to minimize the probability of buffer overﬂow"}},{"authors":[{"name":"F. Jelinek"}],"title":{"text":"Buffer overﬂow in variable length coding of ﬁxed rate sources"}},{"authors":[{"name":"A. D. M. Kester"},{"name":"W. C. M. Kallenberg"}],"title":{"text":"Large deviations of estimators"}},{"authors":[{"name":"Y. Linde"},{"name":"A. Buzo"},{"name":"R. M. Gray"}],"title":{"text":"An algorithm for vector quantizer design"}},{"authors":[{"name":"N. Merhav"}],"title":{"text":"On optimum strategies for minimizing the exponential moments of a given cost function"}},{"authors":[{"name":"N. Merhav"},{"name":"E. Arikan"}],"title":{"text":"The Shannon cipher system with a guessing wiretapper"}},{"authors":[{"name":"N. Merhav"},{"name":"M. Feder"}],"title":{"text":"A strong version of the redundancy\u2013capacity theorem of universal coding"}},{"authors":[{"name":"N. Merhav"},{"name":"M. Feder"}],"title":{"text":"Universal prediction"}},{"authors":[{"name":"N. Merhav"},{"name":"I. Kontoyiannis"}],"title":{"text":"Source coding exponents for zero\u2013 delay coding with ﬁnite memory"}},{"authors":[{"name":"J. B. Moore"},{"name":"R. J. Elliott"},{"name":"S. Dey"}],"title":{"text":"Risk\u2013sensitive generalizations of minimum variance estimation and control"}},{"authors":[{"name":"D. L. Neuhoff"},{"name":"R. K. Gilbert"}],"title":{"text":"Causal source codes"}},{"authors":[{"name":"J. Rissanen"}],"title":{"text":"Universal coding, information, prediction, and estimation"}},{"authors":[{"name":"A. D. Wyner"}],"title":{"text":"On the probability of buffer overﬂow under an arbitrary bounded input-output distribution"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569551535.pdf"},"links":[{"id":"1569566567","weight":3},{"id":"1569564843","weight":16},{"id":"1569566381","weight":4},{"id":"1569566527","weight":11},{"id":"1569566485","weight":6},{"id":"1569565383","weight":10},{"id":"1569565883","weight":6},{"id":"1569564889","weight":5},{"id":"1569565223","weight":4},{"id":"1569566725","weight":11},{"id":"1569565663","weight":7},{"id":"1569565377","weight":18},{"id":"1569566385","weight":11},{"id":"1569567049","weight":3},{"id":"1569564635","weight":12},{"id":"1569565867","weight":6},{"id":"1569566799","weight":5},{"id":"1569565067","weight":5},{"id":"1569559665","weight":7},{"id":"1569561021","weight":5},{"id":"1569564669","weight":3},{"id":"1569565691","weight":4},{"id":"1569566815","weight":7},{"id":"1569566875","weight":6},{"id":"1569564605","weight":2},{"id":"1569559617","weight":3},{"id":"1569566981","weight":8},{"id":"1569566433","weight":5},{"id":"1569566321","weight":11},{"id":"1569566605","weight":3},{"id":"1569565489","weight":5},{"id":"1569566683","weight":14},{"id":"1569566855","weight":8},{"id":"1569560629","weight":14},{"id":"1569566869","weight":10},{"id":"1569565097","weight":10},{"id":"1569566227","weight":5},{"id":"1569566091","weight":14},{"id":"1569559259","weight":10},{"id":"1569566697","weight":6},{"id":"1569566597","weight":13},{"id":"1569565551","weight":5},{"id":"1569565711","weight":6},{"id":"1569566761","weight":5},{"id":"1569566943","weight":14},{"id":"1569565091","weight":13},{"id":"1569566591","weight":12},{"id":"1569556029","weight":4},{"id":"1569566571","weight":11},{"id":"1569552245","weight":27},{"id":"1569565607","weight":6},{"id":"1569565495","weight":4},{"id":"1569559967","weight":8},{"id":"1569567045","weight":15},{"id":"1569565227","weight":4},{"id":"1569564481","weight":15},{"id":"1569560833","weight":10},{"id":"1569566415","weight":18},{"id":"1569564805","weight":7},{"id":"1569567005","weight":11},{"id":"1569566469","weight":6},{"id":"1569566081","weight":11},{"id":"1569565355","weight":11},{"id":"1569564469","weight":6},{"id":"1569565931","weight":10},{"id":"1569566373","weight":5},{"id":"1569566647","weight":4},{"id":"1569566765","weight":25},{"id":"1569564897","weight":3},{"id":"1569565775","weight":6},{"id":"1569565547","weight":8},{"id":"1569566871","weight":7},{"id":"1569566653","weight":3},{"id":"1569565461","weight":22},{"id":"1569564245","weight":3},{"id":"1569564731","weight":9},{"id":"1569565171","weight":6},{"id":"1569566207","weight":8},{"id":"1569564227","weight":21},{"id":"1569558325","weight":7},{"id":"1569565837","weight":5},{"id":"1569566671","weight":24},{"id":"1569566303","weight":22},{"id":"1569566119","weight":2},{"id":"1569564233","weight":11},{"id":"1569566459","weight":9},{"id":"1569567535","weight":3},{"id":"1569563411","weight":24},{"id":"1569560427","weight":4},{"id":"1569564401","weight":6},{"id":"1569564849","weight":3},{"id":"1569559541","weight":9},{"id":"1569565317","weight":3},{"id":"1569566363","weight":6},{"id":"1569566319","weight":3},{"id":"1569565123","weight":8},{"id":"1569566941","weight":5},{"id":"1569566033","weight":6},{"id":"1569566739","weight":3},{"id":"1569555811","weight":10},{"id":"1569558459","weight":4},{"id":"1569565609","weight":6},{"id":"1569565291","weight":7},{"id":"1569564203","weight":10},{"id":"1569566821","weight":5},{"id":"1569556713","weight":9},{"id":"1569562685","weight":4},{"id":"1569566751","weight":7},{"id":"1569566467","weight":6},{"id":"1569565771","weight":10},{"id":"1569566157","weight":5},{"id":"1569560613","weight":6},{"id":"1569566903","weight":5},{"id":"1569566999","weight":7},{"id":"1569565859","weight":6},{"id":"1569564249","weight":2},{"id":"1569565809","weight":3},{"id":"1569566843","weight":6},{"id":"1569566579","weight":10},{"id":"1569558483","weight":10},{"id":"1569566563","weight":10},{"id":"1569566089","weight":3},{"id":"1569566173","weight":2},{"id":"1569559221","weight":4},{"id":"1569556091","weight":4},{"id":"1569565347","weight":14},{"id":"1569566925","weight":5},{"id":"1569564387","weight":7},{"id":"1569565455","weight":6},{"id":"1569566497","weight":6},{"id":"1569566795","weight":4},{"id":"1569566963","weight":13},{"id":"1569561679","weight":4},{"id":"1569566709","weight":16},{"id":"1569564989","weight":7},{"id":"1569566787","weight":2},{"id":"1569566717","weight":2},{"id":"1569560721","weight":8},{"id":"1569566015","weight":4},{"id":"1569566523","weight":6},{"id":"1569565897","weight":10},{"id":"1569551763","weight":7},{"id":"1569565953","weight":5},{"id":"1569566895","weight":4},{"id":"1569566889","weight":3},{"id":"1569565709","weight":4},{"id":"1569566749","weight":3},{"id":"1569566269","weight":8},{"id":"1569564189","weight":12},{"id":"1569564195","weight":4},{"id":"1569561513","weight":15},{"id":"1569566985","weight":17},{"id":"1569564613","weight":4},{"id":"1569565369","weight":3},{"id":"1569567009","weight":5},{"id":"1569566865","weight":5},{"id":"1569565321","weight":4},{"id":"1569558785","weight":5},{"id":"1569564647","weight":5},{"id":"1569566095","weight":15},{"id":"1569566193","weight":5},{"id":"1569564271","weight":3},{"id":"1569564337","weight":3},{"id":"1569565907","weight":9},{"id":"1569566343","weight":5},{"id":"1569564311","weight":4},{"id":"1569565803","weight":6},{"id":"1569565785","weight":8},{"id":"1569566239","weight":4},{"id":"1569566167","weight":4},{"id":"1569566679","weight":10},{"id":"1569565989","weight":5},{"id":"1569566575","weight":8},{"id":"1569563981","weight":17},{"id":"1569561085","weight":11},{"id":"1569566419","weight":5},{"id":"1569566617","weight":7},{"id":"1569559565","weight":16},{"id":"1569566905","weight":16},{"id":"1569566733","weight":3},{"id":"1569566753","weight":3},{"id":"1569566311","weight":9},{"id":"1569563307","weight":12},{"id":"1569566063","weight":6},{"id":"1569558681","weight":11},{"id":"1569555999","weight":2},{"id":"1569566759","weight":12},{"id":"1569565589","weight":17},{"id":"1569559195","weight":3},{"id":"1569566149","weight":13},{"id":"1569559995","weight":2},{"id":"1569566657","weight":10},{"id":"1569558859","weight":4},{"id":"1569565199","weight":2},{"id":"1569565213","weight":7},{"id":"1569565365","weight":3},{"id":"1569566643","weight":5},{"id":"1569566511","weight":12},{"id":"1569566719","weight":8},{"id":"1569566991","weight":3},{"id":"1569565841","weight":2},{"id":"1569566369","weight":5},{"id":"1569566531","weight":6},{"id":"1569567665","weight":14},{"id":"1569561143","weight":12},{"id":"1569566581","weight":11},{"id":"1569565833","weight":7},{"id":"1569566489","weight":8},{"id":"1569564611","weight":5},{"id":"1569565535","weight":7},{"id":"1569562867","weight":8},{"id":"1569566395","weight":8},{"id":"1569565667","weight":5},{"id":"1569561795","weight":7},{"id":"1569566845","weight":8},{"id":"1569566325","weight":10},{"id":"1569566423","weight":4},{"id":"1569565257","weight":3},{"id":"1569564795","weight":7},{"id":"1569567015","weight":12},{"id":"1569559805","weight":6},{"id":"1569566437","weight":19},{"id":"1569566811","weight":3},{"id":"1569566851","weight":23},{"id":"1569558901","weight":3},{"id":"1569565735","weight":13},{"id":"1569553909","weight":14},{"id":"1569559111","weight":9},{"id":"1569566687","weight":3},{"id":"1569562285","weight":2},{"id":"1569564881","weight":4},{"id":"1569566939","weight":8},{"id":"1569553537","weight":21},{"id":"1569565427","weight":15},{"id":"1569566403","weight":4},{"id":"1569565839","weight":4},{"id":"1569565915","weight":5},{"id":"1569552251","weight":16},{"id":"1569566139","weight":3},{"id":"1569553519","weight":9},{"id":"1569567051","weight":7},{"id":"1569566885","weight":6},{"id":"1569564441","weight":6},{"id":"1569566231","weight":7},{"id":"1569564209","weight":4},{"id":"1569554689","weight":2},{"id":"1569566513","weight":7},{"id":"1569566425","weight":6},{"id":"1569554881","weight":7},{"id":"1569554971","weight":10},{"id":"1569565501","weight":11},{"id":"1569566899","weight":7},{"id":"1569566445","weight":5},{"id":"1569566209","weight":10},{"id":"1569562821","weight":3},{"id":"1569566649","weight":3},{"id":"1569566791","weight":6},{"id":"1569565559","weight":9},{"id":"1569566371","weight":4},{"id":"1569565655","weight":17},{"id":"1569566909","weight":5},{"id":"1569566127","weight":7},{"id":"1569565151","weight":3},{"id":"1569558985","weight":9},{"id":"1569563763","weight":17},{"id":"1569565087","weight":2},{"id":"1569566473","weight":11},{"id":"1569564857","weight":5},{"id":"1569564333","weight":7},{"id":"1569566913","weight":14},{"id":"1569566809","weight":12},{"id":"1569566629","weight":8},{"id":"1569566257","weight":3},{"id":"1569565033","weight":13},{"id":"1569566447","weight":11},{"id":"1569566357","weight":4},{"id":"1569565817","weight":6},{"id":"1569565847","weight":8},{"id":"1569564353","weight":3},{"id":"1569563897","weight":3},{"id":"1569557083","weight":4},{"id":"1569565887","weight":15},{"id":"1569565929","weight":6},{"id":"1569566141","weight":8},{"id":"1569553591","weight":4},{"id":"1569566721","weight":5},{"id":"1569565055","weight":3},{"id":"1569564677","weight":2},{"id":"1569563231","weight":9},{"id":"1569565633","weight":12},{"id":"1569566661","weight":2},{"id":"1569565279","weight":4},{"id":"1569555879","weight":9},{"id":"1569565521","weight":2},{"id":"1569566115","weight":5},{"id":"1569565219","weight":12},{"id":"1569558509","weight":6},{"id":"1569554759","weight":4},{"id":"1569564851","weight":3},{"id":"1569565595","weight":6},{"id":"1569565185","weight":6},{"id":"1569566773","weight":8},{"id":"1569566037","weight":3},{"id":"1569564985","weight":6},{"id":"1569565095","weight":4},{"id":"1569566223","weight":4},{"id":"1569558401","weight":10},{"id":"1569566553","weight":6},{"id":"1569564973","weight":2},{"id":"1569565469","weight":5},{"id":"1569564969","weight":12},{"id":"1569566593","weight":2},{"id":"1569566043","weight":3},{"id":"1569565029","weight":11},{"id":"1569565357","weight":15},{"id":"1569561245","weight":5},{"id":"1569566505","weight":5},{"id":"1569565393","weight":6},{"id":"1569565933","weight":12},{"id":"1569562207","weight":12},{"id":"1569565705","weight":4},{"id":"1569566191","weight":5},{"id":"1569567033","weight":25},{"id":"1569565527","weight":7},{"id":"1569566853","weight":3},{"id":"1569566603","weight":15},{"id":"1569567029","weight":4},{"id":"1569565363","weight":8},{"id":"1569566159","weight":7},{"id":"1569566695","weight":5},{"id":"1569566051","weight":6},{"id":"1569561379","weight":5},{"id":"1569565909","weight":4},{"id":"1569561123","weight":7},{"id":"1569555787","weight":2},{"id":"1569565467","weight":5},{"id":"1569566655","weight":17},{"id":"1569566673","weight":14},{"id":"1569567235","weight":5},{"id":"1569565441","weight":4},{"id":"1569565739","weight":4},{"id":"1569565311","weight":5},{"id":"1569566233","weight":15},{"id":"1569566667","weight":6},{"id":"1569566297","weight":5},{"id":"1569566893","weight":11},{"id":"1569566317","weight":5},{"id":"1569564097","weight":4},{"id":"1569560997","weight":15},{"id":"1569563845","weight":7},{"id":"1569566407","weight":5},{"id":"1569560349","weight":6},{"id":"1569566501","weight":8},{"id":"1569565741","weight":11},{"id":"1569566275","weight":6},{"id":"1569566481","weight":8},{"id":"1569565545","weight":9},{"id":"1569566857","weight":11},{"id":"1569565961","weight":3},{"id":"1569566387","weight":6},{"id":"1569566245","weight":15},{"id":"1569560503","weight":17},{"id":"1569565463","weight":8},{"id":"1569564339","weight":2},{"id":"1569566219","weight":5},{"id":"1569565439","weight":18},{"id":"1569566229","weight":7},{"id":"1569566949","weight":3},{"id":"1569566133","weight":4},{"id":"1569562551","weight":9},{"id":"1569563395","weight":7},{"id":"1569566901","weight":6},{"id":"1569551347","weight":10},{"id":"1569565415","weight":7},{"id":"1569555367","weight":16},{"id":"1569561623","weight":8},{"id":"1569566383","weight":4},{"id":"1569564485","weight":13},{"id":"1569565155","weight":4},{"id":"1569566631","weight":11},{"id":"1569565571","weight":16},{"id":"1569565885","weight":7},{"id":"1569566177","weight":7},{"id":"1569565493","weight":5},{"id":"1569557633","weight":5},{"id":"1569564411","weight":3},{"id":"1569566805","weight":4},{"id":"1569559199","weight":4},{"id":"1569566929","weight":4},{"id":"1569566293","weight":13},{"id":"1569565665","weight":7},{"id":"1569566831","weight":10},{"id":"1569565549","weight":12},{"id":"1569565523","weight":12},{"id":"1569565611","weight":10},{"id":"1569557715","weight":6},{"id":"1569564175","weight":11},{"id":"1569566983","weight":18},{"id":"1569566779","weight":4},{"id":"1569566097","weight":6},{"id":"1569566479","weight":5},{"id":"1569556361","weight":4},{"id":"1569566431","weight":3},{"id":"1569565397","weight":7},{"id":"1569566873","weight":9},{"id":"1569565765","weight":10},{"id":"1569565925","weight":12},{"id":"1569565435","weight":5},{"id":"1569557275","weight":7},{"id":"1569565263","weight":5},{"id":"1569566129","weight":2},{"id":"1569566261","weight":3},{"id":"1569565215","weight":6},{"id":"1569565093","weight":2},{"id":"1569565385","weight":6},{"id":"1569565575","weight":8},{"id":"1569565919","weight":16},{"id":"1569565181","weight":7},{"id":"1569566711","weight":11},{"id":"1569565241","weight":5},{"id":"1569566927","weight":6},{"id":"1569565661","weight":14},{"id":"1569565865","weight":9},{"id":"1569566887","weight":5},{"id":"1569565273","weight":12},{"id":"1569566267","weight":10},{"id":"1569564131","weight":6},{"id":"1569552037","weight":6},{"id":"1569564919","weight":7},{"id":"1569565511","weight":7},{"id":"1569566737","weight":7},{"id":"1569566429","weight":5},{"id":"1569561221","weight":4},{"id":"1569564595","weight":2},{"id":"1569566917","weight":10},{"id":"1569566035","weight":9},{"id":"1569566253","weight":3},{"id":"1569565353","weight":6},{"id":"1569564683","weight":11},{"id":"1569564305","weight":14},{"id":"1569564283","weight":7},{"id":"1569564291","weight":3},{"id":"1569566691","weight":7},{"id":"1569565421","weight":10},{"id":"1569566547","weight":4},{"id":"1569566651","weight":10},{"id":"1569565177","weight":5},{"id":"1569566823","weight":9},{"id":"1569566595","weight":4},{"id":"1569566677","weight":5},{"id":"1569565349","weight":4},{"id":"1569552025","weight":14},{"id":"1569566137","weight":10},{"id":"1569565013","weight":3},{"id":"1569565829","weight":4},{"id":"1569566237","weight":4},{"id":"1569566283","weight":5},{"id":"1569565645","weight":8},{"id":"1569566529","weight":7},{"id":"1569565375","weight":16},{"id":"1569566715","weight":5},{"id":"1569565237","weight":7},{"id":"1569566639","weight":4},{"id":"1569566755","weight":6},{"id":"1569566819","weight":6},{"id":"1569565041","weight":8},{"id":"1569564703","weight":13},{"id":"1569566713","weight":4},{"id":"1569565541","weight":2},{"id":"1569565597","weight":3},{"id":"1569566813","weight":7},{"id":"1569565293","weight":4},{"id":"1569566771","weight":18},{"id":"1569564649","weight":3},{"id":"1569564201","weight":6},{"id":"1569562277","weight":4},{"id":"1569566641","weight":20},{"id":"1569565425","weight":4},{"id":"1569559035","weight":2},{"id":"1569564247","weight":5},{"id":"1569564437","weight":13},{"id":"1569566533","weight":3},{"id":"1569563975","weight":4},{"id":"1569551905","weight":9},{"id":"1569564861","weight":3},{"id":"1569565457","weight":10},{"id":"1569564787","weight":8},{"id":"1569566487","weight":10},{"id":"1569565529","weight":15},{"id":"1569556759","weight":12},{"id":"1569566619","weight":16},{"id":"1569565271","weight":2},{"id":"1569561185","weight":10},{"id":"1569566075","weight":4},{"id":"1569566397","weight":3},{"id":"1569566301","weight":2},{"id":"1569558779","weight":24},{"id":"1569565669","weight":5},{"id":"1569565233","weight":6},{"id":"1569563721","weight":6},{"id":"1569566001","weight":5},{"id":"1569565593","weight":12},{"id":"1569560235","weight":6},{"id":"1569566817","weight":9},{"id":"1569564157","weight":3},{"id":"1569565729","weight":2},{"id":"1569566389","weight":3},{"id":"1569566435","weight":5},{"id":"1569567483","weight":5},{"id":"1569566911","weight":4},{"id":"1569564923","weight":9},{"id":"1569565367","weight":6},{"id":"1569566299","weight":21},{"id":"1569564281","weight":5},{"id":"1569564769","weight":9},{"id":"1569565769","weight":5},{"id":"1569566171","weight":5},{"id":"1569566601","weight":4},{"id":"1569565805","weight":21},{"id":"1569561713","weight":4},{"id":"1569566933","weight":9},{"id":"1569563919","weight":22},{"id":"1569566577","weight":7},{"id":"1569557851","weight":13},{"id":"1569567691","weight":5},{"id":"1569565389","weight":7},{"id":"1569559919","weight":11},{"id":"1569565861","weight":3},{"id":"1569566147","weight":7},{"id":"1569565537","weight":14},{"id":"1569559523","weight":2},{"id":"1569566057","weight":4},{"id":"1569562367","weight":12},{"id":"1569560785","weight":10},{"id":"1569565561","weight":3},{"id":"1569565631","weight":4},{"id":"1569560213","weight":3},{"id":"1569566457","weight":2},{"id":"1569555891","weight":8},{"id":"1569566847","weight":3},{"id":"1569565997","weight":5},{"id":"1569563425","weight":9},{"id":"1569565035","weight":8},{"id":"1569559597","weight":13},{"id":"1569564961","weight":4},{"id":"1569559251","weight":5},{"id":"1569565089","weight":3},{"id":"1569567013","weight":4},{"id":"1569566583","weight":5},{"id":"1569561861","weight":6},{"id":"1569565337","weight":5},{"id":"1569564253","weight":3},{"id":"1569565737","weight":8},{"id":"1569560459","weight":5},{"id":"1569566807","weight":2},{"id":"1569564463","weight":6},{"id":"1569565853","weight":11},{"id":"1569550425","weight":18},{"id":"1569566273","weight":7},{"id":"1569564123","weight":10},{"id":"1569566341","weight":4},{"id":"1569565889","weight":11},{"id":"1569566635","weight":5},{"id":"1569566611","weight":11},{"id":"1569563725","weight":2},{"id":"1569551539","weight":11},{"id":"1569564505","weight":9},{"id":"1569565165","weight":8},{"id":"1569565565","weight":8},{"id":"1569565635","weight":12},{"id":"1569561397","weight":3},{"id":"1569565731","weight":6},{"id":"1569556327","weight":3},{"id":"1569566797","weight":15},{"id":"1569566125","weight":4},{"id":"1569566413","weight":8},{"id":"1569565707","weight":12},{"id":"1569565113","weight":15},{"id":"1569566375","weight":13},{"id":"1569565143","weight":7},{"id":"1569564257","weight":22},{"id":"1569565583","weight":4},{"id":"1569566555","weight":6},{"id":"1569564931","weight":8},{"id":"1569565373","weight":6},{"id":"1569564141","weight":2},{"id":"1569566973","weight":8},{"id":"1569561579","weight":12},{"id":"1569566449","weight":7},{"id":"1569566987","weight":5},{"id":"1569565031","weight":8},{"id":"1569564755","weight":4},{"id":"1569551541","weight":21},{"id":"1569565619","weight":3},{"id":"1569566839","weight":10},{"id":"1569551751","weight":7},{"id":"1569558697","weight":4},{"id":"1569565139","weight":8},{"id":"1569565895","weight":10},{"id":"1569566663","weight":6},{"id":"1569564419","weight":6},{"id":"1569565579","weight":6},{"id":"1569566067","weight":7},{"id":"1569566825","weight":15},{"id":"1569566615","weight":4},{"id":"1569566241","weight":4},{"id":"1569564807","weight":3},{"id":"1569566609","weight":2},{"id":"1569563007","weight":23},{"id":"1569566113","weight":15},{"id":"1569566443","weight":15},{"id":"1569566727","weight":18},{"id":"1569565315","weight":5},{"id":"1569565515","weight":3},{"id":"1569566417","weight":6},{"id":"1569560581","weight":10},{"id":"1569559233","weight":4}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S1.T8.1","endtime":"10:10","authors":"Neri Merhav","date":"1341222600000","papertitle":"On Optimum Strategies for Minimizing the Exponential Moments of a Loss Function","starttime":"09:50","session":"S1.T8: Information Theoretic Tools and Properties","room":"Stratton (491)","paperid":"1569551535"},"cluster":{"jsonClass":"HashMap$HashTrieMap","spectral6":"5","spectral43":"18","spectral28":"5","spectral32":"22","spectral14":"0","spectral20":"13","spectral9":"5","spectral25":"19","spectral42":"14","spectral3":"0","spectral47":"25","spectral17":"14","louvain":"232","spectral36":"7","spectral39":"1","spectral10":"1","spectral15":"5","spectral33":"16","spectral5":"4","spectral21":"10","spectral44":"9","spectral26":"1","spectral40":"33","spectral8":"6","spectral11":"10","spectral4":"2","spectral37":"30","spectral48":"5","spectral22":"4","spectral23":"12","spectral12":"2","spectral50":"41","spectral19":"14","spectral34":"22","spectral45":"32","spectral7":"0","spectral49":"27","spectral38":"1","spectral24":"22","spectral13":"10","spectral31":"3","spectral29":"1","spectral35":"33","spectral30":"26","spectral41":"1","spectral27":"25","spectral18":"2","spectral46":"0","spectral2":"0","spectral16":"5"}}
