{"id":"1569566807","paper":{"title":{"text":"Dynamic Intrusion Detection in Resource-Constrained Cyber Networks"},"authors":[{"name":"Keqin Liu"},{"name":"Qing Zhao"}],"abstr":{"text":"Abstract\u2014We consider a large-scale cyber network with N components. Each component is either in a healthy state ( 0) or an abnormal state (1). Due to intrusions, the state of each component transits from 0 to 1 over time according to an arbitrary stochastic process. At each time, a subset of K (K < N ) components are probed and those observed in abnormal states are ﬁxed. The objective is to design a dynamic probing strategy that minimizes the long-term network cost incurred at all abnormal components. We formulate the problem as a Restless Multi-Armed Bandit (RMAB) process. We show that this class of RMAB is indexable and Whittle index can be obtained in closed- form. For homogeneous networks, we show that Whittle index policy achieves the optimal performance with a simple structure that does not require any prior knowledge on the intrusion processes."},"body":{"text":"The objective of Intrusion Detection Systems (IDS) is to quickly locate malicious activities (e.g., denial of service attack, port scans, hackers) so that infected parts can be ﬁxed to minimize the overall damage to the network. With the increasing size, diversity, and interconnectivity of the cyber system, however, intru- sion detection faces the challenge of scalability: how to rapidly locate intrusions and anomalies in a large dynamic network with limited resources. The two basic approaches to intrusion detection, namely, active probing and passive monitoring [1], [2], both face stringent resource constraints when the network is large and dynamic. Speciﬁcally, active-probing based approaches need to choose judiciously which components of the network to probe to reduce overhead; passive-monitoring based approaches need to determine how to sample the network so that real-time processing of the resulting data is within the computational capacity of the IDS [3]. The problem is compounded by the fact that the adversarial behaviors are typically stochastic and evolving.\nIn this paper, we address resource-constrained intru- sion detection in large dynamic cyber networks. We consider a network with N heterogeneous components which can be paths, routers, or subnets. At a given time, a component can be in a healthy state or an abnormal state.\nAn abnormal component remains abnormal until the anomaly is detected and resolved. A healthy component may be attacked and become abnormal if the attack is successful. We consider a general attack model: the behavior of the intruder can be arbitrarily correlated in time and varies across components, and different attacks may have different success probabilities. When an abnor- mal component is probed, it is ﬁxed and returns to the healthy state. When a healthy component is probed, its state evolution (i.e., how likely it will become abnormal in each subsequent time instant) is reset. This reset process models the scenario where proactive actions are taken (patches are installed, ﬁrewalls upgraded, etc.) by the IDS to refresh the component\u2019s immunity to attacks. Note that this model is signiﬁcantly different and more complicated than the SIS (susceptible-infected- susceptible) model and its variants (see, e.g., [4]).\nFor each component in an abnormal state, a cost (depending on the criticality of the component) per unit time is incurred. At each time, the IDS can choose a subset of K components to probe, where K is often much smaller than N due to resource constraints. The question here is how to dynamically probe these N components to minimize the total long-term cost. The key is to learn from past observations and decisions and dynamically adjust the probing actions.\nWe formulate the dynamic intrusion detection prob- lem as a special class of Restless Multi-Armed Bandit (RMAB) process, where each component is considered as an arm. In 1988, Whittle generalized the classic Multi-Armed Bandit (MAB) problem to RMAB, a more powerful stochastic model to take into account arm dynamics that cannot be directly controlled [5]. While the classic MAB can be solved in linear time with respect to the number of arms [6], ﬁnding the optimal solution to a general RMAB is PSPACE-hard with exponential com- plexity [7]. Whittle proposed an index policy with linear complexity that was shown to be asymptotically (when the number of arms approaches inﬁnity) optimal under certain conditions [8], [9]. The difﬁculty of Whittle index policy lies in the complexity of establishing its existence\n(the so-called indexability) and computing the index. There is no general characterization regarding which class of RMAB is indexable and whether Whittle index can be efﬁciently computed, and little is known about the optimality of Whittle index (when it does exist) for ﬁnite-size systems. In this paper, we show that the class of RMAB at hand is indexable and Whittle index can be obtained in closed-form, leading to easy implementations of the policy. For homogeneous networks, we show that Whittle index policy is optimal for any network size N and has a simple robust structure that does not require any prior knowledge on the attack model.\nMost existing studies on intrusion detection do not consider the constraint on the system monitoring capac- ity (see, e.g., [10]\u2013[13]). Our work takes a stochastic control approach to intrusion detection in large networks with resource constraints, where the problem of adap- tively allocating the limited probing and repair power is of interest.\nIn the literature of RMAB, indexability was studied in [14] for RMAB with ﬁnite state space, where nu- merical algorithms were proposed to test indexability and compute Whittle index. Extensive numerical stud- ies in [15]\u2013[17] have demonstrated the near optimal performance of Whittle index policy. For the RMAB studied in this paper, the system state space is inﬁnite, which renders such numerical methods infeasible, even for a ﬁxed realization of system parameters. Analytical studies of indexability exist for certain special classes of RMAB [15]\u2013[24]. In particular, the indexability was established for a class of RMAB that arises in the context of dynamic spectrum access [20], [21] and multi-agent tracking systems [22]. Furthermore, in [21], Whittle index policy was shown to be optimal when arms are homogeneous by establishing its equivalence to the myopic policy and leveraging existing results on the optimality of the myopic policy given in [25]\u2013[27]. The work in [21] was extended to a more general model in [24], where the indexability, the closed-form Whittle index, and the asymptotic optimality of Whittle index policy were established.\nConsider a cyber network with N heterogeneous components that are subject to attacks over time. At each discrete time, each component is either in the healthy state ( 0) or the abnormal state (1). If an attack to a healthy component is successful, the component enters the abnormal state until it is probed and ﬁxed. We assume that different components experience statis- tically independent but not necessarily identical attack processes.\nEach attack process is a general stochastic process with arbitrary time dependencies. Consequently, the state evolution of a component is given by an arbitrary probability sequence {p n (t)} t≥0 , where p n (t) is the probability that component n is in the abnormal state at time t with t being the time elapsed since the last probing of component n. Speciﬁcally, if a component (say, component n) is probed and observed in state 0, a simple maintenance action is taken which resets its state evolution to {p n (t)} t≥0 . If component n is observed in state 1, a repair action is taken, and the component will be back to the normal state in the next time instant 1 and then evolve according to {p n (t)} t≥0 . It is easy to see that {p n (t)} t≥0 is a monotonically increasing sequence. This general model includes the i.i.d. attack process as a special case: each component is compromised with a constant probability q n (n = 1, . . . , N ) at each time. For this special attack model, the state of component n transits as a Markov chain and p n (t) = 1 − (1 − q n ) t , which monotonically converges to 1 at the geometric rate ( 1 − q n ) as t increases. In general, we do not require any speciﬁc form of {p n (t)} t≥0 .\nFor each abnormal component (say, component n), a cost c n is incurred per unit time. With limited resource, only a subset of K (K < N ) components can be probed at each time. The objective is to minimize the long-term average network cost by designing the optimal sequential probing policy.\nIn this section, we formulate the intrusion detection problem as a special class of Restless Multi-Armed Bandit (RMAB) process. The concepts of indexability and Whittle index are also introduced.\nIn a general RMAB, a player chooses K out of N independent arms to activate at each time based on the current states of all arms. At each time, the state of each arm transits according to two potentially different Markovian rules depending on whether it is made active or passive. Each arm contributes an immediate reward depending on its current state and the imposed action. The objective is to maximize the long-term average reward by optimally selecting arms to activate over time based on the arm state evolutions.\nWe need to note that the states of all arms are assumed to be fully observable and obey Markovian transition rules in an RMAB. However, for the intrusion detection problem at hand, the state ( 0/1) of each component is not observable unless it is probed, and the state\ntransition rules are non-Markovian in general. It is thus not suitable to model the component state as the arm state. By exploring the reset nature of the problem, we show in the next lemma that a sufﬁcient statistic for optimal decision making is given by the two-dimensional vector set {(i n , t n )} N n=1 , where i n ∈ {0, 1} is the last observed state of component n and t n the time elapsed since the last observation. As a consequence, we can treat (i n , t n ) as the arm state of component n, which is fully observable but with an inﬁnite dimension. In the rest of the paper, we refer to (i n , t n ) as the arm state of component n to distinguish it from the component state S n ∈ {0, 1}. We let a n ∈ {active (1), passive (0)} denote the probing action on arm n.\nLemma 1: For the intrusion detection problem, the vector set {(i n , t n )} N n=1 is a sufﬁcient statistics for optimal decision making. Furthermore, given the current probing actions and observations, the arm state (i n , t n ) of component n transits according to the following Markovian rules.\nwhere Γ(·) denotes the one-step transition of the arm state given the current arm state and action.\nNow we complete the RMAB formulation of the intru- sion detection problem by observing that the immediate reward R n (S n ) offered by component n can be modeled by −c n if it is currently in the abnormal state and 0 otherwise. Consequently, the reward maximization is equivalent to the cost minimization. The objective is to maximize the expected average reward over an inﬁnite horizon:\n1 T\nwhere π denotes a sequential probing policy and E π the expectation under π. In the rest of the paper, we use RMAB-IDS to denote this class of RMAB.\nWe now establish the optimality equation for RMAB- IDS. We consider the following strong average-reward criterion under which not only the steady-state average reward but also the transient reward starting from an arbitrary initial arm state is maximized, leading to the maximum reward growth rate.\nwhere A = {a n } N n=1 with N n=1 a n = K denotes the current probing actions, G the maximum steady- state average reward over the inﬁnite horizon, F (·) the transient reward for a given set of initial arm states, and E A [·] the expectation operator given A. Solving the optimality equation (1) using dynamic programming suffers from exponential complexity. In Sec. IV, we show that for RMAB-IDS, the linear-complexity Whittle index policy exists and can be obtained in closed-form with a near-optimal performance.\nThe key idea of Whittle index policy is to provide a subsidy for passivity to measure the attractiveness of activating an arm at its current state. Based on the strong decomposability of Whittle index, it is sufﬁcient to focus on each single arm [5].\n1) Single-Armed Bandit with Subsidy: Consider the single-armed bandit for the intrusion detection problem with only one arm/component. At each time instant, we decide whether to activate the arm or make it passive. Assume that a subsidy, denoted by λ, is gained when- ever the arm is made passive. We have the following optimality equations. For simplicity of the presentation, we drop the component index from the notations.\nwhere g and f (·) denote, respectively, the maximum steady-state average reward and the transient reward. For a given subsidy for passivity λ, the optimal policy for this single-arm problem is essentially given by an optimal partition of the arm state space i=0,1 {(i, t)} t≥1 into a passive set\nP(λ) = {(i, t) : a ∗ (i, t, λ) = 0} = {(i, t) : λ + f (i, t + 1)\nand its complement, an active set A(λ) = {(i, t) : a ∗ (i, t, λ) = 1}, where a ∗ (i, t, λ) denotes the optimal action at arm state (i, t) under subsidy λ.\n2) Indexability and Whittle Index: To deﬁne Whittle index policy, it is required that the RMAB is index- able [5].\nDeﬁnition 1: An RMAB is indexable if for each arm, the passive set P(λ) increases monotonically from the empty set φ to the entire state space i=1,2 {(i, t)} t≥1 as the subsidy λ increases from −∞ to +∞. An RMAB is strictly indexable if the states join the passive set one by one (instead of as groups) as λ continuously increases.\nGiven the indexability, the Whittle index W (i, t) of an arm state (i, t) is deﬁned as the inﬁmum subsidy λ that makes the passive action optimal at (i, t):\nW (i, t) = inf{λ : a ∗ (i, t, λ) = 0} = inf{λ : λ + f (i, t + 1)\nWhittle index is intuitive: how rewarding it is to activate the arm under a particular state is measured by the minimum subsidy λ needed to make it optimal to not activate the arm at this state.\nWhittle index policy is naturally given by playing the K arms with the largest Whittle indexes.\nIn this section, we establish the indexability of RMAB-IDS and solve for Whittle index in closed-form.\nTheorem 1: RMAB-IDS is indexable. Proof: See [28].\nGiven the indexability established in Theorem 1, we proceed to solve for the closed-form Whittle index of RMAB-IDS. For simplicity of the presentation, we focus on the case that the bandit is strictly indexable (see Deﬁnition 1), i.e., there is no tie among the Whittle indexes. A simple condition in the following is adopted to guarantee the strict indexability.\nNote that C1 is always satisﬁed under the Markovian state model (see Sec. II). As shown in the following theorem, under C1, RMAB-IDS is strictly indexable. The closed-form Whittle index function is subsequently obtained.\nTheorem 2: Under C1, RMAB-IDS is strictly index- able and the Whittle index W (·) is given below.\nThe near-optimal performance of Whittle index policy is observed through numerical examples (see Sec. VI). In Sec. V, we show that when all components are homogeneous, Whittle index policy is equivalent to the myopic policy and achieves the optimal performance.\nIn this section, we study the performance of Whittle index policy in homogeneous networks, i.e., all compo- nents have the same parameters: the probability sequence {p(t)} t≥0 and the per-unit cost c for being abnormal.\nWe ﬁrst establish the equivalence of Whittle index pol- icy with the myopic policy for homogeneous networks.\nIn general, the myopic policy chooses the K components to solely minimize the expected cost in the next slot. It is not difﬁcult to show that for homogeneous networks, the myopic policy is reduced to choosing the K components with the largest probabilities of being in the abnormal state. The myopic action ˆ A(·) as a function of the current states of all arms is thus given below.\nLemma 2: For homogeneous networks, Whittle index policy is equivalent to the myopic policy and has the following simple structure: initialize a queue in which components are ordered according to the descending or- der of their initial probabilities of being in the abnormal state. Each time we probe the K components at the head of the queue. In the next slot, these K components will be moved to the bottom of the queue while keeping those observed in state 1 a higher position than those observed in state 0.\nFrom Lemma 2, Whittle index policy can be im- plemented without knowing the system parameters {p(t)} t≥0 and c. Furthermore, Whittle index policy is optimal, as given in the following theorem.\nTheorem 3: For homogeneous networks, Whittle in- dex policy minimizes the expected total cost over a ﬁnite time horizon of an arbitrary length T (T ≥ 1). It is thus also optimal under the strong average-reward criterion over the inﬁnite time horizon.\nWe have shown that Whittle index policy is optimal in homogeneous networks. In this section, we demonstrate the near-optimal performance of Whittle index policy in heterogeneous networks.\nIn Fig. 1, we compare the performance of Whittle index policy with the optimal policy. As mentioned in Sec. I, the structure of the optimal policy for a general RMAB is unknown. The only approach is to numerically compute the optimal policy through the standard dynamic programming procedure. Due to the curse of dimensionality of dynamic programming, we can only simulate the performance of the optimal policy over a short time horizon. As shown in Fig. 1, we observe that Whittle index policy achieves a near-optimal performance.\nIn Fig. 2, we compare Whittle index policy with the myopic policy. While Whittle index policy is equivalent to the myopic policy in homogeneous networks, it out- performs the myopic policy in heterogeneous networks as demonstrated in Fig. 2.\nIn this paper, we studied the intrusion detection problem in large cyber networks under arbitrary attack processes. By adopting a general non-Markovian model of the network dynamics, we formulated the problem as a special class of RMAB. We showed that this class of RMAB is indexable and Whittle index can be solved in closed-form. This result leads to a low-complexity implementation of Whittle index policy that achieves a near-optimal performance. We further showed that for homogeneous networks, Whittle index policy can be implemented without knowing the system parameters and is optimal over both ﬁnite and inﬁnite time horizons."},"refs":[{"authors":[{"name":"S. Jajodi"},{"name":"P. Li"},{"name":"V. Swaru"},{"name":"C. Wan"}],"title":{"text":"Cyber Situational Awareness, Springer, 2009"}},{"authors":[{"name":"H. Debar"},{"name":"M. Dacier"},{"name":"A. Wespi"}],"title":{"text":"Towards A Taxonomy of Intrusion- Detection Systems"}},{"authors":[{"name":"M. Kodialam"},{"name":"T. V. Lakshman"}],"title":{"text":"Detecting Network Intrusions via Sampling"}},{"authors":[{"name":"J. C. Wierman"},{"name":"D. J. Marchette"}],"title":{"text":"Modeling Computer Virus Prevalence with a Susceptible-Infected-Susceptible Model with Reintroduction"}},{"authors":[{"name":"P. Whittle"}],"title":{"text":"Restless Bandits: Activity Allocation in a Changing World"}},{"authors":[{"name":"J. C. Gittins"}],"title":{"text":"Bandit Processes and Dynamic Allocation Indices"}},{"authors":[{"name":"C. H. Papadimitriou"},{"name":"J. N. Tsitsiklis"}],"title":{"text":"The Complexity of Optimal Queueing Network Control"}},{"authors":[{"name":"R. R. Weber"},{"name":"G. Weiss"}],"title":{"text":"On an Index Policy for Restless Bandits"}},{"authors":[{"name":"R. R. Weber"},{"name":"G. Weiss"}],"title":{"text":"Addendum to \u2019On an Index Policy for Restless Bandits"}},{"authors":[{"name":"W. Lee"},{"name":"S. J. Stolfo"}],"title":{"text":"Data Mining Approaches for Intrusion Detection"}},{"authors":[{"name":"E. Denning"}],"title":{"text":"An Intrusion-Detection Model"}},{"authors":[{"name":"M. Roesch"}],"title":{"text":"Snort-Light Weight Intrusion Detection for Networks"}},{"authors":[{"name":"A. K. Ghosh"},{"name":"A. Schwartzbard"},{"name":"M. Schats"}],"title":{"text":"Learning program behavior proﬁles for intrusion detection"}},{"authors":[{"name":"J. E. Ni˜no-Mora"}],"title":{"text":"Restless Bandits, Partial Conservation Laws and Index- ability"}},{"authors":[{"name":"K. D. Glazebrook"},{"name":"H. M. Mitchell"}],"title":{"text":"An Index Policy for a Stochastic Scheduling Model with Improving/Deteriorating Jobs"}},{"authors":[{"name":"P. S. Ansell"},{"name":"K. D. Glazebrook"},{"name":"E. Ni˜no-Mora"},{"name":"M. O\u2019Keeffe"}],"title":{"text":"Whittle\u2019s Index Policy for a Multi-Class Queueing System with Convex Holding Costs"}},{"authors":[{"name":"K. D. Glazebrook"},{"name":"D. Ruiz-Hernandez"},{"name":"C. Kirkbride"}],"title":{"text":"Some Indexable Families of Restless Bandit Problems"}},{"authors":[{"name":"N. Ehsan"},{"name":"M. Liu"}],"title":{"text":"On the Optimality of An Index Policy for Bandwidth Allocation with Delayed State Observation and Differentiated Services"}},{"authors":[{"name":"V. Raghunathan"},{"name":"V. Borkar"},{"name":"M. Cao"},{"name":"P. R. Kumar"}],"title":{"text":"Index Policies for Real-Time Multicast Scheduling for Wireless Broadcast Systems"}},{"authors":[{"name":"K. Liu"}],"title":{"text":"A Restless Bandit Formulation of Opportunistic Access: Indexablity and Index Policy"}},{"authors":[{"name":"K. Liu"},{"name":"Q. Zhao"}],"title":{"text":"Indexability of Restless Bandit Problems and Optimality of Whittle Index for Dynamic Multichannel Access"}},{"authors":[{"name":"J. Le Ny"},{"name":"M. Dahleh"},{"name":"E. Feron"}],"title":{"text":"Multi-UAV Dynamic Routing with Partial Observations using Restless Bandit Allocation Indices"}},{"authors":[{"name":"T. He"},{"name":"A. Anandkumar"},{"name":"D. Agrawal"}],"title":{"text":"Index-Based Sampling Policies for Tracking Dynamic Networks under Sampling Constraints"}},{"authors":[{"name":"K. Liu"},{"name":"R. Weber"},{"name":"Q. Zhao"}],"title":{"text":"Indexability and Whittle Index for Restless Bandit Problems Involving Reset Processes"}},{"authors":[{"name":"Q. Zhao"},{"name":"B. Krishnamachari"},{"name":"K. Liu"}],"title":{"text":"On Myopic Sensing for Multi- Channel Opportunistic Access: Structure, Optimality, and Performance"}},{"authors":[{"name":"S. H. Ahmad"},{"name":"M. Liu"},{"name":"T. Javadi"},{"name":"Q. Zhao"},{"name":"B. Krishnamachari"}],"title":{"text":"Optimality of Myopic Sensing in Multi-Channel Opportunistic Access"}},{"authors":[{"name":"S. Ahmad"},{"name":"M. Liu"}],"title":{"text":"Multi-channel Opportunistic Access: A Case of Restless Bandits with Multiple Plays"}},{"authors":[{"name":"K. Liu"},{"name":"Q. Zhao"}],"title":{"text":"Intrusion Detection in Resource-Constrained Cyber Networks: A Restless Multi-Armed Bandit Approach"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566807.pdf"},"links":[{"id":"1569566527","weight":2},{"id":"1569565377","weight":2},{"id":"1569566385","weight":2},{"id":"1569564669","weight":5},{"id":"1569566869","weight":2},{"id":"1569565097","weight":10},{"id":"1569566227","weight":5},{"id":"1569559259","weight":3},{"id":"1569566697","weight":7},{"id":"1569566591","weight":2},{"id":"1569556029","weight":3},{"id":"1569565607","weight":2},{"id":"1569565495","weight":6},{"id":"1569566415","weight":2},{"id":"1569566373","weight":4},{"id":"1569551535","weight":2},{"id":"1569565171","weight":2},{"id":"1569558325","weight":2},{"id":"1569565837","weight":3},{"id":"1569566671","weight":3},{"id":"1569564233","weight":2},{"id":"1569566459","weight":3},{"id":"1569567535","weight":2},{"id":"1569563411","weight":2},{"id":"1569559541","weight":2},{"id":"1569555811","weight":5},{"id":"1569565291","weight":2},{"id":"1569565809","weight":2},{"id":"1569566089","weight":2},{"id":"1569566173","weight":2},{"id":"1569556091","weight":2},{"id":"1569566497","weight":2},{"id":"1569561679","weight":2},{"id":"1569566709","weight":7},{"id":"1569566015","weight":3},{"id":"1569565897","weight":3},{"id":"1569566889","weight":2},{"id":"1569565369","weight":14},{"id":"1569565321","weight":2},{"id":"1569564647","weight":9},{"id":"1569566193","weight":2},{"id":"1569565907","weight":7},{"id":"1569564311","weight":3},{"id":"1569565785","weight":3},{"id":"1569565989","weight":8},{"id":"1569566575","weight":4},{"id":"1569559565","weight":2},{"id":"1569563307","weight":2},{"id":"1569566759","weight":2},{"id":"1569565589","weight":3},{"id":"1569559995","weight":2},{"id":"1569566657","weight":2},{"id":"1569565213","weight":4},{"id":"1569566643","weight":6},{"id":"1569566975","weight":11},{"id":"1569566489","weight":3},{"id":"1569565535","weight":3},{"id":"1569566325","weight":2},{"id":"1569564795","weight":3},{"id":"1569565427","weight":5},{"id":"1569564441","weight":5},{"id":"1569566231","weight":2},{"id":"1569566899","weight":17},{"id":"1569566649","weight":3},{"id":"1569566473","weight":3},{"id":"1569565033","weight":4},{"id":"1569565929","weight":2},{"id":"1569565055","weight":2},{"id":"1569566115","weight":3},{"id":"1569564851","weight":12},{"id":"1569565029","weight":2},{"id":"1569562207","weight":2},{"id":"1569565527","weight":2},{"id":"1569565363","weight":9},{"id":"1569565441","weight":6},{"id":"1569565739","weight":6},{"id":"1569560997","weight":2},{"id":"1569566481","weight":2},{"id":"1569565545","weight":2},{"id":"1569566857","weight":2},{"id":"1569566387","weight":3},{"id":"1569566229","weight":2},{"id":"1569565415","weight":3},{"id":"1569565549","weight":6},{"id":"1569557715","weight":2},{"id":"1569564175","weight":3},{"id":"1569566983","weight":3},{"id":"1569566479","weight":2},{"id":"1569566431","weight":2},{"id":"1569566261","weight":2},{"id":"1569565575","weight":12},{"id":"1569566887","weight":2},{"id":"1569566429","weight":3},{"id":"1569566917","weight":5},{"id":"1569566035","weight":2},{"id":"1569566823","weight":2},{"id":"1569566715","weight":2},{"id":"1569565041","weight":3},{"id":"1569562277","weight":2},{"id":"1569564437","weight":2},{"id":"1569565529","weight":3},{"id":"1569565233","weight":2},{"id":"1569565593","weight":3},{"id":"1569564923","weight":2},{"id":"1569566299","weight":2},{"id":"1569565769","weight":2},{"id":"1569565805","weight":2},{"id":"1569567691","weight":2},{"id":"1569559919","weight":2},{"id":"1569566147","weight":2},{"id":"1569560213","weight":4},{"id":"1569566457","weight":3},{"id":"1569566847","weight":3},{"id":"1569565089","weight":2},{"id":"1569567013","weight":2},{"id":"1569561861","weight":2},{"id":"1569564463","weight":2},{"id":"1569565853","weight":2},{"id":"1569550425","weight":4},{"id":"1569563725","weight":2},{"id":"1569566973","weight":2},{"id":"1569564509","weight":2},{"id":"1569566839","weight":2},{"id":"1569565139","weight":3},{"id":"1569566663","weight":3},{"id":"1569565579","weight":2},{"id":"1569564807","weight":2},{"id":"1569563007","weight":2},{"id":"1569566113","weight":2},{"id":"1569566443","weight":2},{"id":"1569565515","weight":2},{"id":"1569560581","weight":6}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S6.T4.1","endtime":"11:50","authors":"Keqin Liu, Qing Zhao","date":"1341315000000","papertitle":"Dynamic Intrusion Detection in Resource-Constrained Cyber Networks","starttime":"11:30","session":"S6.T4: Distributed Applications","room":"Stratton 20 Chimneys (306)","paperid":"1569566807"},"cluster":{"jsonClass":"HashMap$HashTrieMap","spectral6":"5","spectral43":"31","spectral28":"17","spectral32":"0","spectral14":"7","spectral20":"18","spectral9":"3","spectral25":"10","spectral42":"24","spectral3":"0","spectral47":"5","spectral17":"13","louvain":"213","spectral36":"30","spectral39":"11","spectral10":"0","spectral15":"0","spectral33":"19","spectral5":"4","spectral21":"7","spectral44":"41","spectral26":"9","spectral40":"3","spectral8":"1","spectral11":"6","spectral4":"2","spectral37":"15","spectral48":"16","spectral22":"19","spectral23":"13","spectral12":"6","spectral50":"10","spectral19":"1","spectral34":"16","spectral45":"30","spectral7":"5","spectral49":"14","spectral38":"35","spectral24":"2","spectral13":"8","spectral31":"5","spectral29":"11","spectral35":"20","spectral30":"0","spectral41":"23","spectral27":"3","spectral18":"17","spectral46":"35","spectral2":"1","spectral16":"9"}}
