{"id":"1569566523","paper":{"title":{"text":"Distributed Estimation in Multi-Agent Networks"},"authors":[{"name":"Lalitha Sankar"},{"name":"H. Vincent Poor"}],"abstr":{"text":"Abstract\u2014 A problem of distributed state estimation at mul- tiple agents that are physically connected and have competitive interests is mapped to a distributed source coding problem with additional privacy constraints. The agents interact to estimate their own states to a desired ﬁdelity from their (sensor) measure- ments which are functions of both the local state and the states at the other agents. For a Gaussian state and measurement model, it is shown that the sum-rate achieved by a distributed protocol in which the agents broadcast to one another is a lower bound on that of a centralized protocol in which the agents broadcast as if to a virtual CEO converging only in the limit of a large number of agents. The sufﬁciency of encoding using local measurements is also proved for both protocols."},"body":{"text":"We consider a network of K distributed agents in which each agent observes sensor measurements from a distinct part of a large interconnected physical network. Examples of such networks include cyber-physical systems, speciﬁcally the smart grid, in which an agent can be viewed as a regional operator whose power measurements are affected by those at other agents due to the physical grid connectivity. Agent k is interested in estimating the state (deﬁned as a set of system parameters; for e.g., voltages and phases in the electric grid) of its local network from its measurements, Y k , which are a function of both the local state X k and the states X l , l = k, l, k ∈ {1, 2, . . . , K} of other agents in the network where the states X k are assumed to be independent of each other.\nEstimating X k at agent k with high ﬁdelity requires the agents to interact and share data amongst themselves. While the estimate ﬁdelity is crucial to the control decisions made by the agents, in many distributed systems, for competitive reasons, the agents wish to keep their state information private. This leads to a problem of competitive privacy which captures the tradeoff between the utility to the agent (estimate ﬁdelity) that can be achieved via cooperation and the resulting privacy leakage (quantiﬁed via mutual information).\nMapping utility to distortion and privacy to leakage quanti- ﬁed via mutual information, one can abstract the competitive privacy problem as a distributed source coding problem with additional leakage constraints. The set of all achievable rate- ﬁdelity-leakage tuples determines the utility-privacy tradeoff region. In [1], we introduced and studied this problem for a two-agent interactive system with Gaussian states and noisy Gaussian measurements. We proved that side-information\n(measurements at the other agent) aware Wyner-Ziv encoding [2] at each agent achieves both the minimal rate and the minimal leakage for every choice of ﬁdelity (quantiﬁed via mean-squared distortion).\nEven without additional privacy constraints, the problem of determining the set of all rate-distortion tuples in a multi agent network is related to the distributed source coding problem [3], [4] which remains open. Furthermore, for a relatively simpler setting obtained by assuming that a central entity, often referred to as a chief executive ofﬁcer (CEO), wishes to estimate the states X k , for all k, from the transmissions of all agents, we obtain a multi-variate (vector) Gaussian CEO problem which also remains open except for speciﬁc cases [5].\nCircumventing these challenges, we focus on the rate- distortion-leakage behavior in the limit of large K for a distributed protocol in which each agent encodes its measure- ments taking into account the prior broadcasts of the other agents (henceforth referred to as progressive encoding) as well as the side-information at the other agents. We compare the performance of this protocol with a centralized protocol in which the agents broadcast their encoded messages as if to a virtual CEO. We consider a noisy Gaussian measurement model at each agent with the same level of interference from the states of the other agents. For this symmetric model, our results demonstrate that the sum-rate achieved by distributed protocol outperforms that for the centralized schemes with asymptotic convergence with K. We also prove the sufﬁciency of encoding local measurements for both protocols and present outer bounds for the per user rate and leakage.\nThe paper is organized as follows. We introduce the model and communication protocols in Section II. In Section III we develop the achievable rate-distortion-leakage tuples for both protocols as well as outer bounds. We conclude in Section IV.\nWe consider a network of K agents such that, at any time instant i, i = 1, 2, . . . , n, the measurement Y k,i at agent k, k = 1, 2, . . . , K, is related to the states X m,i , m = 1, 2, . . . , K, at the agents as follows:\nwhere the state variables X m,i ∼ N (0, σ 2 ), for all m and i are assumed to be independent and identically distributed\n(i.i.d.) and are also independent of the i.i.d. noise variables Z k,i ∼ N (0, 1). The coefﬁcient h > 0 is assumed to be ﬁxed for all time and known at all agents. We assume that the k th agent observes a sequence of n measurements Y n k = [Y k,1 Y k,2 . . . Y k,n ], for all k, prior to communications.\nUtility : For the continuous Gaussian distributed state and measurements, a reasonable metric for utility at the k th agent is the mean square error D k between the original and the estimated state sequences X n k and ˆ X n k , respectively.\nPrivacy : The measurements at each agent in conjunction with the quantized data shared by the other agents while enabling accurate estimation also leaks information about the other agents\u2019 states. We capture this leakage using mutual information.\nWe assume that each agent broadcasts a function of its measurements (distributed procotol) to all agents and they do so in a round-robin fashion. We assume that all agents encode in one of the following two ways: i) local encoding in which each agent quantizes only its measurements; or ii) progressive encoding in which each agent encodes and transmits taking into account both its measurements and prior communications from other agents. In both cases, the agents transmit at a rate that takes into account the correlated measurements and prior communications of other agents.\nTo better understand the advantage of the above distributed procotol, we also consider the case where the agents broadcast as if communicating with a virtual central operator, say CEO, henceforth referred to as the centralized protocol. This may be viewed as the case in which the computing power at the agents is limited and the CEO shares with each agent its received messages (which are then decoded at each agent). For either protocol, the encoding can be either local or progressive. Let I p ∈ {0, 1} and I enc ∈ {0, 1} be random variables that denote the choice of protocols and encodings such that I p = 1 and I p = 0 for the distributed and centralized protocol, respectively, and I enc = 1 and I enc = 0 for the progressive and local encoding, respectively.\nFormally, the encoder at agent k maps its measurements to an index set J k where\nis the index set at the k th agent for mapping the measurement sequence, and the prior communications (progressive encod- ing), via the encoder f k , k = 1, 2, . . . K, deﬁned as\nsuch that at the end of the K broadcasts, one from each agent, the decoding function F k at the k th agent (or the CEO) is a mapping from the received message sets (both protocols) and the measurements (the distributed procotol) to that of the reconstructed sequence denoted as\nLet M k denotes the size of J k . The expected distortion D k at the k th agent is given by\nThe privacy leakage , L (l) k , about state k at agent l, l = k, is given by\nDeﬁnition 1: The utility-privacy tradeoff region is the set of all (D 1 , . . . , D k , L (2) 1 , . . . , L (K) 1 , . . . , L (1) K , . . . , L (K−1) K ) for\nwhich there exists a coding scheme given by (2)-(4) with pa- rameters (n, K, M 1 , M 2 , D 1 +ǫ, . . . , D K +ǫ, L 1 +ǫ, . . . , L K + ǫ) for n sufﬁciently large such that ǫ → 0 as n → ∞.\nWe use the following proposition, lemma, and function deﬁnition in the sequel to compute the achievable distortions and rates.\nProposition 1: For (column) vectors A and B, let K AA = var (A) = E (A − E [A]) A T − E A T \t and K AB =\nE (A − E [A]) B T − E B T denote the covariance and cross-correlation matrices, respectively. The conditional vari- ance E[var(A |B)] is then given as E[var(A|B)] = K AA −\nLemma 1: For a K × K symmetric Toeplitz matrix whose diagonal entries are all a, and off-diagonal entries are all b the determinant is (a + (K − 1) b) (a − b) (K−1) .\nProof: The determinant is obtained by the following two operations: i) add columns 2- K to column 1, and ii) subtract row 1 from each of the remaining rows.\nDeﬁnition 2: For some α, β ∈ R + , the function f 1 (k, c) ≡ α + (k − 2) β − (k − 1) c varies over k ∈ [1, K] and c ∈ R + .\nWe assume that each agent has the same distortion con- straint D. The distortion D at each agent ranges from a mini- mum achieved when it has perfect access to the measurements at all agents to a maximum achieved when it estimates using only its own measurements. From the symmetry of the model in (1), the minimal (resp. maximal) distortion achieved at each agent is the same. Let D min and D max denote the minimal and maximal distortions, respectively, at each agent. For the Gaussian model considered here with minimum mean square error (MSE) constraints, we have\nD min = E [var(X 1 |Y 1 Y 2 . . . Y K )] , and \t (8) D max = E [var(X 1 |Y 1 )] . \t (9)\nα ≡ E(Y 2 l ) = σ 2 X (1 + h (K − 1)) + 1, for all l (10a) β ≡ E(Y l Y k ) = σ 2 X 2\nNote that for large K, α → h (K − 1) σ 2 X , and β → h (K − 2) σ 2 X .\nwhere the simpliﬁcation in (13) results from the assumption of jointly Gaussian random variables. Applying Lemma 1, for\n  \n  \nA general coding strategy for this distributed source coding problem needs to take into account: a) the order of agent broadcasts; b) multiple encoding possibilities at each agent depending on whether the received data is used alongwith local measurements in encoding; c) exploiting the correlated measurements at other agents in broadcasting just sufﬁcient data for other agents to achieve their distortions; and d) mul- tiple rounds of interactions. We present a distributed encoding scheme with a single round of communication (for simplicity of analysis) in which the agents broadcast in order (the source permutation choice is irrelevant due to the symmetry of the model). The local and progressive coding schemes differ in including the received data in encoding at each agent, while the centralized and distributed protocols differ in whether they exploit the correlated measurements at the other agents.\nThe achievable distortion D in general depends on the encoding scheme chosen. Let R k and ˜ R k denote the rates for the local and progessive encoding schemes, respectively. We ﬁrst consider the progressive encoding scheme in which each agent broadcasts (to all other agents) a noisy func- tion of both its measurements and prior communications. More precisely, agent k maps its measurement and prior communication sequences to one among a set of 2 n ˜ R k ˜ U n k\n˜ U n k sequences are generated via an i.i.d distribution of ˜ U k,i for all i such that ˜ U 1,i = Y 1,i + Q 1,i and for all k > 1, ˜ U k,i = Y k,i + k−1 l=1 a k,l ˜ U l,i +Q k,i where a k,l ∈ R, and Q k,i ∼ N 0, σ 2 Q is independent of Y k,i for all k = 1, 2, . . . , K, and i = 1, 2, . . . , n.\nThe achievable distortion D at agent k as a result of estimating its state using both its measurements Y n k and the received sequences ˜ U n l , for all l = k, is such that D ∈ [D min , D max ] where D max is achieved when U n l = 0 for all l and D = D min for σ 2 Q = 0. On the other hand, for the local encoding scheme, let U k,i = Y k,i + Q k,i , for all k and i, such that agent k maps only its measurement sequences to one among a set of 2 nR k U n k sequences chosen to satisfy the distortion constraints.\nTheorem 1: The sets D of all achievable distortions D for the local and progressive encoding schemes for the distributed protocol are the same.\nProof: For Gaussian codebooks and Gaussian measure- ments and from symmetry of the model, the distortion D at each agent is given by\nD = E var X 1 |Y 1 ˜ U 1 ˜ U 2 ˜ U 3 . . . ˜ U K \t (17) = E [var (X 1 |Y 1 U 1 U 2 U 3 . . . U K )] ∈ [D min , D max ] (18)\nwhere in (17) we have used that fact that ˜ U 1 = U 1 , and conditioned on U 1 ,it sufﬁces to condition on U 2 , and similarly for the remaining U k , k > 2.\nComputation of D: Using the independence of the quanti- zation noise Q k for all k, as well as the independence of Q k and X k , we have E [U k U l ] = E [Y k Y l ] = β for all l = k and E U 2 k = E Y 2 k + E Q 2 k = α + σ 2 Q . Thus, D is obtained in a manner analogous to the calculation of D min with the replacement of c 3 by c 3 + σ 2 Q . Thus, we have\n  \n  \nRate Computation : We consider a round-robin protocol in which agent 1 broadcasts a quantized function of its measure- ments and prior communications at a rate which takes into account all the side information at all other agents. Thus, the rate ˜ R 1 required is the maximal of the rates required to each agent and is given by\n˜ R 1 ≥ I( ˜ U 1 ; Y 1 ) − min I( ˜ U 1 ; Y 2 ), . . . , I( ˜ U 1 ; Y K ) (20a) = I(U 1 ; Y 1 ) − I(U 1 ; Y 2 ) = R 1 \t (20b)\nwhere (20b) follows from the symmetry of the measurement model, the fact that ˜ U 1 = U 1 , and R 1 is the minimal rate required at agent 1 for the local scheme. Next, agent 2 analogously broadcasts a function of its measurements at a\nwhere (21c) follows from h( ˜ U 2 |Y 1 ˜ U 1 ) − h( ˜ U 2 |Y 2 ˜ U 1 ) = h(U 2 |Y 1 ) − h(U 2 |Y 2 ) since U 2 − Y 2 − U 1 form a Markov chain and due to the symmetry of the model. It can be veriﬁed easily that the bound in (21c) is the minimal rate R 2 for the local encoding scheme. One can similarly show that the rate at which agent 3 broadcasts is\nwhere we have used the fact that U 3 − Y 3 − U 1 U 2 and U 1 − Y 1 − U 3 form Markov chains. Generalizing we have, for all k > 1,\nwhere the bound in (23a) is the minimal rate at which agent k is required to broadcast when it only encodes Y n k .\nCalculation of Leakage : For the proposed progressive en- coding, the leakage of the state of agent k at any other agent j = k, for all such k, j, is bounded as\nL (j) k = 1 n I(X n k ; Y n j J 1 J 2 . . . J K ), j = k \t (24a) ≥ I(X 1 ; Y 2 ˜ U 1 . . . ˜ U K ) = I(X 1 ; Y 2 U 1 . . . U K ) (24b)\n(α − σ 2 X ) f 1 (K, c 5 ) \t (24c) where (24b) is a result of the model symmetry, the code construction and typicality arguments and is omitted for brevity. The bound in (24c) follows from the relation of the code constructions for the two encoding schemes and c 5 = (β −\nTheorem 2: It is sufﬁcient to encode the local measure- ments at each agent in the distributed protocol.\nTheorem 2 follows directly from the fact that for Gaussian encoding, from (18), (23a), and (24c), we have that the set of all rate-distortion-leakage tuples achieved by the local and progressive encoding schemes is the same.\nThe sum-rate of the distributed scheme R Dist sum = K k=1 R k can be simpliﬁed as\n(25b) + 1 2 log (f 1 K, β 2 /α + σ 2 Q ) α + σ 2 Q − β\nwhere (25b) is obtained from (25a) by determining |E [var (U K |Y 1 )] | where U K−1 = [U 2 U 3 . . . U K ] T de-\nnotes a column vector of length (K − 1). By expanding E var U K−1 |Y 1 using Proposition 1, one can verify that |E [var (U K |Y 1 )] | simpliﬁes to ﬁnding the determinant of the (K − 1) × (K − 1) Toeplitz matrix with diagonal and off diagonal entries α + σ 2 Q − β 2 α and β − β 2 α , respectively, which from Lemma 1 is given by f 1 K, β 2 /α (α + σ 2 Q − β) (K−2) . One can similarly show that E [var (U 1 |Y 2 )] = α+σ 2 Q −β 2 /α.\nIn the limit of K → ∞, (K − 2) β − (K − 1) β 2 α → 0, α − β 2 /α → h, α − β → h, and therefore, the second and third log terms in (25b) scale as log (K) . Thus, in the limit, the per agent rate R = R Dist sum /K is given by\nWe now compare the distributed protocol to a centralized protocol in which each agent broadcasts at a rate intended for a (virtual) CEO, and thus, is oblivious of the correlated measurements at the other agents. Here again, the agents can use a progressive encoding scheme analogously to the distributed protocol. As in the distributed protocol, here too one can show that a local encoding scheme sufﬁces, in which agent k generates a codebook U n k whose entries U k,i are generated in an i.i.d fashion such that U k,i = Y k,i + Q k,i , Q k,i is independent of Y k,i and Q l,i , for all l = k, for all k, and for all i. The compression rates are bounded as follows. First, agent 1 transmits its quantized measurements at a rate R 1 such that for error-free decoding of U n 1 at the decoder, we require\nAgent 2 takes into account the knowledge of U n 1 at all agents and broadcasts at a rate\nNote that the agents broadcast taking into account the prior transmissions (as if to a CEO) but not the side information at the other agents. Continuing similarly, we have for all k ≥ 2,\nThe resulting sum rate R CEO sum = K k=1 R k can be simpliﬁed as\n(30) = h (U K , U K−1 . . . U 1 ) − K 2 log 2πeσ 2 Q \t (31)\nThus, the rate on average per user is R CEO = R CEO sum /K which converges in the limit of a large number of agents K to\nComparing (25b) and (32), we can verify that for every choice of σ 2 Q , and hence D, R CEO sum > R Dist sum . Furthermore, one can also show that the leakage at each agent for the centralized protocol is the same as the distributed protocol in (24) and is the same for both the local and progressive encoding schemes. The following theorem summarizes our results.\nTheorem 3: The sum-rate of the centralized protocol is strictly lower bounded by that for the distributed protocol and converges to this lower bound only in the limit of large K.\nFrom the symmetry of the model, it sufﬁces to bound the rate R 1 of agent 1 as\nR 1 ≥ 1 n H(J 1 ) ≥ 1 n I(Y n 1 ; J 1 |Y n 2 Y n 3 . . . Y n K ) \t (34) ≥ h (Y 1 |Y 2 . . . Y K ) − 1 n n\nwhere (35) results from the fact that ˆ X n 2 , . . . ˆ X n K can be esti- mated from J 1 , Y n 2 , . . . Y n K , and that conditioning on only one of the estimates is a lower bound on R 1 , and (36) results from using the fact that a jointly Gaussian distribution maximizes the differential entropy for a ﬁxed variance, from the concavity of the log function for Σ ≡ E var Y 1 | ˆ X 1 Y 2 Y 3 . . . Y K . For jointly Gaussian Y 1 , . . . , Y K , ˆ X 2 , we can write\nwhere Z ∼ N 0, σ 2 Z is independent of Y k for all k, and from symmetry, we choose the same scaling constant b in (37). For g ≡ E[ ˆ X 2 − Y 2 − bY 3 . . . − bY K 2 ] = b 2 / b 2 α + σ 2 Z ,\nwhere we have used the orthogonality of the minimum MSE estimate and the measurements, i.e., E X 1 − ˆ X 1 Y l = 0, for all l = 1, and the distortion constraint in (5).\nWith ˆ X 2 in (37), one can similarly bound L (j) 1 = L (2) 1 (from symmetry), for all j, as\nwhere g 1 ≡ E ˆ X 2 − Y 2 2 \t = (b 2 (K − 1) α + (K − 1) (K − 2) bβ/2 + σ 2−1 Z ) −1 ,\nq 1 ≡ α − g 1 b 2 β 2 (K − 1) 2 , and \t (42) q 2 = g 1 b 2 1 + (K − 2)\nRemark 2: Due to the lack of a pre-log factor K, the per- user rate R for the outer bound rapidly approaches 0 with K (relative to the inner bounds).\nThe rate R and leakage L k (for any k) as a function of K are illustrated in Fig. 1 for h = 0.5 and σ 2 Q = 6.\nWe have introduced a distributed state estimation problem among K agents with ﬁdelity and privacy constraints. We have shown that the sum-rate and per user rate achieved from a distributed protocol in which the agents directly interact taking into account the prior knowledge at all agents lower bounds those achieved by a centralized protocol with convergence for very large K. Tighter outer bounds that account for the distributed coding are much needed."},"refs":[{"authors":[{"name":"L. Sankar"},{"name":"S. Kar"},{"name":"R. Tandon"},{"name":"H. V. Poor"}],"title":{"text":"Competitive privacy in the smart grid: An information-theoretic approach"}},{"authors":[{"name":"A. D. Wyner"},{"name":"J. Ziv"}],"title":{"text":"The rate-distortion function for source coding with side information at the decoder"}},{"authors":[{"name":"T. Berger"}],"title":{"text":"Multiterminal source coding"}},{"authors":[{"name":"S. Tung"}],"title":{"text":"Multiterminal rate-distortion theory"}},{"authors":[{"name":"A. B. Wagner"},{"name":"S. Tavildar"},{"name":"P. Viswanath"}],"title":{"text":"Rate region of the quadratic gaussian two-encoder source-coding problem"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566523.pdf"},"links":[{"id":"1569564843","weight":6},{"id":"1569566485","weight":3},{"id":"1569565383","weight":2},{"id":"1569564889","weight":3},{"id":"1569566725","weight":5},{"id":"1569565377","weight":4},{"id":"1569566385","weight":3},{"id":"1569564635","weight":2},{"id":"1569566799","weight":2},{"id":"1569565067","weight":3},{"id":"1569564669","weight":3},{"id":"1569565691","weight":2},{"id":"1569566981","weight":2},{"id":"1569566321","weight":2},{"id":"1569566683","weight":4},{"id":"1569566855","weight":2},{"id":"1569560629","weight":3},{"id":"1569566869","weight":3},{"id":"1569565097","weight":2},{"id":"1569566227","weight":2},{"id":"1569566091","weight":2},{"id":"1569559259","weight":3},{"id":"1569566697","weight":2},{"id":"1569566597","weight":6},{"id":"1569565711","weight":4},{"id":"1569566943","weight":5},{"id":"1569565091","weight":2},{"id":"1569566591","weight":6},{"id":"1569566571","weight":3},{"id":"1569552245","weight":6},{"id":"1569565495","weight":2},{"id":"1569567045","weight":6},{"id":"1569564481","weight":3},{"id":"1569560833","weight":2},{"id":"1569566415","weight":6},{"id":"1569564805","weight":2},{"id":"1569567005","weight":3},{"id":"1569566469","weight":2},{"id":"1569566081","weight":6},{"id":"1569565355","weight":2},{"id":"1569565931","weight":4},{"id":"1569566647","weight":2},{"id":"1569551535","weight":6},{"id":"1569566765","weight":4},{"id":"1569565547","weight":2},{"id":"1569565461","weight":8},{"id":"1569564731","weight":4},{"id":"1569566207","weight":4},{"id":"1569564227","weight":9},{"id":"1569558325","weight":2},{"id":"1569566671","weight":7},{"id":"1569566303","weight":3},{"id":"1569566119","weight":2},{"id":"1569564233","weight":3},{"id":"1569566459","weight":3},{"id":"1569567535","weight":2},{"id":"1569563411","weight":9},{"id":"1569559541","weight":3},{"id":"1569566319","weight":2},{"id":"1569565123","weight":2},{"id":"1569566941","weight":2},{"id":"1569566033","weight":4},{"id":"1569555811","weight":3},{"id":"1569558459","weight":2},{"id":"1569565609","weight":3},{"id":"1569565291","weight":4},{"id":"1569564203","weight":4},{"id":"1569566821","weight":3},{"id":"1569556713","weight":5},{"id":"1569566751","weight":2},{"id":"1569566467","weight":2},{"id":"1569566903","weight":2},{"id":"1569565859","weight":2},{"id":"1569566843","weight":2},{"id":"1569558483","weight":2},{"id":"1569566173","weight":2},{"id":"1569559221","weight":2},{"id":"1569565347","weight":4},{"id":"1569566925","weight":2},{"id":"1569564387","weight":2},{"id":"1569565455","weight":2},{"id":"1569566497","weight":2},{"id":"1569566963","weight":4},{"id":"1569566709","weight":7},{"id":"1569565897","weight":2},{"id":"1569551763","weight":2},{"id":"1569565953","weight":3},{"id":"1569566889","weight":6},{"id":"1569566269","weight":3},{"id":"1569564189","weight":6},{"id":"1569561513","weight":2},{"id":"1569566985","weight":2},{"id":"1569565321","weight":2},{"id":"1569566095","weight":3},{"id":"1569566193","weight":2},{"id":"1569565907","weight":5},{"id":"1569565785","weight":2},{"id":"1569566239","weight":3},{"id":"1569566679","weight":4},{"id":"1569565989","weight":7},{"id":"1569566575","weight":4},{"id":"1569563981","weight":9},{"id":"1569559565","weight":3},{"id":"1569566905","weight":3},{"id":"1569563307","weight":4},{"id":"1569566063","weight":3},{"id":"1569558681","weight":2},{"id":"1569566759","weight":3},{"id":"1569566149","weight":3},{"id":"1569566657","weight":6},{"id":"1569565213","weight":2},{"id":"1569565365","weight":7},{"id":"1569566511","weight":3},{"id":"1569566719","weight":2},{"id":"1569565841","weight":2},{"id":"1569566369","weight":2},{"id":"1569566531","weight":2},{"id":"1569567665","weight":3},{"id":"1569561143","weight":5},{"id":"1569566581","weight":2},{"id":"1569565833","weight":2},{"id":"1569564611","weight":3},{"id":"1569562867","weight":3},{"id":"1569561795","weight":5},{"id":"1569566845","weight":2},{"id":"1569566325","weight":3},{"id":"1569566423","weight":2},{"id":"1569564795","weight":2},{"id":"1569567015","weight":3},{"id":"1569559805","weight":3},{"id":"1569566437","weight":6},{"id":"1569566811","weight":2},{"id":"1569566851","weight":8},{"id":"1569565735","weight":5},{"id":"1569553909","weight":6},{"id":"1569559111","weight":3},{"id":"1569566939","weight":2},{"id":"1569553537","weight":7},{"id":"1569565427","weight":4},{"id":"1569566403","weight":2},{"id":"1569552251","weight":3},{"id":"1569553519","weight":4},{"id":"1569566885","weight":2},{"id":"1569564441","weight":71},{"id":"1569566513","weight":2},{"id":"1569554881","weight":4},{"id":"1569554971","weight":5},{"id":"1569565501","weight":2},{"id":"1569566209","weight":3},{"id":"1569566649","weight":2},{"id":"1569565559","weight":2},{"id":"1569566371","weight":2},{"id":"1569565655","weight":6},{"id":"1569565151","weight":6},{"id":"1569558985","weight":2},{"id":"1569563763","weight":3},{"id":"1569566473","weight":5},{"id":"1569564857","weight":2},{"id":"1569564333","weight":2},{"id":"1569566913","weight":3},{"id":"1569566629","weight":3},{"id":"1569565033","weight":4},{"id":"1569566447","weight":3},{"id":"1569565847","weight":6},{"id":"1569563897","weight":2},{"id":"1569565887","weight":5},{"id":"1569565929","weight":2},{"id":"1569566141","weight":4},{"id":"1569563231","weight":3},{"id":"1569565633","weight":6},{"id":"1569555879","weight":4},{"id":"1569566115","weight":2},{"id":"1569565219","weight":3},{"id":"1569558509","weight":3},{"id":"1569554759","weight":2},{"id":"1569565595","weight":2},{"id":"1569565185","weight":2},{"id":"1569566037","weight":2},{"id":"1569566553","weight":2},{"id":"1569564969","weight":6},{"id":"1569565029","weight":7},{"id":"1569565357","weight":42},{"id":"1569561245","weight":2},{"id":"1569565933","weight":3},{"id":"1569562207","weight":3},{"id":"1569566191","weight":3},{"id":"1569567033","weight":4},{"id":"1569565527","weight":4},{"id":"1569566603","weight":6},{"id":"1569565363","weight":2},{"id":"1569566159","weight":2},{"id":"1569566695","weight":2},{"id":"1569566051","weight":3},{"id":"1569561379","weight":2},{"id":"1569561123","weight":2},{"id":"1569566655","weight":2},{"id":"1569566673","weight":6},{"id":"1569567235","weight":2},{"id":"1569565739","weight":2},{"id":"1569565311","weight":2},{"id":"1569566233","weight":5},{"id":"1569566667","weight":2},{"id":"1569566893","weight":5},{"id":"1569566317","weight":2},{"id":"1569564097","weight":2},{"id":"1569560997","weight":5},{"id":"1569563845","weight":4},{"id":"1569560349","weight":2},{"id":"1569566501","weight":4},{"id":"1569565741","weight":5},{"id":"1569566481","weight":3},{"id":"1569565545","weight":2},{"id":"1569566245","weight":2},{"id":"1569565463","weight":2},{"id":"1569565439","weight":7},{"id":"1569566229","weight":3},{"id":"1569562551","weight":2},{"id":"1569566155","weight":4},{"id":"1569563395","weight":2},{"id":"1569555367","weight":4},{"id":"1569561623","weight":3},{"id":"1569564485","weight":2},{"id":"1569566631","weight":2},{"id":"1569565571","weight":5},{"id":"1569565885","weight":2},{"id":"1569566177","weight":2},{"id":"1569557633","weight":2},{"id":"1569559199","weight":2},{"id":"1569566293","weight":4},{"id":"1569565665","weight":2},{"id":"1569566831","weight":2},{"id":"1569565549","weight":3},{"id":"1569565523","weight":2},{"id":"1569565611","weight":4},{"id":"1569557715","weight":3},{"id":"1569564175","weight":2},{"id":"1569566983","weight":5},{"id":"1569566097","weight":3},{"id":"1569566479","weight":2},{"id":"1569565397","weight":2},{"id":"1569566873","weight":2},{"id":"1569565765","weight":5},{"id":"1569565925","weight":2},{"id":"1569565435","weight":2},{"id":"1569557275","weight":2},{"id":"1569565215","weight":2},{"id":"1569565385","weight":2},{"id":"1569565919","weight":8},{"id":"1569565181","weight":2},{"id":"1569566711","weight":5},{"id":"1569566927","weight":2},{"id":"1569565661","weight":2},{"id":"1569566887","weight":3},{"id":"1569565273","weight":2},{"id":"1569564131","weight":2},{"id":"1569564919","weight":2},{"id":"1569565511","weight":2},{"id":"1569566737","weight":2},{"id":"1569566429","weight":2},{"id":"1569566917","weight":3},{"id":"1569564683","weight":4},{"id":"1569564305","weight":6},{"id":"1569566691","weight":2},{"id":"1569565421","weight":5},{"id":"1569566651","weight":2},{"id":"1569566823","weight":2},{"id":"1569566677","weight":2},{"id":"1569552025","weight":2},{"id":"1569566137","weight":4},{"id":"1569565375","weight":6},{"id":"1569565237","weight":4},{"id":"1569564703","weight":3},{"id":"1569566813","weight":3},{"id":"1569566771","weight":8},{"id":"1569562277","weight":2},{"id":"1569566641","weight":6},{"id":"1569565425","weight":2},{"id":"1569564247","weight":3},{"id":"1569564437","weight":2},{"id":"1569551905","weight":2},{"id":"1569564861","weight":2},{"id":"1569565457","weight":3},{"id":"1569564787","weight":2},{"id":"1569566487","weight":4},{"id":"1569565529","weight":5},{"id":"1569556759","weight":6},{"id":"1569566619","weight":5},{"id":"1569561185","weight":11},{"id":"1569558779","weight":14},{"id":"1569565233","weight":2},{"id":"1569563721","weight":2},{"id":"1569565593","weight":2},{"id":"1569560235","weight":2},{"id":"1569566817","weight":5},{"id":"1569564157","weight":2},{"id":"1569566435","weight":2},{"id":"1569564923","weight":2},{"id":"1569566299","weight":8},{"id":"1569564769","weight":3},{"id":"1569565805","weight":8},{"id":"1569561713","weight":3},{"id":"1569566933","weight":2},{"id":"1569563919","weight":10},{"id":"1569557851","weight":2},{"id":"1569565389","weight":2},{"id":"1569559919","weight":3},{"id":"1569566147","weight":2},{"id":"1569565537","weight":6},{"id":"1569559523","weight":2},{"id":"1569566057","weight":2},{"id":"1569562367","weight":2},{"id":"1569560785","weight":2},{"id":"1569565561","weight":2},{"id":"1569565997","weight":2},{"id":"1569565035","weight":2},{"id":"1569559597","weight":5},{"id":"1569559251","weight":3},{"id":"1569567013","weight":3},{"id":"1569564463","weight":2},{"id":"1569565853","weight":3},{"id":"1569550425","weight":7},{"id":"1569566273","weight":3},{"id":"1569564123","weight":3},{"id":"1569565889","weight":2},{"id":"1569566611","weight":3},{"id":"1569564505","weight":4},{"id":"1569565165","weight":2},{"id":"1569565565","weight":2},{"id":"1569565635","weight":8},{"id":"1569565731","weight":2},{"id":"1569566797","weight":3},{"id":"1569565707","weight":4},{"id":"1569565113","weight":2},{"id":"1569566375","weight":2},{"id":"1569564257","weight":7},{"id":"1569566555","weight":4},{"id":"1569564931","weight":6},{"id":"1569566973","weight":2},{"id":"1569561579","weight":3},{"id":"1569566987","weight":2},{"id":"1569565031","weight":2},{"id":"1569551541","weight":6},{"id":"1569566839","weight":3},{"id":"1569551751","weight":3},{"id":"1569565139","weight":4},{"id":"1569566663","weight":3},{"id":"1569564419","weight":3},{"id":"1569566067","weight":3},{"id":"1569566825","weight":5},{"id":"1569566615","weight":2},{"id":"1569566241","weight":2},{"id":"1569563007","weight":4},{"id":"1569566113","weight":2},{"id":"1569566443","weight":4},{"id":"1569566727","weight":4},{"id":"1569560581","weight":2},{"id":"1569559233","weight":2}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S2.T8.4","endtime":"12:50","authors":"Lalitha Sankar, H. Vincent Poor","date":"1341232200000","papertitle":"Distributed Estimation in Multi-Agent Networks","starttime":"12:30","session":"S2.T8: Distributed Detection and Estimation","room":"Stratton (491)","paperid":"1569566523"},"cluster":{"jsonClass":"HashMap$HashTrieMap","spectral6":"5","spectral43":"6","spectral28":"14","spectral32":"6","spectral14":"0","spectral20":"13","spectral9":"5","spectral25":"11","spectral42":"14","spectral3":"0","spectral47":"5","spectral17":"14","louvain":"54","spectral36":"20","spectral39":"38","spectral10":"1","spectral15":"5","spectral33":"14","spectral5":"0","spectral21":"14","spectral44":"14","spectral26":"1","spectral40":"38","spectral8":"6","spectral11":"10","spectral4":"1","spectral37":"30","spectral48":"38","spectral22":"5","spectral23":"12","spectral12":"2","spectral50":"2","spectral19":"14","spectral34":"29","spectral45":"24","spectral7":"0","spectral49":"7","spectral38":"24","spectral24":"20","spectral13":"10","spectral31":"15","spectral29":"1","spectral35":"31","spectral30":"26","spectral41":"26","spectral27":"2","spectral18":"2","spectral46":"22","spectral2":"0","spectral16":"6"}}
