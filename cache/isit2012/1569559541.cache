{"id":"1569559541","paper":{"title":{"text":"On Linear Coherent Estimation with Spatial Collaboration"},"authors":[{"name":"Swarnendu Kar"},{"name":"Pramod K. Varshney"}],"abstr":{"text":"Abstract\u2014We consider a power-constrained sensor network, consisting of multiple sensor nodes and a fusion center (FC), that is deployed for the purpose of estimating a common random parameter of interest. In contrast to the distributed framework, the sensor nodes are allowed to update their individual observations by (linearly) combining observations from neighboring nodes. The updated observations are communicated to the FC using an analog amplify-and-forward modulation scheme and through a coherent multiple access channel. The optimal collaborative strategy is ob- tained by minimizing the cumulative transmission power subject to a maximum distortion constraint. For the distributed scenario (i.e., with no observation sharing), the solution reduces to the power- allocation problem considered by Xiao et. al. [1]. Collaboration among neighbors signiﬁcantly improves power efﬁciency of the network in the low local-SNR regime, as demonstrated through an insightful example and numerical simulations."},"body":{"text":"Wireless sensor networks consist of spatially distributed battery-powered sensors that monitor certain environmental con- ditions and often cooperate to perform speciﬁc signal processing tasks like detection, estimation and classiﬁcation [2]. In this paper, we consider a network that is deployed for the purpose of estimating a common random parameter of interest. After observing noisy versions of the parameter, the sensors can share their observations among other neighboring nodes, an act referred to as collaboration in this paper (following [3]). The observations from all the neighbors are linearly combined and then transmitted to the fusion center (FC) through a coherent MAC channel. The FC receives the noise-corrupted signal and makes the ﬁnal inference. The schematic diagram of such a system is shown in Figure 1 (we will introduce the notations and describe each block later in Section II).\nThe individual sensor nodes are battery powered and hence the network, as a whole, is highly power limited. In the absence\nof a power limit, the sensors could ideally collaborate with all the other nodes, make the inference in the network, and transmit the estimated parameter to the FC without any further distortion (by using inﬁnite transmission power). However, in the presence of a strict power constraint, both collaboration and transmission have to be performed judiciously, so as to maximize the quality of inference at the FC. In this paper, we study the tradeoff between cumulative transmission power and the quality of inference for a given collaborative neighborhood. We assume cost-free collaboration, i.e., the power required to share observations within the neighborhood is negligibly small compared to the power required to communicate with the FC. In an extended version of this paper, we would address the more general problem where collaboration incurs a ﬁnite cost.\nIn the absence of collaboration, this problem is the same as distributed estimation , which has been extensively researched - both from analog [1],[4] and digital [5],[6] encoding perspec- tives. When the parameter to be estimated is a scalar, as in our case, much of the problem formulation is similar to distributed beamforming in relay networks [7],[8]. However, research re- garding collaborative estimation is relatively nascent. When the transmission channels are orthogonal and cost-free collaboration is possible within a fully connected sensor network, it has been shown in [3] that it is optimal to perform the inference in the network and use the best available channel to transmit the estimated parameter. In this paper, we study the optimal collaboration design for the partially connected network and coherent MAC channel .\nWe consider the scenario where the parameter of interest is a scalar random variable with known statistics, speciﬁcally, Gaussian distributed with zero mean and variance η 2 . The obser- vations at the sensor nodes n = 1, 2, . . . , N are governed by the linear model x n = h n θ + n , where h n is the source attenuation and w n is the measurement noise. Let h = [h 1 , h 2 , . . . , h N ] T . The measurement noise vector = [ 1 , 2 , . . . , N ] T is assumed to be zero-mean, Gaussian with (spatial) covariance E[ T ] = Σ. Perfect knowledge of the observation model parameters {h n } N n=1 and Σ is assumed. In vector notation, the observation model is\nwhere x = [x 1 , x 2 , . . . , x N ] T denotes the vector of observations. We consider an extension of the analog amplify-and-forward\nscheme as our encoding and modulation framework for commu- nication to the fusion center. In the basic amplify-and-forward scheme, each node transmits a weighted version of its own observation, say W n x n , with resulting power W 2 n E[x 2 n ]. Such a scheme is appealing and often-used (e.g., [4], [1], [3]) due to two reasons, 1) Uncoded nature: Does not require block\ncoding across time and hence efﬁcient for low-latency systems, 2) Optimal: For a memoryless Gaussian source transmitted through an AWGN channel (Figure 1 with N = 1), an amplify- and-forward scheme helps achieve the optimal power-distortion tradeoff in an information-theoretic sense (see Example 2.2 in [9]). The optimality of linear coding has also been established [10] for distributed estimation over a coherent MAC (Figure 1 without spatial collaboration) when the observation noise is spatially uncorrelated.\nLet the availability of collaborative links among the various nodes be represented by the N × N adjacency matrix (not necessarily symmetric) A, where A ij ∈ {0, 1}. An entry A ij = 1 signiﬁes that node j shares its observations with node i. Sharing of this observation is assumed to be realized through a reliable communication link that consumes power C i,j , regardless of the actual value of observation. The N × N matrix C describes all the costs of collaboration among various sensors and is assumed to be known. Since each node is trivially connected to itself, A ii = 1 and C ii = 0. We denote the set of all A-sparse matrices as\nCorresponding to an adjacency matrix A and an A-sparse matrix W , we deﬁne collaboration in the network as individual nodes being able to linearly combine local observations from other collaborating nodes, z n = \t j:A\nW nj x j . In effect, the network is able to achieve a one-shot spatial transformation W : x → z of the form\nWe would refer to W as the collaboration matrix. It may be noted that, 1) Particularization: When W is a diagonal matrix (equivalently, A is the identity matrix I N ), our collaborative scheme simpliﬁes to the basic amplify-and-forward strategy [1], 2) Collaboration cost: Any collaboration involving W ∈ S A is achieved at the expense of (cumulative) power\nand 3) Transmission cost: The (cumulative) power required for transmission of encoded message z is\nThe transformed observations z are assumed to be transmitted to the fusion center through a coherent-MAC channel. In prac- tice, a coherent MAC channel can be realized through transmit beamforming [11], where sensor nodes simultaneously transmit a common message (in our case, all z k -s are scaled versions of a common θ) and the phases of their transmissions are controlled so that the signals constructively combine at the FC. The channel gain at node n is assumed to be g n and the noise of the coherent- MAC channel u is assumed to be a zero-mean AWGN with variance ξ 2 . Perfect knowledge of the channel state {g n } N n=1 and ξ 2 is assumed. Let g = [g 1 , g 2 , . . . , g N ]. The output of the coherent-MAC channel (or the input to the fusion center) is\nan accurate estimate θ of the original random parameter θ. We consider the mean square error (MSE) as the distortion metric D W E θ, ,u (θ − θ) 2 ; W . Since the measurement model is (conditionally) linear and Gaussian (see (1), (3) and (6)),\nE θ, ,u [θ |y] is used as the optimum fusion rule. It is well known that MMSE attains the posterior Cram´er-Rao lower bound,\nwhere J W denotes the (conditional) Fisher information. It may be noted here that, for the centralized case, i.e., where all the observations x are directly available at the FC, the benchmark performance is,\nThe design of the the collaboration matrix W is critical since it affects both the power requirements and estimation performance of the entire application. Speciﬁcally, the following quantities depend on W , 1) the resources required to collabo- rate, Q nz (W ) 1 , as described in (4), 2) the resources required to transmit, P W , as described in (5) and 3) the ﬁnal distortion of the estimate at the FC, D W , provided by (8). In this paper, we address the problem of designing the optimum collaboration matrix subject to a (cumulative) power constraint,\nwhere P denotes the (cumulative) power available in the net- work. It should be noted that, in addition to a cumulative power constraint, there may be individual power constraints corresponding to the various sensor nodes. However, we do not address the individual power constraints in this paper and this issue remains a worthy topic for future research.\nProblem (10), in general, has no known globally optimal solution. However, for the special case when the entries of the collaboration cost matrix C are either zero or inﬁnity, C ij ∈ {0, ∞}, we will show that there exists a unique solution for which a closed-form solution can be derived . Physically, this special case corresponds to the situation when the topol- ogy of a network is ﬁxed (and hence not subject to design) and communication among neighbors are relatively inexpensive compared to communication with the FC. Let A = zero(C) denote the permitted adjacency matrix for such a situation. Hence, the collaboration cost vanishes, Q A = 0, and problem (10) simpliﬁes to,\ncost for collaboration, we would refer to (11) as the ideal- collaborative power-allocation problem. As regards the more general case (problem (10) for arbitrary costs C and the topol- ogy being subject to design), one can start from the distributed topology A = I, and follow a greedy algorithm and augment the collaborative topology with the most power-efﬁcient link at each iteration. This extension is not discussed in this paper due to space constraints and will be relegated to an extended version of this paper.\nFrom (8), we note that minimizing the distortion D W is equivalent to maximizing the (conditional) Fisher information J W . Hence problem (11) is equivalent to,\nSince multiplying W by a scalar α > 1 (strictly) increases both J W and P W (and for α < 1, strictly decreases them), problem (12) is equivalent to its converse formulation, where power is minimized subject to a minimum (conditional) Fisher information J ∈ (0, J 0 ),\nin the sense that the optimal solutions J opt (P ) (of (12)) and P opt (J) (of (13)) are inverses of one another. Moreover, the opti- mal solutions hold with active constraints (satisfying equalities). From (5) and (8), problem (13) is further equivalent to,\nwhich, on closer look, is a quadratically constrained quadratic program (QCQP) in L nnz (A) variables.\nAn explicit form of QCQP can be obtained from problem (14) by concatenating the elements of W (column-wise, only those that are allowed to be non-zero), in w = [w 1 , w 2 , . . . , w L ] T , and accordingly transforming other constants,\nWe illustrate the relevant transformations through an example, in Figure 2, with N = 4 nodes and 3 collaborating links, i.e., total L = 7 non-zero coefﬁcients. Based on topology A, node k sends its observations to nodes T k and receives observations from nodes F k . The notations T w k and F w k similarly denote the respective indices of w as obtained from W . The matrix Ω is formed from V by copying the (sub)matrices V F k → Ω F w\nfor k = 1, 2, . . . , N , satisfying Tr (W V W T ) = w T Ωw. The matrix G is similarly formed from vector g by copying the elements g T k → G T w\nThe solution to problem (15) (equivalently, problems (12), (13) and (14)) is summarized in Theorem 1.\nTheorem 1: (Power-Distortion tradeoff for Linear Coherent Ideal-Collaborative Estimation) Assuming Σ to be positive\ndeﬁnite, the tradeoff between (conditional) Fisher Information and (cumulative) transmission power is\nwhere the scalar κ is such that w T opt Ωw opt = P . Equivalently, for J ∈ (0, J 0 ), P opt (J) = Jξ 2 µ + (J), where µ + (J) is the only positive solution to the generalized eigenvalue problem (Γ + µZ)v = 0 (note that Z is a function of J).\nTheorem 1 is important since it shows the effect of (cu- mulative) transmit power and the topology on the estimation performance. Corresponding to the example topology in Figure 2 and randomly chosen system parameters h , Σ and g, a typical power-distortion tradeoff curve is shown in Figure 3 (bold line). Some remarks regarding Theorem 1 are in order.\nRemark 1 (Distributed and fully connected cases): For the distributed scenario, A = I, and we have w = diag(W ), 2 Ω = diag(diag(V )) and G = diag(g). Furthermore, when Σ is diagonal (equivalently, when observation noise is spatially uncorrelated), equation (17) reduces to\nFor the fully connected scenario, A = 11 T , we have w = vec(W ), Ω = V ⊗ I, G = I ⊗ g, and subsequently the following result.\nFurthermore, distortion resulting from (20) is information theo- retically optimal.\nProof: See [13]. Information theoretic optimality follows from Corollary 2.3.5 of [14].\nThe information theoretic optimality is expected since a fully connected network is equivalent to the centralized scenario with effective channel gain g .\nRemark 2 (Limits and a lower bound): For better understand- ing the dependence of distortion D on (cumulative) SNR P ξ , we compute the low and high SNR limits of distortion (and optimal weights, upto second order Taylor series) in Table I. For any topology A (and consequently Γ), provided a large (cumulative) power is available, the resultant distortion approaches that of the centralized case, D 0 (see (9)). In low-SNR situations, the distortion approaches that of the prior, η 2 . Towards the goal of obtaining a simpler approximation of (17) for both the low and high SNR regimes, we obtain the following result.\n(21) Then, J + (P ) ≥ J opt (P ) and hence D − (P ) ≤ D opt (P ).\nBoth the high and low-SNR limits and the lower bound D − are displayed in Figure 3. From Figure 3, we verify that both the low and high SNR limits are quite accurate (in their respective regimes) and the lower bound, while accurate in both the limits, always satisfy D − < D.\nRemark 3 (Decentralized computation of collaborative strate- gies): The optimal combining weights in Table I, besides being accurate in the low and high-SNR regimes respectively, have appealing interpretations that can facilitate decentralized compu- tation of collaborative strategies, thereby requiring lesser coordi- nation with the fusion center and facilitating faster adaptation to dynamically changing topologies. Firstly, it can be shown that, w ∝ Ω −1 Gh (low-SNR regime) corresponds to the case where each node is performing local-MMSE estimation. Computation of the optimal combining weights can hence be performed from local observation and covariance models only. Secondly, w ∝ Ω −1 GΓΣ −1 h (high-SNR regime) can be shown to correspond to the solution of a convex linearly constrained quadratic program (LCQP) with separable objective function, which can be efﬁciently solved in a decentralized manner [15]. We relegate the details to a future extended version of this paper.\nsome combinations of signal parameters, network topology and channel gains, the power-distortion tradeoff can be explicitly derived. In Figure 4, we display a class of graphs, namely the K-connected directed cycle, in which each node shares its observations with the next K nodes. Note that K = 0 denotes the distributed scenario while K = N − 1 denotes the fully connected scenario.\nProposition 4: (Homogeneous and equicorrelated sensor net- work with cycle topology) Assume a collaborative sensor net- work with, 1) identical observation gains, h = h 0 1, 2) equicor- related and homogeneous observation noise, Σ = σ 2 ((1 −ρ)I + ρ11 T ), where ρ ∈ [0, 1), 3) K-connected directed cycle as the neighborhood adjacency matrix A, and 4) identical channel gains, g = g 0 1. For such a problem setup, the lower bound in (21) is actually an equality, i.e., D opt (P ) = D − (P ), with W C(K) opt (P ) ∝ A and\n1 − ρ K + 1\n(22) Proof: See [13].\nFrom Proposition 4, we readily infer the conditions under which collaboration can be beneﬁcial. For K = 0, 1, . . . , N − 1, let us denote by P C(K) opt (J) the (minimum) power required to obtain some prespeciﬁed distortion D (J and D are related by (8)). Then the (relative) power (RPS) savings obtained due to collaboration is (from (22)),\nwhich represents the gain compared to distributed scenario (K = 0). Firstly, we note that RPS(K, J) ∈ [0, 1) (since\nρ ∈ [0, 1) and K ≥ 0), which shows that it is always beneﬁcial to collaborate, assuming cost-free collaboration. Also, more (relative) power is saved when, 1) the collaboration among nodes increases (higher K), 2) the observation noise is less correlated (lower ρ), and 3) the local-SNR is small (smaller γ \t η 2 h 2 0 σ 2 ). When local-SNR is large, say γ = 100, then even a fully connected network can provide only a power saving of 1%. On the other hand, if the local-SNR is small, say γ = 1, then a fully connected network can provide upto 50% power savings.\nTo demonstrate the (cumulative) power saved due to col- laboration and to investigate whether the insights obtained from Proposition 4 extend to more complicated scenarios, we consider the following simulation setup. The spatial placement and neighborhood structure is modeled as a Random Geo- metric Graph, RGG (N, r) [16], where sensors are uniformly distributed over a unit square with bidirectional communication links present only for pairwise distances at most r, i.e., A such that A i,j = 1I [d i,j ≤r] .The noise is modeled as a homogeneous and exponentially correlated Gaussian covariance matrix, i.e., Σ is such that Σ i,j = σ 2 ρ d i,j , where ρ ∈ (0, 1) is indicative of the degree of spatial correlation. A smaller value of ρ indicates lower correlation with ρ → 0 signifying completely independent observations. Speciﬁcally, we consider ρ = 10 −3 and ρ = 10 −7 to contrast the effect of correlation (for sensor nodes apart by distance d i,j = 0.1, the actual correlations are ρ 0.1 ≈ 0.5 and ρ 0.1 ≈ 0.2 respectively). We consider N = 50 nodes with identical local-SNR (speciﬁcally, σ 2 = 0.5, h = 1 with η 2 = 1 and η 2 = 2 for two separate runs). The individual channel gains were generated by uniform random numbers in the range (0, 1]. At each instance, power was allocated to satisfy the pre-speciﬁed distortion performance of η 2 +D 0 2 . We display the power savings obtained after collaborating through RGG (N, r) topology, P (0) opt −P (r) opt , as a percentage of the power required for the distributed case, P (0) opt , for increasing radius of collaboration r, in Figure 5. We note that signiﬁcant power is saved through collaboration for different magnitudes of local-SNR, η 2 , and varying degrees of spatial correlation, ρ. Also, we observe that\n(relative) power savings seem to increase with lower spatial correlation and lower local-SNR, which were also the insights obtained from the simpler example considered in Proposition 4.\nIn this paper, we addressed the problem of collaborative estimation in a sensor network where sensors communicate with the FC using a coherent MAC channel. For the scenario when the collaborative topology is ﬁxed and collaboration is cost-free, we obtained the optimal power-distortion tradeoff in closed-form by solving a QCQP problem. Through the use of both theoretical and numerical results, we established that collaboration helps to substantially lower the power requirements in a network, specially in low local-SNR scenario. As future work, we wish to explore the collaborative estimation problem when the parameter to be estimated is a vector with correlated elements. The issue of collaboration with non-zero cost, as mentioned earlier, is also important. Finally, collaboration in the presence of individual power constraints (in addition to cumulative) is another topic worthy of future research."},"refs":[{"authors":[{"name":"J.-J. Xiao"},{"name":"S. Cui"},{"name":"Z.-Q. Luo"},{"name":"A. Goldsmith"}],"title":{"text":"Linear coherent de- centralized estimation"}},{"authors":[{"name":"I. Akyildiz"},{"name":"W. Su"},{"name":"Y. Sankarasubramaniam"},{"name":"E. Cayirci"}],"title":{"text":"A survey on sensor networks"}},{"authors":[{"name":"J. Fang"},{"name":"H. Li"}],"title":{"text":"Power constrained distributed estimation with cluster- based sensor collaboration"}},{"authors":[{"name":"S. Cui"},{"name":"J.-J. Xiao"},{"name":"A. Goldsmith"},{"name":"Z.-Q. Luo"},{"name":"H. Poor"}],"title":{"text":"Estimation diversity and energy efﬁciency in distributed sensing"}},{"authors":[{"name":"A. Ribeiro"},{"name":"G. B. Giannakis"}],"title":{"text":"Bandwidth-constrained distributed estimation for wireless sensor networks-Part I: Gaussian case"}},{"authors":[{"name":"J. Li"},{"name":"G. AlRegib"}],"title":{"text":"Distributed estimation in energy-constrained wire- less sensor networks"}},{"authors":[{"name":"V. Havary-Nassab"},{"name":"S. Shahbazpanahi"},{"name":"A. Grami"},{"name":"Z.-Q. Luo"}],"title":{"text":"Dis- tributed beamforming for relay networks based on second-order statistics of the channel state information"}},{"authors":[{"name":"Y. Jing"},{"name":"H. Jafarkhani"}],"title":{"text":"Network beamforming using relays with perfect channel information"}},{"authors":[{"name":"M. Gastpar"}],"title":{"text":"To code or not to code"}},{"authors":[{"name":"M. Gastpar"},{"name":"B. Rimoldi"},{"name":"M. Vetterli"}],"title":{"text":"To code, or not to code: Lossy source-channel communication revisited"}},{"authors":[{"name":"R. Mudumbai"},{"name":"D. R. Brown"},{"name":"U. Madhow"},{"name":"H. V. Poor"}],"title":{"text":"Distributed transmit beamforming: Challenges and recent progress"}},{"authors":[{"name":"S. M. Ka"}],"title":{"text":"Fundamentals of Statistical Signal Processing: Estimation Theory "}},{"authors":[{"name":"S. Kar"},{"name":"P. K. Varshney"}],"title":{"text":"Linear coherent estimation with spatial collaboration"}},{"authors":[{"name":"M. Gastpar"}],"title":{"text":"Information-theoretic bounds on sensor network perfor- mance"}},{"authors":[{"name":"S. Boyd"},{"name":"N. Parikh"},{"name":"E. Chu"},{"name":"B. Peleato"},{"name":"J. Eckstein"}],"title":{"text":"Distributed optimization and statistical learning via the alternating direction method of multipliers"}},{"authors":[{"name":"N. Freris"},{"name":"H. Kowshik"},{"name":"P. Kumar"}],"title":{"text":"Fundamentals of large sensor networks: Connectivity, capacity, clocks, and computation"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569559541.pdf"},"links":[{"id":"1569564843","weight":7},{"id":"1569566381","weight":2},{"id":"1569566527","weight":3},{"id":"1569566485","weight":5},{"id":"1569565383","weight":7},{"id":"1569565883","weight":6},{"id":"1569564889","weight":4},{"id":"1569565223","weight":4},{"id":"1569566725","weight":3},{"id":"1569565663","weight":3},{"id":"1569565377","weight":14},{"id":"1569566385","weight":7},{"id":"1569564635","weight":3},{"id":"1569565867","weight":4},{"id":"1569566799","weight":4},{"id":"1569565067","weight":6},{"id":"1569559665","weight":3},{"id":"1569561021","weight":3},{"id":"1569564669","weight":5},{"id":"1569565691","weight":2},{"id":"1569566815","weight":4},{"id":"1569566875","weight":2},{"id":"1569564605","weight":5},{"id":"1569559617","weight":3},{"id":"1569566981","weight":6},{"id":"1569566433","weight":2},{"id":"1569566321","weight":3},{"id":"1569566605","weight":4},{"id":"1569565489","weight":2},{"id":"1569566683","weight":4},{"id":"1569566855","weight":4},{"id":"1569560629","weight":4},{"id":"1569566869","weight":4},{"id":"1569565097","weight":4},{"id":"1569566227","weight":5},{"id":"1569566091","weight":6},{"id":"1569559259","weight":5},{"id":"1569566697","weight":7},{"id":"1569566597","weight":5},{"id":"1569565551","weight":5},{"id":"1569565711","weight":7},{"id":"1569566761","weight":3},{"id":"1569566943","weight":4},{"id":"1569565091","weight":6},{"id":"1569566591","weight":13},{"id":"1569556029","weight":3},{"id":"1569566571","weight":4},{"id":"1569552245","weight":9},{"id":"1569565607","weight":3},{"id":"1569565495","weight":3},{"id":"1569567045","weight":3},{"id":"1569565227","weight":3},{"id":"1569564481","weight":4},{"id":"1569560833","weight":2},{"id":"1569566415","weight":8},{"id":"1569564805","weight":3},{"id":"1569567005","weight":5},{"id":"1569566469","weight":2},{"id":"1569566081","weight":13},{"id":"1569565355","weight":6},{"id":"1569564469","weight":2},{"id":"1569565931","weight":3},{"id":"1569566373","weight":4},{"id":"1569566647","weight":3},{"id":"1569551535","weight":9},{"id":"1569566765","weight":12},{"id":"1569564897","weight":4},{"id":"1569565547","weight":2},{"id":"1569566871","weight":5},{"id":"1569566653","weight":7},{"id":"1569565461","weight":10},{"id":"1569564731","weight":4},{"id":"1569565171","weight":4},{"id":"1569566207","weight":4},{"id":"1569564227","weight":9},{"id":"1569558325","weight":6},{"id":"1569565837","weight":6},{"id":"1569566671","weight":10},{"id":"1569566303","weight":2},{"id":"1569564233","weight":3},{"id":"1569566459","weight":11},{"id":"1569567535","weight":2},{"id":"1569563411","weight":21},{"id":"1569564401","weight":4},{"id":"1569564849","weight":3},{"id":"1569566319","weight":3},{"id":"1569565123","weight":2},{"id":"1569566941","weight":4},{"id":"1569566033","weight":7},{"id":"1569566739","weight":3},{"id":"1569555811","weight":3},{"id":"1569558459","weight":2},{"id":"1569565609","weight":3},{"id":"1569565291","weight":4},{"id":"1569564203","weight":6},{"id":"1569566821","weight":5},{"id":"1569556713","weight":2},{"id":"1569562685","weight":3},{"id":"1569566751","weight":2},{"id":"1569566467","weight":5},{"id":"1569565771","weight":3},{"id":"1569566157","weight":3},{"id":"1569560613","weight":4},{"id":"1569566903","weight":6},{"id":"1569566999","weight":5},{"id":"1569565859","weight":3},{"id":"1569565809","weight":5},{"id":"1569566843","weight":4},{"id":"1569566579","weight":2},{"id":"1569558483","weight":3},{"id":"1569566563","weight":5},{"id":"1569566089","weight":6},{"id":"1569564903","weight":2},{"id":"1569566173","weight":2},{"id":"1569559221","weight":3},{"id":"1569556091","weight":2},{"id":"1569565347","weight":6},{"id":"1569566925","weight":4},{"id":"1569564387","weight":5},{"id":"1569565455","weight":8},{"id":"1569566497","weight":12},{"id":"1569566795","weight":3},{"id":"1569566963","weight":3},{"id":"1569561679","weight":5},{"id":"1569566709","weight":9},{"id":"1569564989","weight":2},{"id":"1569560721","weight":2},{"id":"1569566015","weight":10},{"id":"1569566523","weight":3},{"id":"1569565897","weight":12},{"id":"1569551763","weight":3},{"id":"1569565953","weight":5},{"id":"1569566895","weight":5},{"id":"1569566889","weight":2},{"id":"1569566749","weight":3},{"id":"1569566269","weight":3},{"id":"1569564189","weight":6},{"id":"1569564195","weight":2},{"id":"1569561513","weight":5},{"id":"1569566985","weight":5},{"id":"1569564613","weight":2},{"id":"1569565369","weight":4},{"id":"1569567009","weight":5},{"id":"1569566865","weight":7},{"id":"1569565321","weight":13},{"id":"1569558785","weight":2},{"id":"1569564647","weight":4},{"id":"1569566095","weight":5},{"id":"1569566193","weight":4},{"id":"1569564271","weight":11},{"id":"1569564337","weight":3},{"id":"1569565907","weight":3},{"id":"1569566343","weight":2},{"id":"1569564311","weight":2},{"id":"1569565803","weight":3},{"id":"1569565785","weight":4},{"id":"1569566239","weight":3},{"id":"1569566167","weight":4},{"id":"1569566679","weight":6},{"id":"1569565989","weight":6},{"id":"1569566575","weight":8},{"id":"1569563981","weight":7},{"id":"1569561085","weight":4},{"id":"1569566419","weight":3},{"id":"1569566617","weight":2},{"id":"1569559565","weight":4},{"id":"1569566905","weight":8},{"id":"1569566733","weight":3},{"id":"1569566753","weight":6},{"id":"1569566311","weight":19},{"id":"1569563307","weight":7},{"id":"1569566063","weight":6},{"id":"1569558681","weight":3},{"id":"1569555999","weight":3},{"id":"1569566759","weight":7},{"id":"1569565589","weight":2},{"id":"1569559195","weight":2},{"id":"1569566149","weight":6},{"id":"1569559995","weight":2},{"id":"1569566657","weight":7},{"id":"1569558859","weight":2},{"id":"1569565199","weight":5},{"id":"1569565213","weight":5},{"id":"1569565365","weight":4},{"id":"1569566643","weight":3},{"id":"1569566511","weight":6},{"id":"1569566991","weight":2},{"id":"1569565841","weight":3},{"id":"1569566975","weight":4},{"id":"1569566369","weight":2},{"id":"1569566531","weight":8},{"id":"1569567665","weight":4},{"id":"1569561143","weight":2},{"id":"1569566581","weight":2},{"id":"1569565833","weight":2},{"id":"1569566489","weight":2},{"id":"1569564611","weight":12},{"id":"1569565535","weight":7},{"id":"1569562867","weight":5},{"id":"1569566395","weight":5},{"id":"1569565667","weight":2},{"id":"1569561795","weight":2},{"id":"1569566845","weight":3},{"id":"1569566325","weight":10},{"id":"1569566423","weight":2},{"id":"1569565257","weight":3},{"id":"1569564795","weight":9},{"id":"1569567015","weight":5},{"id":"1569559805","weight":7},{"id":"1569566437","weight":7},{"id":"1569566811","weight":4},{"id":"1569566851","weight":12},{"id":"1569558901","weight":2},{"id":"1569565735","weight":12},{"id":"1569553909","weight":8},{"id":"1569559111","weight":4},{"id":"1569566687","weight":2},{"id":"1569566939","weight":3},{"id":"1569553537","weight":11},{"id":"1569565427","weight":6},{"id":"1569566403","weight":4},{"id":"1569565915","weight":5},{"id":"1569552251","weight":4},{"id":"1569566139","weight":2},{"id":"1569553519","weight":2},{"id":"1569567051","weight":3},{"id":"1569566885","weight":3},{"id":"1569564441","weight":3},{"id":"1569566231","weight":6},{"id":"1569564209","weight":2},{"id":"1569566513","weight":5},{"id":"1569566425","weight":2},{"id":"1569554881","weight":2},{"id":"1569554971","weight":8},{"id":"1569565501","weight":4},{"id":"1569566899","weight":2},{"id":"1569566445","weight":3},{"id":"1569566209","weight":12},{"id":"1569562821","weight":2},{"id":"1569566649","weight":24},{"id":"1569566791","weight":2},{"id":"1569565559","weight":3},{"id":"1569566371","weight":5},{"id":"1569565655","weight":6},{"id":"1569566909","weight":6},{"id":"1569566127","weight":3},{"id":"1569565151","weight":3},{"id":"1569558985","weight":8},{"id":"1569563763","weight":4},{"id":"1569566473","weight":11},{"id":"1569564857","weight":6},{"id":"1569564333","weight":6},{"id":"1569566913","weight":7},{"id":"1569566809","weight":3},{"id":"1569566629","weight":5},{"id":"1569566257","weight":6},{"id":"1569565033","weight":11},{"id":"1569566447","weight":7},{"id":"1569566357","weight":2},{"id":"1569565817","weight":2},{"id":"1569565847","weight":8},{"id":"1569564353","weight":2},{"id":"1569563897","weight":3},{"id":"1569557083","weight":3},{"id":"1569565887","weight":6},{"id":"1569565929","weight":3},{"id":"1569566141","weight":5},{"id":"1569565055","weight":8},{"id":"1569563231","weight":3},{"id":"1569565633","weight":7},{"id":"1569566661","weight":2},{"id":"1569565279","weight":2},{"id":"1569555879","weight":4},{"id":"1569565521","weight":2},{"id":"1569566115","weight":6},{"id":"1569565219","weight":4},{"id":"1569558509","weight":2},{"id":"1569554759","weight":4},{"id":"1569564851","weight":2},{"id":"1569565595","weight":5},{"id":"1569565185","weight":6},{"id":"1569566773","weight":5},{"id":"1569565095","weight":4},{"id":"1569566223","weight":3},{"id":"1569566553","weight":7},{"id":"1569564973","weight":2},{"id":"1569565469","weight":2},{"id":"1569564969","weight":3},{"id":"1569566593","weight":2},{"id":"1569565029","weight":9},{"id":"1569565357","weight":11},{"id":"1569561245","weight":2},{"id":"1569566505","weight":5},{"id":"1569565933","weight":4},{"id":"1569562207","weight":5},{"id":"1569565705","weight":2},{"id":"1569566191","weight":6},{"id":"1569567033","weight":7},{"id":"1569565527","weight":6},{"id":"1569566853","weight":4},{"id":"1569566603","weight":7},{"id":"1569565363","weight":7},{"id":"1569566159","weight":2},{"id":"1569566695","weight":5},{"id":"1569566051","weight":7},{"id":"1569561379","weight":2},{"id":"1569565909","weight":5},{"id":"1569561123","weight":4},{"id":"1569565467","weight":2},{"id":"1569566655","weight":6},{"id":"1569566673","weight":8},{"id":"1569567235","weight":6},{"id":"1569565441","weight":4},{"id":"1569565739","weight":2},{"id":"1569565311","weight":2},{"id":"1569566233","weight":4},{"id":"1569566667","weight":5},{"id":"1569566297","weight":2},{"id":"1569566893","weight":3},{"id":"1569566317","weight":9},{"id":"1569564097","weight":4},{"id":"1569560997","weight":3},{"id":"1569563845","weight":2},{"id":"1569566407","weight":3},{"id":"1569560349","weight":6},{"id":"1569566501","weight":5},{"id":"1569565741","weight":4},{"id":"1569566275","weight":3},{"id":"1569566481","weight":11},{"id":"1569565545","weight":6},{"id":"1569566857","weight":6},{"id":"1569565961","weight":2},{"id":"1569566387","weight":4},{"id":"1569566245","weight":3},{"id":"1569560503","weight":3},{"id":"1569565463","weight":3},{"id":"1569564339","weight":2},{"id":"1569566219","weight":7},{"id":"1569565439","weight":9},{"id":"1569566229","weight":4},{"id":"1569566949","weight":8},{"id":"1569566133","weight":5},{"id":"1569562551","weight":5},{"id":"1569563395","weight":4},{"id":"1569566901","weight":2},{"id":"1569551347","weight":2},{"id":"1569565415","weight":3},{"id":"1569555367","weight":6},{"id":"1569561623","weight":7},{"id":"1569566383","weight":5},{"id":"1569564485","weight":4},{"id":"1569566631","weight":2},{"id":"1569565571","weight":7},{"id":"1569565885","weight":7},{"id":"1569566177","weight":3},{"id":"1569565493","weight":5},{"id":"1569557633","weight":2},{"id":"1569566805","weight":4},{"id":"1569559199","weight":3},{"id":"1569566929","weight":3},{"id":"1569566293","weight":9},{"id":"1569565665","weight":6},{"id":"1569566831","weight":4},{"id":"1569565549","weight":4},{"id":"1569565523","weight":4},{"id":"1569565611","weight":5},{"id":"1569557715","weight":2},{"id":"1569564175","weight":4},{"id":"1569566983","weight":8},{"id":"1569566097","weight":5},{"id":"1569566479","weight":9},{"id":"1569566431","weight":2},{"id":"1569565397","weight":6},{"id":"1569566873","weight":3},{"id":"1569565765","weight":4},{"id":"1569565925","weight":2},{"id":"1569565435","weight":3},{"id":"1569557275","weight":4},{"id":"1569565263","weight":2},{"id":"1569565215","weight":3},{"id":"1569565093","weight":2},{"id":"1569565385","weight":2},{"id":"1569565575","weight":3},{"id":"1569565919","weight":6},{"id":"1569565181","weight":3},{"id":"1569566711","weight":9},{"id":"1569565241","weight":4},{"id":"1569566927","weight":7},{"id":"1569565661","weight":4},{"id":"1569565865","weight":4},{"id":"1569566887","weight":7},{"id":"1569565273","weight":4},{"id":"1569566267","weight":3},{"id":"1569564131","weight":4},{"id":"1569552037","weight":4},{"id":"1569564919","weight":3},{"id":"1569565511","weight":3},{"id":"1569566737","weight":7},{"id":"1569566429","weight":2},{"id":"1569561221","weight":5},{"id":"1569566917","weight":12},{"id":"1569566035","weight":4},{"id":"1569565353","weight":7},{"id":"1569564683","weight":3},{"id":"1569564305","weight":4},{"id":"1569564283","weight":3},{"id":"1569566691","weight":6},{"id":"1569565421","weight":5},{"id":"1569566547","weight":3},{"id":"1569566651","weight":4},{"id":"1569566823","weight":4},{"id":"1569566595","weight":3},{"id":"1569566677","weight":4},{"id":"1569565349","weight":6},{"id":"1569566137","weight":6},{"id":"1569565013","weight":6},{"id":"1569566283","weight":6},{"id":"1569565645","weight":4},{"id":"1569566529","weight":5},{"id":"1569565375","weight":12},{"id":"1569566715","weight":5},{"id":"1569565237","weight":8},{"id":"1569566639","weight":4},{"id":"1569566819","weight":2},{"id":"1569565041","weight":6},{"id":"1569564703","weight":6},{"id":"1569566713","weight":4},{"id":"1569565541","weight":2},{"id":"1569565597","weight":3},{"id":"1569566813","weight":4},{"id":"1569565293","weight":2},{"id":"1569566771","weight":11},{"id":"1569562277","weight":4},{"id":"1569566641","weight":12},{"id":"1569565425","weight":4},{"id":"1569566977","weight":2},{"id":"1569564247","weight":5},{"id":"1569564437","weight":7},{"id":"1569566533","weight":4},{"id":"1569551905","weight":2},{"id":"1569564861","weight":6},{"id":"1569565457","weight":5},{"id":"1569564787","weight":2},{"id":"1569566487","weight":6},{"id":"1569565529","weight":9},{"id":"1569556759","weight":3},{"id":"1569566619","weight":12},{"id":"1569561185","weight":6},{"id":"1569566397","weight":5},{"id":"1569566301","weight":5},{"id":"1569558779","weight":7},{"id":"1569565669","weight":10},{"id":"1569565233","weight":3},{"id":"1569563721","weight":2},{"id":"1569566001","weight":3},{"id":"1569565593","weight":3},{"id":"1569560235","weight":3},{"id":"1569566817","weight":4},{"id":"1569564157","weight":2},{"id":"1569566389","weight":5},{"id":"1569566435","weight":2},{"id":"1569567483","weight":6},{"id":"1569566911","weight":3},{"id":"1569564923","weight":6},{"id":"1569565367","weight":2},{"id":"1569566299","weight":11},{"id":"1569564281","weight":4},{"id":"1569564769","weight":5},{"id":"1569565769","weight":4},{"id":"1569566171","weight":2},{"id":"1569566601","weight":4},{"id":"1569565805","weight":19},{"id":"1569561713","weight":3},{"id":"1569566933","weight":3},{"id":"1569563919","weight":12},{"id":"1569566577","weight":3},{"id":"1569557851","weight":5},{"id":"1569565389","weight":3},{"id":"1569559919","weight":13},{"id":"1569565861","weight":3},{"id":"1569566147","weight":5},{"id":"1569565537","weight":3},{"id":"1569559523","weight":3},{"id":"1569566057","weight":4},{"id":"1569562367","weight":4},{"id":"1569560785","weight":3},{"id":"1569565561","weight":6},{"id":"1569565631","weight":5},{"id":"1569566457","weight":15},{"id":"1569555891","weight":2},{"id":"1569566847","weight":4},{"id":"1569565997","weight":7},{"id":"1569563425","weight":10},{"id":"1569565035","weight":8},{"id":"1569559597","weight":11},{"id":"1569564961","weight":5},{"id":"1569559251","weight":3},{"id":"1569565089","weight":2},{"id":"1569567013","weight":7},{"id":"1569566583","weight":3},{"id":"1569561861","weight":4},{"id":"1569565337","weight":5},{"id":"1569565737","weight":4},{"id":"1569560459","weight":5},{"id":"1569566807","weight":2},{"id":"1569564463","weight":3},{"id":"1569565853","weight":9},{"id":"1569550425","weight":15},{"id":"1569566273","weight":3},{"id":"1569564123","weight":10},{"id":"1569566341","weight":5},{"id":"1569565889","weight":2},{"id":"1569566635","weight":15},{"id":"1569566611","weight":5},{"id":"1569551539","weight":3},{"id":"1569564505","weight":3},{"id":"1569565565","weight":3},{"id":"1569565635","weight":3},{"id":"1569561397","weight":3},{"id":"1569556327","weight":6},{"id":"1569566797","weight":5},{"id":"1569566125","weight":2},{"id":"1569566413","weight":5},{"id":"1569565707","weight":7},{"id":"1569565113","weight":4},{"id":"1569566375","weight":3},{"id":"1569564257","weight":11},{"id":"1569565583","weight":2},{"id":"1569566555","weight":2},{"id":"1569564931","weight":5},{"id":"1569565373","weight":2},{"id":"1569566973","weight":7},{"id":"1569561579","weight":5},{"id":"1569566449","weight":4},{"id":"1569566987","weight":3},{"id":"1569565031","weight":3},{"id":"1569564755","weight":3},{"id":"1569551541","weight":7},{"id":"1569565619","weight":2},{"id":"1569566839","weight":7},{"id":"1569551751","weight":3},{"id":"1569565139","weight":9},{"id":"1569565895","weight":2},{"id":"1569566663","weight":6},{"id":"1569564419","weight":2},{"id":"1569565579","weight":3},{"id":"1569566067","weight":5},{"id":"1569566825","weight":6},{"id":"1569566615","weight":2},{"id":"1569566241","weight":12},{"id":"1569564807","weight":3},{"id":"1569563007","weight":12},{"id":"1569566113","weight":2},{"id":"1569566443","weight":6},{"id":"1569566727","weight":8},{"id":"1569565315","weight":4},{"id":"1569566417","weight":4},{"id":"1569560581","weight":5},{"id":"1569559233","weight":2}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S8.T8.2","endtime":"17:20","authors":"Swarnendu Kar, Pramod Varshney","date":"1341334800000","papertitle":"On Linear Coherent Estimation with Spatial Collaboration","starttime":"17:00","session":"S8.T8: Estimation and Detection","room":"Stratton (491)","paperid":"1569559541"},"cluster":{"jsonClass":"HashMap$HashTrieMap","spectral6":"5","spectral43":"14","spectral28":"5","spectral32":"4","spectral14":"13","spectral20":"2","spectral9":"6","spectral25":"7","spectral42":"11","spectral3":"0","spectral47":"36","spectral17":"3","louvain":"536","spectral36":"14","spectral39":"38","spectral10":"4","spectral15":"5","spectral33":"6","spectral5":"4","spectral21":"20","spectral44":"39","spectral26":"1","spectral40":"22","spectral8":"1","spectral11":"10","spectral4":"2","spectral37":"30","spectral48":"14","spectral22":"13","spectral23":"11","spectral12":"5","spectral50":"18","spectral19":"8","spectral34":"27","spectral45":"17","spectral7":"5","spectral49":"35","spectral38":"14","spectral24":"10","spectral13":"1","spectral31":"3","spectral29":"14","spectral35":"8","spectral30":"8","spectral41":"20","spectral27":"4","spectral18":"14","spectral46":"1","spectral2":"0","spectral16":"14"}}
