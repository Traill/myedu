{"id":"1569566853","paper":{"title":{"text":"BPRS: Belief Propagation Based Iterative Recommender System"},"authors":[{"name":"Erman Ayday"},{"name":"Arash Einolghozati"},{"name":"Faramarz Fekri"}],"abstr":{"text":"Abstract\u2014In this paper we introduce the ﬁrst application of the Belief Propagation (BP) algorithm in the design of recom- mender systems. We formulate the recommendation problem as an inference problem and aim to compute the marginal probability distributions of the variables which represent the ratings to be predicted. However, computing these marginal probability functions is computationally prohibitive for large- scale systems. Therefore, we utilize the BP algorithm to efﬁciently compute these functions. Recommendations for each active user are then iteratively computed by probabilistic message passing. As opposed to the previous recommender algorithms, BPRS does not require solving the recommendation problem for all the users if it wishes to update the recommendations for only a single active. Further, BPRS computes the recommendations for each user with linear complexity and without requiring a training period. Via computer simulations (using the 100K MovieLens dataset), we verify that BPRS iteratively reduces the error in the predicted ratings of the users until it converges. Finally, we conﬁrm that BPRS is comparable to the state of art methods such as Correlation-based neighborhood model (CorNgbr) and Singular Value Decomposition (SVD) in terms of rating and precision accuracy. Therefore, we believe that the BP-based recommendation algorithm is a new promising approach which offers a signiﬁcant advantage on scalability while providing competitive accuracy for the recommender systems."},"body":{"text":"Today, the quantity of available information grows rapidly, overwhelming consumers to discover useful information and ﬁlter out the irrelevant items. Thus, the user is confronted with a big challenge of ﬁnding the most relevant information or item in the short amount of time. Recommender systems are aimed at addressing this overload problem, suggesting to the users those items that meet their interests and preferences. More generally, recommender systems can learn about user preferences and proﬁle over time, based on data mining algorithms, and automatically suggest products (from a large space of possible options) that ﬁt the users\u2019 needs. Hence, it is foreseeable that the social web is going to be driven by these recommender systems.\nHowever, there are certain challenges to design scalable, accurate and dependable recommender systems. The available data for the recommender systems is incomplete, uncertain, inconsistent and/or intentionally-contaminated. Further, since new data (ratings) becomes available continuously, recom- mendations need to be updated in frequent intervals causing computational limitations for large-scale systems. Latent factor models (such as Matrix Factorization) have proven to be the\nmost accurate method in the Root Mean Square Error (RMSE) sense. However, most existing and highly popular Matrix Factorization-based recommender algorithms are shown to be prone to malicious behavior [1] and they have scalability issues. In other words, they fall short of incorporating the attack proﬁles and the extra noise generated by the malicious users. Further, each new update (using the most recent data or ratings) for a particular active user requires to solve the entire problem for every user in the system. Hence, new research needed to focus on algorithms which meet these challenges and provide scalable, accurate and dependable recommender systems.\nIn this paper we introduce the ﬁrst application of Belief Propagation (BP), an iterative probabilistic algorithm, to solve the recommendation problem. We have applied BP to trust and reputation systems in our previous work [2], [3]. In such systems, BP is used to solve the inference problem for ﬁnding the global reputation of service providers in a network based on the previous ratings of the users. The main difference be- tween trust and reputation systems and recommender systems is that in the former one the inference problem has to be solved globally but in the latter one, the inferences are local and speciﬁc for each user. In [4] and [5], we have studeied the reputation system for Delay tolerant networks (DTN) and P2P networks respectively.\nThe key observation we make is that recommender systems deal with complicated global functions of many variables (e.g., users and items). By using a factor graph, we can obtain a qualitative representation of how the users and items are related on a graphical structure. Therefore, we propose to model the recommender system on a factor graph using which our goal is to compute the marginal probability distribution functions of the variables representing the ratings to be pre- dicted for the users. However, we observe that computing the marginal probability functions is computationally prohibitive for large-scale recommender systems. Therefore, we utilize the BP algorithm to efﬁciently compute these marginal probability distributions. The key role of the BP algorithm is that we can use it to compute the marginal distributions in a complexity that grows linearly with the number of nodes (i.e, users/items).\nHereafter, we refer to our scheme as the \u201cBelief Propaga- tion Based Iterative Recommender System\u201d (BPRS). BPRS has several prominent features. First, it does not require to solve the problem for all users if it wishes to update the\npredictions for only a single active user and it does not require a training period to utilize the most recent data (ratings). Second, its complexity remains linear per single user, making it very attractive for large-scale systems. Therefore, it can update the recommendations for each active (online) user instantaneously using the most recent data (ratings). Further, we show that BPRS provides comparable usage prediction and rating prediction accuracy to other popular methods such as the Correlation-based neighborhood model (CorNgbr) and Singular Value Decomposition (SVD). Therefore, we are very optimistic that this work promises a new direction for the recommender systems which will be scalable, accurate, and resilient to attacks.\nThe rest of this paper is organized as follows. In the rest of this section, we summarize the related work. In Section II, we describe the proposed BPRS in detail. Next, in Section III, we evaluate BPRS via computer simulations using the MovieLens dataset. Finally, Section IV concludes the paper.\nRecommender systems [6] can be classiﬁed into two main categories: i) content-based ﬁltering [7] in which the system uses behavioral data about a user to recommend items similar to those previously consumed by the user, and ii) collabo- rative ﬁltering [8] in which the system compares one user\u2019s behavior against the other users\u2019 behaviors and identiﬁes items which were preferred by similar users. Collaborative ﬁltering algorithms fall further into two general classes: memory- based [9] and model-based algorithms [10], [11]. Model- based algorithms include methods exploiting Singular Value Decomposition (SVD), Principal Component Analysis (PCA) and Maximum Margin Matrix Factorization (MMMF) tech- niques [12], [13].\nThe application of Bayesian networks and message passing algorithms for recommender systems is also studied in the past [14], [15]. In [14], the message passing technique is used to determine the latent factors of the users and items (as an al- ternative to SVD). In [15], because of the fuzziness associated with the ambiguity in the description of the ratings, a (non- iterative) inference is proposed among the users to remove this ambiguity. The key difference between our approach and the other message passing-based methods is that, we describe the recommendation problem as computing marginal likeli- hood distributions from complicated global functions of many variables and to use Belief Propagation (BP) to ﬁnd them. This is inspired by successful applications of BP algorithms in various ﬁelds such as decoding of error correcting codes [16], Artiﬁcial Intelligence [17], and reputation systems [2].\nBelief Propagation (BP) [16], [17] is a message passing algorithm for performing interface on graphical models (e.g., factor graphs, Bayesian networks, Markov random ﬁelds). It has demonstrated empirical success in numerous applications\nincluding LDPC codes, turbo codes, free energy approxima- tion, and satisﬁability. BP is a method for computing marginal distributions of the unobserved nodes conditioned on the observed ones.\nOur objective is to formulate the recommendation problem as making statistical inference about the ratings of users for unseen items based on observations. That is, given the past data evidence, what would be the likelihood (probability) that the rating takes a particular value? Here, the probability is the degree of belief to which the prediction of the rating is supported by the available evidence. This requires ﬁnding the marginal probability distributions of the variables representing the ratings of the items to be predicted conditioned on some observed preferences.\nWe assume two different sets in the system: i) the set of users U and ii) the set of items (products) I. Users provide feedbacks, in the form of ratings, about the items for which they have an opinion. The main goal is to provide accurate recommendations for every user by predicting the ratings of the user for the items that he/she has not rated before (unseen item). Here, we consider an arbitrary user z (referred as the active user) and compute the prediction of ratings for user z for unseen items. We assume u users and s items in the system (i.e., |U| = u and |I| = s). Let G z = {G zj : j ∈ I} be the collection of variables representing the ratings of the items to be predicted for the active user z. Note that a subset of these variables are already known as the corresponding items were rated by user z. Hence, they do not require any prediction. Let also R z = {R zi : i ∈ U} be the conﬁdence of the system on the users for their ratings\u2019 reliability, given the active user is z. Further, we let T ij represent the rating provided previously by user i about the item j. We denote T as the s × u item-user matrix that stores these ratings, and T i as the set of ratings provided by the user i. We note that some rating entries could be missing (attributed to unseen items). To be consistent with the most of existing recommender systems, we assume that the rating values are integers from the set Υ = {1, 2, 3, 4, 5}.\nThe recommendation problem can be viewed as ﬁnding the marginal probability distributions of each variable in G z , given the observed data (i.e., existing ratings and the conﬁdence of the system for the user\u2019s ratings). There are s marginal probability functions, p(G zj |T, R z ), each of which is associated with a variable G zj ; the predicted rating of item j for user z. We formulate the problem by considering the global function p(G z |T, R z ), which is the joint probability distribution function of the variables in G z given the rating matrix and the conﬁdence of the system for the user\u2019s ratings. Then, clearly, each marginal probability function p(G zj |T, R z ) may be obtained as follows:\nwhere the notation G z \\{G zj } implies all variables in G z except G zj .\nUnfortunately, the number of terms in (1) grows expo- nentially with the number of variables, making the direct computation infeasible for large-scale systems. However, we propose to factorize (1) to local functions f i using a factor graph and utilize the BP algorithm to calculate the marginal probability distributions in linear complexity. A factor graph is a bipartite graph containing two sets of nodes (corresponding to variables and factors) and edges incident between two sets. Following [16], we form a factor graph by setting a variable node for each variable G zj , a factor node for each function f i , and an edge connecting variable node j to the factor node i if and only if G zj is an argument of f i .\nWe arrange the collection of the users and items together with the ratings provided by the users as a factor graph g(U, I). Then, since we consider the particular active user z, the factor graph is reduced to g( ˆ U , I) (as in Fig. 1) by only keeping the users that are connected to z via a path of length at most two in g(U, I) (i.e., the users who rated at least one item that is also rated by z) and removing all the other user nodes from the graph together with their edges. In this representation, each user corresponds to a factor node in the graph, shown as a square and each item is represented by a variable node shown as a hexagon. Further, each rating is represented by an edge from the factor node to the variable node. Hence, if a user i ( i ∈ ˆ U) has a rating about item j (j ∈ S), we place an edge with value T ij from the factor node i to the variable node representing item j. Eventually, the g( ˆ U , I) graph has | ˆ U | = ˆ u users and |I| = s items.\nNext, we suppose that the global function p(G z |T, R z ) factors into products of several local functions, each having a subset of variables from G z as arguments as follows:\nwhere Z is the normalization constant and G zi is a subset of G z . Hence, in the graph representation of Fig. 1, each factor node is associated with a local function and each local function f i represents the probability distributions of its arguments given the conﬁdence of the system for the associated user and the existing ratings of the associated user.\nWe now describe the message exchange between a user k and an item a (in Fig. 1) provided that the active user is z\nin BPRS. We clarify that all the messages are formed by the algorithm that is ran in the central authority. We represent the set of neighbors of the variable node a and the factor nodes k and z (in g( ˆ U , I)) as N a , N k , and N z , respectively (neighbors of an item are the set of users who rated the item while neighbors of a user are the items which it rated). Further, let Ξ = N a \\{k} and ∆ = N k \\{a}. Let G (ν) zj and R (ν) zi be the value of variable G zj and system\u2019s conﬁdence on user i at the iteration ν of the algorithm, respectively. The message λ (ν) k →a (G (ν) za ) (from factor node k to the variable node a) denotes the relative probabilities that G (ν) za = ℓ (ℓ ∈ Υ) at the ν th iteration, given T ka and R (ν−1) zk . On the other hand, µ (ν) a →k (G (ν) za ) (from variable node a to the factor node k) denotes the probability that G (ν) za = ℓ (ℓ ∈ Υ) at the ν th iteration.\nThe message from the factor node k to the variable node a at the ν th iteration is formed using the principles of the BP as\nwhere G zk is the set of variable nodes which are the arguments of the local function f k at the factor node k. This message transfer is illustrated in the right half of Fig. 2. Further, R (ν−1) zk\nis a value between zero and one and can be calculated as follows:\nThe above equation can be interpreted as one minus the average inconsistency of user k calculated by using the mes- sages it received from all its neighbors. Further, ρ, which is the highest possible deviation of a user, is set to 4 in this particular rating system, where the rating values are integers from the set Υ. Thus, the reliability of users (in their ratings) is measured based on the messages formed by the algorithm. Using (3) and assuming that the predicted ratings in set G zk are independent from each other at each intermediate step (to reduce the computational complexity), it can be shown that\nSince the second part of (6) is a constant, λ (ν) k →a (G (ν) za ) ∝ \t f k (G (ν) za , T k , R (ν−1) zk ), and hence,\n     \n    \nHere, κ a denotes the genre (i.e., type) or the set of genres of item a. Further, |κ z a (h)| is the number of items in the same genre as κ a which are previously rated as h by the active user z. The way we compute the probabilities in (7) resembles the belief/plausibility concept of the Dempster-Shafer The- ory [18]. Given T ka = 1, R (ν−1) zk can be viewed as the belief of user k that G (ν) za is one (at the ν th iteration). In other words, in the eyes of user k, G (ν) za is equal to one with probability R (ν−1) zk . Thus, (1 − R (ν−1) zk ) corresponds to the uncertainty in the belief of user k. In order to remove this uncertainty and express p(G (ν) za |T ka , R (ν−1) zk ) as the probabilities that G (ν) za is ℓ (ℓ ∈ Υ), we distribute the uncertainty among the possible outcomes (one to ﬁve) in proportion to the histogram of the ratings provided by the active user z for the items in the same genre as κ a . That is, if the active user previously provided high ratings for the items in the same genre as κ a , then we distribute most of the uncertainty to the higher ratings in proportion to the rating histogram of the active user for the items in the same genre as κ a . Similarly, if the active user previously provided low ratings for the items in the same genre as κ a , we distribute most of the uncertainty to the lower ratings. Therefore, from user k\u2019s point of view, G za is equal to one with probability R (ν−1) zk +(1−R (ν−1) zk )× |κ z a (1)|+1\n. On the other hand, it is equal to ℓ (ℓ = 1) with probability\n. We note that the above discus- sion assumed T ka = 1 and similar statements hold for the cases when T ka = 2, 3, 4, 5. It is worth clarifying that, as opposed to the Dempster-Shafer Theory, we do not combine the beliefs of the users. Instead, we consider the belief of each user individually and calculate probabilities that G (ν) za\nbeing ℓ (ℓ ∈ Υ) in the eyes of each user as in (7). We note that if the active user z did not rate any items from this particular genre ( κ a ), we distribute the uncertainty in proportion to the average rating of user z (for the items it previously rated) ( A z = i∈Nz T zi |N z | ). The above computation in (7) must be performed for every neighbors of each factor node. This ﬁnishes the ﬁrst half of the ν th iteration. In the second half of the ν th iteration, we calculate the message µ (ν) a →k (G (ν) za ) by multiplying all probabilities the variable node a received from its neighbors excluding the one from the factor node k, as shown in the left half of Fig. 2. We note that the previous ratings of the active user play a key role in the algorithm. Hence, the values of those variables in G z which are associated with the items already rated by the active user z are set to the corresponding ratings (i.e., G zj = T zj if j ∈ N z ). Thus, if\na ∈ N z , the messages generated from the variable node a do not vary with iterations since the value of this variable node ( G za ) is ﬁxed based on the ratings of the active user. Therefore, the message from the variable node a to the factor node k at the ν th iteration is given by\n   \n  \n0 \t if a ∈ N z and T za = ℓ. (8)\nThe algorithm proceeds to the next iteration in the same way as the ν th iteration. We clarify that the iterative algorithm starts by computing λ (1) k →a by using R (0) zk = ̺, where ̺ ( 0 < ̺ < 1) is the system\u2019s present conﬁdence on the users for the reliability of their ratings computed at the previous execution of the algorithm. At the end of each iteration, the upper equation in (8), after following modiﬁcation, is used to compute the prediction of ratings of the active user z. That is, we use the set N a instead of Ξ in (8) to compute µ (ν) a (G (ν) za ) for every item a for which the active user z did not have any rating. Then, we set G (ν) za = 5 i =1 iµ (ν) a (i). The iterations stop when G zj values converge for every item j.\nWe evaluate the performance of BPRS using the 100K MovieLens dataset. The dataset contains 100, 000 ratings from 943 users on 1682 items (movies) in which each user has rated at least 20 items. Further, the rating values are integers from 1 to 5. We note that based on our simulations, we observed that BPRS converges, on the average, in 10 iterations. Therefore, for the remaining of this section, we either show our results during the ﬁrst 10 iterations or after the 10 th iteration.\nWe evaluate the rating prediction accuracy of BPRS in terms of Root Mean Square Error (RMSE) metrics over the predicted ratings. We note that each test dataset is created by 80%/20% split of the full data into training and test data.Then, we used the training data ( 80% of the whole dataset) to predict the ratings in the test dataset. We computed the RMSE as below:\nwhere |K| is the number of ratings (to be predicted) in the test dataset, ˆ G ij is the actual value of the rating provided by user i for the item j in the test dataset, and G ij is the predicted rating value by the algorithm.\nIn Figs. 3, we show the RMSE provided by BPRS for two different scenarios: when all users connected to each active user via a path are used and when only the 2-hop neighbors of each active user are used in the algorithm. We observe that keeping only the 2-hop neighbors of each active user provides better performance in terms of RMSE.\nFinally, we evaluated BPRS against some popular recom- mendation algorithms such as: 1. MovieAvg (which computes the predicting ratings for the movies by averaging all the received ratings for each movie) with an RMSE of 1.053, 2. Correlation-based neighborhood model (CorNgbr), with an RMSE of 0.9406 [11], and 3. SVD latent factor model, with 50 factors and RMSE of 0.9046 [11]. We conclude that BPRS is comparable to existing methods such as CorNgbr and SVD in terms of rating prediction accuracy. On the other hand, BPRS generates recommendations in linear complexity for each active user and updates the recommendations for each active user instantaneously using the most recent data.\nAssuming u users and s items in the system, we obtained the computational complexity of BPRS (in the number of multiplications) as max (O(cs), O(cu)) per each active user, where c is the average number of nonzero elements in each row of the user-item matrix. We note that due to the sparseness of the user-item matrix, the coefﬁcient c is a small number. Further, as we discussed before, BPRS converges, on the average, in 10 iterations. Hence, we did not include the number of iterations in the complexity measure as it only introduces a small constant in front of the total complexity. This result indicates that BPRS can compute the recommendations for each active user very efﬁciently using the most recent data (ratings). Therefore, we claim that the BP-based approach toward the recommendation problem is very promising and can result in a new class of accurate and scalable recommender systems.\nIn this paper, we introduced the Belief Propagation Based Iterative Recommender System (BPRS). BPRS formulates the recommendation problem as making statistical inference about the ratings of users for unseen items based on observations. BPRS provides a complexity that remains linear per single active user, making it very attractive for large-scale systems. Further, it can update the recommendations for each active user instantaneously using the most recent data (ratings) and without solving the recommendation problem for all users. While providing these signiﬁcant scalability advantages over the existing methods, we showed that BPRS also provides comparable rating prediction accuracy with popular methods."},"refs":[{"authors":[{"name":"Z. Cheng"},{"name":"N. Hurley"}],"title":{"text":"Effective diverse and obfuscated attacks on model-based recommender systems"}},{"authors":[{"name":"E. Ayday"},{"name":"F. Fekri"}],"title":{"text":"Application of belief propagation to trust and reputation management"}},{"authors":[],"title":{"text":"Belief propagation based iterative trust and reputation manage- ment"}},{"authors":[],"title":{"text":"An iterative algorithm for trust management and adversary detection for delay tolerant networks"}},{"authors":[],"title":{"text":"BP-P2P: a belief propagation-based trust and reputation manage- ment for p2p networks"}},{"authors":[{"name":"P. Resnick"},{"name":"H. R. Varian"}],"title":{"text":"Recommender systems"}},{"authors":[{"name":"M. Balabanovic"},{"name":"Y. Shoham"}],"title":{"text":"Fab: Content-based, collaborative recommendation"}},{"authors":[{"name":"P. Resnick"},{"name":"N. Iacovou"},{"name":"M. Suchak"},{"name":"P. Bergstrom"},{"name":"J. Riedl"}],"title":{"text":"Grou- pLens: an open architecture for collaborative ﬁltering of netnews"}},{"authors":[{"name":"J. Herlocker"},{"name":"J. A. Konstan"},{"name":"J. Riedl"}],"title":{"text":"An empirical analysis of design choices in neighborhood-based collaborative ﬁltering algorithms"}},{"authors":[{"name":"T. Hofmann"}],"title":{"text":"Latent class models for collaborative ﬁltering"}},{"authors":[{"name":"Y. Koren"}],"title":{"text":"Factorization meets the neighborhood: a multifaceted col- laborative ﬁltering model"}},{"authors":[{"name":"B. M. Sarwar"},{"name":"G. Karypis"},{"name":"J. A. Konstan"},{"name":"J. T. Riedl"}],"title":{"text":"Application of dimensionality reduction in recommender system - a case study"}},{"authors":[{"name":"N. Srebro"},{"name":"J. Rennie"},{"name":"T. Jaakkola"}],"title":{"text":"Maximum margin matrix factor- izations"}},{"authors":[{"name":"D. H. Stern"},{"name":"R. Herbrich"},{"name":"T. Graepel"}],"title":{"text":"Matchbox: large scale online bayesian recommendations"}},{"authors":[{"name":"L. M. de Campos"},{"name":"J. M. Fern´andez-Luna"},{"name":"J. F. Huete"}],"title":{"text":"A collabo- rative recommender system based on probabilistic inference from fuzzy observations"}},{"authors":[{"name":"F. Kschischang"},{"name":"B. Frey"},{"name":"H. A. Loeliger"}],"title":{"text":"Factor graphs and the sum- product algorithm"}},{"authors":[{"name":"J. Pear"}],"title":{"text":"Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference "}},{"authors":[{"name":"G. Shafe"}],"title":{"text":"A Mathematical Theory of Evidence"}}]},"file":{"jsonClass":"File","file":"/home/arnfred/Code/trailhead/resources/isit2012/1569566853.pdf"},"links":[{"id":"1569566567","weight":2},{"id":"1569564843","weight":2},{"id":"1569566527","weight":3},{"id":"1569566485","weight":5},{"id":"1569565383","weight":2},{"id":"1569565883","weight":7},{"id":"1569564889","weight":8},{"id":"1569565223","weight":3},{"id":"1569566725","weight":10},{"id":"1569566385","weight":3},{"id":"1569567049","weight":10},{"id":"1569566799","weight":3},{"id":"1569565067","weight":15},{"id":"1569561021","weight":29},{"id":"1569564669","weight":8},{"id":"1569565691","weight":8},{"id":"1569566815","weight":3},{"id":"1569566875","weight":2},{"id":"1569564605","weight":4},{"id":"1569566981","weight":14},{"id":"1569566433","weight":4},{"id":"1569566321","weight":2},{"id":"1569566605","weight":4},{"id":"1569565489","weight":2},{"id":"1569566855","weight":5},{"id":"1569566869","weight":3},{"id":"1569565097","weight":2},{"id":"1569566227","weight":3},{"id":"1569566091","weight":3},{"id":"1569559259","weight":12},{"id":"1569566697","weight":2},{"id":"1569566597","weight":3},{"id":"1569565551","weight":5},{"id":"1569566761","weight":11},{"id":"1569566943","weight":2},{"id":"1569565091","weight":4},{"id":"1569566591","weight":6},{"id":"1569566571","weight":2},{"id":"1569565607","weight":3},{"id":"1569565495","weight":18},{"id":"1569567045","weight":3},{"id":"1569565227","weight":2},{"id":"1569564481","weight":3},{"id":"1569560833","weight":2},{"id":"1569566415","weight":3},{"id":"1569564805","weight":4},{"id":"1569567005","weight":4},{"id":"1569566081","weight":6},{"id":"1569565613","weight":2},{"id":"1569565355","weight":2},{"id":"1569564469","weight":20},{"id":"1569565931","weight":3},{"id":"1569566373","weight":3},{"id":"1569566647","weight":5},{"id":"1569551535","weight":3},{"id":"1569566765","weight":2},{"id":"1569565547","weight":2},{"id":"1569565461","weight":2},{"id":"1569564731","weight":2},{"id":"1569565171","weight":3},{"id":"1569566207","weight":2},{"id":"1569564227","weight":3},{"id":"1569558325","weight":2},{"id":"1569557585","weight":4},{"id":"1569565837","weight":2},{"id":"1569566303","weight":2},{"id":"1569566119","weight":8},{"id":"1569564233","weight":2},{"id":"1569566459","weight":3},{"id":"1569563411","weight":3},{"id":"1569564401","weight":4},{"id":"1569564849","weight":2},{"id":"1569559541","weight":4},{"id":"1569566319","weight":5},{"id":"1569565123","weight":2},{"id":"1569566941","weight":14},{"id":"1569566033","weight":2},{"id":"1569566739","weight":2},{"id":"1569555811","weight":2},{"id":"1569558459","weight":6},{"id":"1569565609","weight":2},{"id":"1569565291","weight":2},{"id":"1569564203","weight":3},{"id":"1569566821","weight":5},{"id":"1569556713","weight":5},{"id":"1569566467","weight":6},{"id":"1569565771","weight":2},{"id":"1569566157","weight":2},{"id":"1569566903","weight":9},{"id":"1569565859","weight":2},{"id":"1569565809","weight":4},{"id":"1569566843","weight":5},{"id":"1569566579","weight":3},{"id":"1569558483","weight":2},{"id":"1569566563","weight":5},{"id":"1569564903","weight":2},{"id":"1569566173","weight":3},{"id":"1569559221","weight":3},{"id":"1569556091","weight":2},{"id":"1569565347","weight":4},{"id":"1569566925","weight":2},{"id":"1569564387","weight":4},{"id":"1569565455","weight":3},{"id":"1569566497","weight":11},{"id":"1569566795","weight":9},{"id":"1569566963","weight":3},{"id":"1569561679","weight":2},{"id":"1569564989","weight":2},{"id":"1569566015","weight":3},{"id":"1569565897","weight":4},{"id":"1569565953","weight":3},{"id":"1569566895","weight":4},{"id":"1569566889","weight":3},{"id":"1569566269","weight":3},{"id":"1569564189","weight":2},{"id":"1569564195","weight":2},{"id":"1569561513","weight":3},{"id":"1569566985","weight":2},{"id":"1569564613","weight":4},{"id":"1569567009","weight":5},{"id":"1569566865","weight":2},{"id":"1569565321","weight":4},{"id":"1569564647","weight":2},{"id":"1569566193","weight":3},{"id":"1569564271","weight":2},{"id":"1569564337","weight":2},{"id":"1569565907","weight":3},{"id":"1569566343","weight":2},{"id":"1569564311","weight":3},{"id":"1569565803","weight":2},{"id":"1569565785","weight":3},{"id":"1569566679","weight":4},{"id":"1569565989","weight":4},{"id":"1569566575","weight":6},{"id":"1569563981","weight":4},{"id":"1569561085","weight":4},{"id":"1569566617","weight":3},{"id":"1569559565","weight":2},{"id":"1569566905","weight":4},{"id":"1569566733","weight":3},{"id":"1569563307","weight":4},{"id":"1569566063","weight":3},{"id":"1569558681","weight":2},{"id":"1569555999","weight":2},{"id":"1569566759","weight":10},{"id":"1569565589","weight":2},{"id":"1569559195","weight":2},{"id":"1569566149","weight":7},{"id":"1569566657","weight":6},{"id":"1569565199","weight":7},{"id":"1569565213","weight":2},{"id":"1569565365","weight":2},{"id":"1569566643","weight":2},{"id":"1569566511","weight":4},{"id":"1569566719","weight":2},{"id":"1569565841","weight":3},{"id":"1569566369","weight":2},{"id":"1569566531","weight":7},{"id":"1569567665","weight":3},{"id":"1569561143","weight":2},{"id":"1569565833","weight":2},{"id":"1569566489","weight":3},{"id":"1569564611","weight":10},{"id":"1569565535","weight":8},{"id":"1569562867","weight":7},{"id":"1569566395","weight":2},{"id":"1569561795","weight":2},{"id":"1569566845","weight":3},{"id":"1569566325","weight":10},{"id":"1569564795","weight":7},{"id":"1569567015","weight":4},{"id":"1569559805","weight":5},{"id":"1569566437","weight":2},{"id":"1569566811","weight":13},{"id":"1569565735","weight":6},{"id":"1569559111","weight":4},{"id":"1569553537","weight":3},{"id":"1569565427","weight":11},{"id":"1569566403","weight":2},{"id":"1569552251","weight":2},{"id":"1569566885","weight":2},{"id":"1569564441","weight":4},{"id":"1569566231","weight":3},{"id":"1569566513","weight":7},{"id":"1569554881","weight":2},{"id":"1569554971","weight":4},{"id":"1569565501","weight":4},{"id":"1569566899","weight":4},{"id":"1569566445","weight":2},{"id":"1569566209","weight":2},{"id":"1569566649","weight":12},{"id":"1569566371","weight":8},{"id":"1569565655","weight":2},{"id":"1569566909","weight":11},{"id":"1569566127","weight":3},{"id":"1569565151","weight":2},{"id":"1569563763","weight":3},{"id":"1569566473","weight":5},{"id":"1569564857","weight":4},{"id":"1569564333","weight":8},{"id":"1569566913","weight":2},{"id":"1569566809","weight":4},{"id":"1569566629","weight":4},{"id":"1569566257","weight":44},{"id":"1569565033","weight":3},{"id":"1569566447","weight":2},{"id":"1569566357","weight":5},{"id":"1569565847","weight":4},{"id":"1569564353","weight":5},{"id":"1569563897","weight":2},{"id":"1569557083","weight":2},{"id":"1569566141","weight":2},{"id":"1569565633","weight":2},{"id":"1569566661","weight":2},{"id":"1569565279","weight":5},{"id":"1569555879","weight":16},{"id":"1569566115","weight":6},{"id":"1569565219","weight":2},{"id":"1569558509","weight":4},{"id":"1569554759","weight":2},{"id":"1569564851","weight":6},{"id":"1569565595","weight":2},{"id":"1569565185","weight":5},{"id":"1569566773","weight":10},{"id":"1569565095","weight":4},{"id":"1569566223","weight":10},{"id":"1569566553","weight":7},{"id":"1569564969","weight":3},{"id":"1569565029","weight":5},{"id":"1569561245","weight":10},{"id":"1569566505","weight":7},{"id":"1569562207","weight":2},{"id":"1569566191","weight":7},{"id":"1569567033","weight":3},{"id":"1569565527","weight":12},{"id":"1569566603","weight":2},{"id":"1569565363","weight":3},{"id":"1569566695","weight":3},{"id":"1569566051","weight":4},{"id":"1569561379","weight":5},{"id":"1569565909","weight":11},{"id":"1569566655","weight":2},{"id":"1569567235","weight":3},{"id":"1569565441","weight":3},{"id":"1569566667","weight":2},{"id":"1569566893","weight":3},{"id":"1569566317","weight":6},{"id":"1569564097","weight":9},{"id":"1569560997","weight":11},{"id":"1569566407","weight":4},{"id":"1569560349","weight":14},{"id":"1569566501","weight":6},{"id":"1569565741","weight":11},{"id":"1569566275","weight":6},{"id":"1569566481","weight":7},{"id":"1569565545","weight":5},{"id":"1569566857","weight":4},{"id":"1569565961","weight":2},{"id":"1569566387","weight":2},{"id":"1569566245","weight":3},{"id":"1569560503","weight":2},{"id":"1569566229","weight":2},{"id":"1569566949","weight":2},{"id":"1569566133","weight":3},{"id":"1569566155","weight":2},{"id":"1569551347","weight":2},{"id":"1569566383","weight":4},{"id":"1569565885","weight":2},{"id":"1569566177","weight":5},{"id":"1569565493","weight":4},{"id":"1569566805","weight":3},{"id":"1569559199","weight":6},{"id":"1569566929","weight":2},{"id":"1569566293","weight":9},{"id":"1569565665","weight":4},{"id":"1569566831","weight":2},{"id":"1569565549","weight":4},{"id":"1569565611","weight":5},{"id":"1569566983","weight":6},{"id":"1569566479","weight":9},{"id":"1569566431","weight":2},{"id":"1569566873","weight":2},{"id":"1569565765","weight":2},{"id":"1569565093","weight":6},{"id":"1569565575","weight":2},{"id":"1569565919","weight":4},{"id":"1569565181","weight":3},{"id":"1569566711","weight":7},{"id":"1569565241","weight":2},{"id":"1569566927","weight":18},{"id":"1569565661","weight":2},{"id":"1569565865","weight":2},{"id":"1569566887","weight":4},{"id":"1569565273","weight":4},{"id":"1569566267","weight":2},{"id":"1569564131","weight":7},{"id":"1569552037","weight":3},{"id":"1569564919","weight":2},{"id":"1569565511","weight":5},{"id":"1569566737","weight":2},{"id":"1569566429","weight":8},{"id":"1569566917","weight":8},{"id":"1569566035","weight":3},{"id":"1569566253","weight":20},{"id":"1569565353","weight":9},{"id":"1569564683","weight":2},{"id":"1569564305","weight":2},{"id":"1569564291","weight":2},{"id":"1569566691","weight":2},{"id":"1569565421","weight":2},{"id":"1569566547","weight":2},{"id":"1569566651","weight":4},{"id":"1569566823","weight":2},{"id":"1569566595","weight":2},{"id":"1569566677","weight":9},{"id":"1569565349","weight":5},{"id":"1569566137","weight":6},{"id":"1569566283","weight":3},{"id":"1569565645","weight":4},{"id":"1569566529","weight":4},{"id":"1569565375","weight":2},{"id":"1569566715","weight":4},{"id":"1569565237","weight":5},{"id":"1569566639","weight":5},{"id":"1569566819","weight":6},{"id":"1569565041","weight":7},{"id":"1569564703","weight":4},{"id":"1569566713","weight":2},{"id":"1569565541","weight":2},{"id":"1569566813","weight":2},{"id":"1569566771","weight":18},{"id":"1569562277","weight":3},{"id":"1569564247","weight":2},{"id":"1569566533","weight":5},{"id":"1569551905","weight":3},{"id":"1569564861","weight":5},{"id":"1569564787","weight":2},{"id":"1569566487","weight":3},{"id":"1569565529","weight":5},{"id":"1569556759","weight":4},{"id":"1569566619","weight":3},{"id":"1569566397","weight":4},{"id":"1569566301","weight":4},{"id":"1569565669","weight":3},{"id":"1569566001","weight":2},{"id":"1569565593","weight":3},{"id":"1569564157","weight":2},{"id":"1569566389","weight":6},{"id":"1569566435","weight":2},{"id":"1569567483","weight":2},{"id":"1569566911","weight":5},{"id":"1569564923","weight":2},{"id":"1569565367","weight":2},{"id":"1569566299","weight":2},{"id":"1569564769","weight":2},{"id":"1569565769","weight":3},{"id":"1569566171","weight":3},{"id":"1569566601","weight":2},{"id":"1569565805","weight":3},{"id":"1569563919","weight":3},{"id":"1569559919","weight":7},{"id":"1569565861","weight":5},{"id":"1569566147","weight":2},{"id":"1569565537","weight":3},{"id":"1569565561","weight":3},{"id":"1569566457","weight":4},{"id":"1569565997","weight":5},{"id":"1569563425","weight":2},{"id":"1569565035","weight":9},{"id":"1569559597","weight":2},{"id":"1569564961","weight":7},{"id":"1569559251","weight":7},{"id":"1569567013","weight":4},{"id":"1569565337","weight":2},{"id":"1569565737","weight":3},{"id":"1569560459","weight":3},{"id":"1569564463","weight":2},{"id":"1569565853","weight":4},{"id":"1569550425","weight":5},{"id":"1569566273","weight":2},{"id":"1569564123","weight":8},{"id":"1569566341","weight":2},{"id":"1569566635","weight":3},{"id":"1569565565","weight":2},{"id":"1569565635","weight":2},{"id":"1569561397","weight":3},{"id":"1569566797","weight":3},{"id":"1569566413","weight":2},{"id":"1569565707","weight":7},{"id":"1569566375","weight":15},{"id":"1569564257","weight":2},{"id":"1569565583","weight":2},{"id":"1569566555","weight":2},{"id":"1569565373","weight":2},{"id":"1569566973","weight":16},{"id":"1569561579","weight":3},{"id":"1569566449","weight":4},{"id":"1569566987","weight":6},{"id":"1569565031","weight":2},{"id":"1569551541","weight":2},{"id":"1569566839","weight":4},{"id":"1569565139","weight":6},{"id":"1569566663","weight":11},{"id":"1569564419","weight":2},{"id":"1569565579","weight":3},{"id":"1569566067","weight":3},{"id":"1569566825","weight":3},{"id":"1569566241","weight":4},{"id":"1569564807","weight":4},{"id":"1569566609","weight":2},{"id":"1569563007","weight":2},{"id":"1569566113","weight":3},{"id":"1569566443","weight":2},{"id":"1569566727","weight":6},{"id":"1569565315","weight":9},{"id":"1569566417","weight":2},{"id":"1569560581","weight":4}],"meta":{"jsonClass":"HashMap$HashTrieMap","sessionid":"S11.T7.1","endtime":"10:10","authors":"Erman Ayday, Arash Einolghozati, Faramarz Fekri","date":"1341481800000","papertitle":"BPRS: Belief Propagation Based Iterative Recommender System","starttime":"09:50","session":"S11.T7: Message Passing Algorithms","room":"Stratton (407)","paperid":"1569566853"},"cluster":{"jsonClass":"HashMap$HashTrieMap","spectral6":"0","spectral43":"30","spectral28":"2","spectral32":"2","spectral14":"13","spectral20":"5","spectral9":"1","spectral25":"0","spectral42":"30","spectral3":"2","spectral47":"19","spectral17":"16","louvain":"112","spectral36":"21","spectral39":"9","spectral10":"8","spectral15":"5","spectral33":"4","spectral5":"2","spectral21":"7","spectral44":"36","spectral26":"8","spectral40":"38","spectral8":"4","spectral11":"4","spectral4":"3","spectral37":"19","spectral48":"18","spectral22":"10","spectral23":"14","spectral12":"9","spectral50":"13","spectral19":"13","spectral34":"32","spectral45":"12","spectral7":"6","spectral49":"19","spectral38":"32","spectral24":"18","spectral13":"9","spectral31":"1","spectral29":"4","spectral35":"31","spectral30":"13","spectral41":"27","spectral27":"12","spectral18":"9","spectral46":"20","spectral2":"1","spectral16":"5"}}
